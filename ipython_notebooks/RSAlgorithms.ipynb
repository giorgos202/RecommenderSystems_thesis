{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":731,"status":"ok","timestamp":1621245311464,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"e0RZf27tT4S6"},"outputs":[],"source":["# encoding:utf-8\n","class ConfigX(object):\n","    \"\"\"\n","    docstring for ConfigX\n","\n","    configurate the global parameters and hyper parameters\n","\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(ConfigX, self).__init__()\n","\n","        # Dataset Parameters\n","        self.dataset_name = \"CiaoDVD\"  # short name of datasets [\"ft\":\"filmtrust\",\"db\":\"douban\",\"ca\":\"ciao\"]\n","        self.k_fold_num = 5  # the num of cross validation\n","        self.rating_path = \"/content/drive/MyDrive/data/ft_ratings.txt\"  # the raw ratings data file\n","        self.rating_cv_path = \"../data/cv/\"  # the cross validation file of ratings data\n","        self.trust_path = '/content/drive/MyDrive/data/ft_trust_SimRank.txt'   # the raw trust data file\n","        self.sep = ' '  # the separator of rating and trust data in triple tuple\n","        self.random_state = 0  # the seed of random number\n","        self.size = 0.6  # the ratio of train set\n","        self.min_val = 0.5  # the minimum rating value\n","        self.max_val = 4.0  # the maximum rating value\n","\n","        # Model HyperParameter\n","        self.coldUserRating = 5  # the number of ratings a cold start user rated on items\n","        self.factor = 10  # the size of latent dimension for user and item.\n","        self.threshold = 1e-4  # the threshold value of model training \n","        self.lr = 0.01  # the learning rate\n","        self.maxIter = 100  # the maximum number of iterations\n","        self.lambdaP = 0.001  # the parameter of user regularizer\n","        self.lambdaQ = 0.001  # the parameter of item regularizer\n","        self.gamma = 0  # momentum coefficient\n","        self.isEarlyStopping = False  # early stopping flag\n","\n","        # Output Parameters\n","        self.result_path = \"../results/\"  # the directory of results\n","        self.model_path = \"model/\"  # the directory of well-trained variables\n","        self.result_log_path = \"log/\"  # the directory of logs when training models\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9148,"status":"ok","timestamp":1621245322851,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"T6Y99JUZUwDk","outputId":"647c9787-2d5b-4a19-c479-680c85529563"},"outputs":[{"name":"stdout","output_type":"stream","text":["../data/cv folder has been established.\n","CiaoDVD -fold0 data generated finished!\n","CiaoDVD -fold1 data generated finished!\n","CiaoDVD -fold2 data generated finished!\n","CiaoDVD -fold3 data generated finished!\n","CiaoDVD -fold4 data generated finished!\n","All Data Generated Done!\n"]}],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")\n","import os\n","import numpy as np\n","import pandas as pd\n","from scipy.sparse import coo_matrix\n","#from configx.configx import ConfigX\n","\n","\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","Split ratings into five folds\n","\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","\n","\n","def split_5_folds(configx):\n","    K = configx.k_fold_num\n","    names = ['user_id', 'item_id', 'rating']\n","    if not os.path.isfile(configx.rating_path):\n","        print(\"the format of rating data is wrong\")\n","        sys.exit()\n","    df = pd.read_csv(configx.rating_path, sep=configx.sep, names=names)\n","    ratings = coo_matrix((df.rating, (df.user_id, df.item_id)))\n","    users = np.unique(ratings.row)\n","    ratings = ratings.tocsr()\n","\n","    rows = list()\n","    cols = list()\n","    vals = list()\n","    nonzeros = list()\n","\n","    for k in range(K):\n","        size_of_bucket = int(ratings.nnz / K)\n","        if k == K - 1:\n","            size_of_bucket += ratings.nnz % K\n","        rows.append(np.zeros(size_of_bucket))\n","        cols.append(np.zeros(size_of_bucket))\n","        vals.append(np.zeros(size_of_bucket))\n","        nonzeros.append(0)\n","\n","    for i, user in enumerate(users):\n","        items = ratings[user, :].indices\n","        rating_vals = ratings[user, :].data\n","        index_list = [i for i in range(K)] * int(len(items) / float(K) + 1)\n","        np.random.shuffle(index_list)\n","        index_list = np.array(index_list)\n","\n","        for k in range(K):\n","            k_index_list = (index_list[:len(items)] == k)\n","            from_ind = nonzeros[k]\n","            to_ind = nonzeros[k] + sum(k_index_list)\n","\n","            if to_ind \u003e= len(rows[k]):\n","                rows[k] = np.append(rows[k], np.zeros(size_of_bucket))\n","                cols[k] = np.append(cols[k], np.zeros(size_of_bucket))\n","                vals[k] = np.append(vals[k], np.zeros(size_of_bucket))\n","                k_index_list = (index_list[:len(items)] == k)\n","\n","            rows[k][from_ind:to_ind] = [user] * sum(k_index_list)\n","            cols[k][from_ind:to_ind] = items[k_index_list]\n","            vals[k][from_ind:to_ind] = rating_vals[k_index_list]\n","            nonzeros[k] += sum(k_index_list)\n","\n","    if not os.path.exists('../data/cv'):\n","        os.makedirs('../data/cv')\n","        print('../data/cv folder has been established.')\n","\n","    for k, (row, col, val, nonzero) in enumerate(zip(rows, cols, vals, nonzeros)):\n","        bucket_df = pd.DataFrame({'user': row[:nonzero], 'item': col[:nonzero], 'rating': val[:nonzero]},\n","                                 columns=['user', 'item', 'rating'])\n","        bucket_df.to_csv(\"../data/cv/%s-%d.csv\" % (configx.dataset_name, k), sep=configx.sep, header=False, index=False)\n","        print(\"%s -fold%d data generated finished!\" % (configx.dataset_name, k))\n","\n","    print(\"All Data Generated Done!\")\n","\n","\n","if __name__ == \"__main__\":\n","    configx = ConfigX()\n","    split_5_folds(configx)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":653,"status":"ok","timestamp":1621245327556,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"t8bBL6j1Vpw9","outputId":"7573b3c0-fbdf-499b-c868-821123a170af"},"outputs":[{"name":"stdout","output_type":"stream","text":["2494\n","824\n","732\n"]}],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")\n","import pandas as pd\n","#from configx.configx import ConfigX\n","\n","config = ConfigX()\n","data = pd.read_table(config.trust_path, sep=' ', header=None)\n","# the number of links\n","print(len(data))\n","\n","# the number of followers\n","print(len(data[0].unique()))\n","\n","# the number of followees\n","print(len(data[1].unique()))\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":807,"status":"ok","timestamp":1621245330323,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"NocPb2EKV4vb","outputId":"025c515e-b4ec-4d54-d129-87d4e6d4bc41"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["import matplotlib.pylab as plt\n","\n","\n","def show_rmse():\n","    '''\n","    show figure\n","    '''\n","\n","    # epinions\n","    mfr = [1.16677, 1.18048, 1.19479]\n","    sr = [1.09047, 1.10516, 1.13036]\n","    my = [1.08060, 1.09336, 1.11335]\n","    x = [0.8, 0.6, 0.4]\n","\n","    plt.plot(x, mfr, label='PMF')\n","    plt.plot(x, sr, label='SocialReg')\n","    plt.plot(x, my, linewidth='2', label='SocialEmbeddings')\n","\n","    plt.xlabel('ratio of train set')\n","    plt.ylabel('RMSE')\n","    plt.title('Epinions(d=30)-all users')\n","    plt.legend()\n","    plt.show()\n","    pass\n","\n","\n","show_rmse()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":640,"status":"ok","timestamp":1621245333454,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"XxGpVx8KV7aw"},"outputs":[],"source":["class SimMatrix(object):\n","    def __init__(self):\n","        self.symMatrix = {}\n","\n","    def __getitem__(self, item):\n","        if item in self.symMatrix:\n","            return self.symMatrix[item]\n","        return {}\n","\n","    def set(self, i, j, val):\n","        if not i in self.symMatrix:\n","            self.symMatrix[i] = {}\n","        self.symMatrix[i][j] = val\n","        if not j in self.symMatrix:\n","            self.symMatrix[j] = {}\n","        self.symMatrix[j][i] = val\n","\n","    def get(self, i, j):\n","        if not i in self.symMatrix or not j in self.symMatrix[i]:\n","            return 0\n","        return self.symMatrix[i][j]\n","\n","    def contains(self, i, j):\n","        if i in self.symMatrix and j in self.symMatrix[i]:\n","            return True\n","        else:\n","            return False\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":756,"status":"ok","timestamp":1621245336224,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"5A94XJ2RWGE3"},"outputs":[],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")\n","\n","import numpy as np\n","from numpy.linalg import norm\n","#from configx.configx import ConfigX\n","\n","config = ConfigX()\n","\n","\n","def l1(x):\n","    return norm(x, ord=1)\n","\n","\n","def l2(x):\n","    return norm(x)\n","\n","\n","def normalize(rating, minVal=config.min_val, maxVal=config.max_val):\n","    'get the normalized value using min-max normalization'\n","    if maxVal \u003e minVal:\n","        return float(rating - minVal) / (maxVal - minVal) + 0.01\n","    elif maxVal == minVal:\n","        return rating / maxVal\n","    else:\n","        print('error... maximum value is less than minimum value.')\n","        raise ArithmeticError\n","\n","\n","def denormalize(rating, minVal=config.min_val, maxVal=config.max_val):\n","    return minVal + (rating - 0.01) * (maxVal - minVal)\n","\n","\n","def sigmoid(z):\n","    return 1.0 / (1.0 + np.exp(-z))\n","\n","\n","def sigmoid_deriv(z):\n","    return sigmoid(z) * (1.0 - sigmoid(z))\n","\n","\n","def sigmoid_2(z):\n","    return 1.0 / (1.0 + np.exp(-z / 2.0))\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":596,"status":"ok","timestamp":1621245338944,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"_ojmGWCzWN1Q"},"outputs":[],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")\n","\n","import pickle\n","\n","\n","def save_data(obj, filename):\n","    pickle.dump(obj, open(filename, 'wb'))\n","    pass\n","\n","\n","def load_data(filename):\n","    f = open(filename, 'rb')\n","    model = pickle.load(f)\n","    print(filename + ' load data model finished.')\n","    return model\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":772,"status":"ok","timestamp":1621245341331,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"8a9dLxppWPKZ"},"outputs":[],"source":["# encoding:utf-8\n","import math\n","\n","\n","class Metric(object):\n","    '''\n","    the two metrics to measure the prediction accuracy for rating prediction task\n","    '''\n","\n","    def __init__(self):\n","        pass\n","\n","    @staticmethod\n","    def MAE(res):\n","        error = 0\n","        count = 0\n","        for entry in res:\n","            error += abs(entry[2] - entry[3])\n","            count += 1\n","        if count == 0:\n","            return error\n","        return float(error) / count\n","\n","    @staticmethod\n","    def RMSE(res):\n","        error = 0\n","        count = 0\n","        for entry in res:\n","            error += abs(entry[2] - entry[3]) ** 2\n","            count += 1\n","        if count == 0:\n","            return error\n","        return math.sqrt(float(error) / count)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3386,"status":"ok","timestamp":1621245347270,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"Waac8OAAWoCa"},"outputs":[],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")\n","import os\n","from collections import defaultdict\n","import numpy as np\n","\n","#from utility.tools import normalize\n","#from configx.configx import ConfigX\n","\n","\n","class RatingGetter(object):\n","    \"\"\"\n","    docstring for RatingGetter\n","    read rating data and save the global parameters\n","    \"\"\"\n","\n","    def __init__(self, k):\n","        super(RatingGetter, self).__init__()\n","        self.config = ConfigX()\n","        self.k_current = k\n","        self.user = {}\n","        self.item = {}\n","        self.all_User = {}\n","        self.all_Item = {}\n","        self.id2user = {}\n","        self.id2item = {}\n","        self.dataSet_u = defaultdict(dict)\n","        self.trainSet_u = defaultdict(dict)\n","        self.trainSet_i = defaultdict(dict)\n","        self.testSet_u = defaultdict(dict)  # used to store the test set by hierarchy user:[item,rating]\n","        self.testSet_i = defaultdict(dict)  # used to store the test set by hierarchy item:[user,rating]\n","        self.testColdUserSet_u = defaultdict(dict)  # cold start users in test set\n","        self.trainHotUserSet = []  # hot users in train set\n","        self.trainSetLength = 0\n","        self.testSetLength = 0\n","\n","        self.userMeans = {}  # used to store the mean values of users's ratings\n","        self.itemMeans = {}  # used to store the mean values of items's ratings\n","        self.globalMean = 0\n","\n","        self.generate_data_set()  # generate train and test set\n","        self.getDataSet()\n","        self.get_data_statistics()\n","        self.get_cold_start_users()\n","\n","    def generate_data_set(self):\n","        for index, line in enumerate(self.trainSet()):\n","            u, i, r = line\n","            # print(u,i,r)\n","            if not u in self.user:\n","                self.user[u] = len(self.user)\n","                self.id2user[self.user[u]] = u\n","            if not i in self.item:\n","                self.item[i] = len(self.item)\n","                self.id2item[self.item[i]] = i\n","\n","            self.trainSet_u[u][i] = r\n","            self.trainSet_i[i][u] = r\n","            self.trainSetLength = index + 1\n","        self.all_User.update(self.user)\n","        self.all_Item.update(self.item)\n","\n","        for index, line in enumerate(self.testSet()):\n","            u, i, r = line\n","            if not u in self.user:\n","                self.all_User[u] = len(self.all_User)\n","            if not i in self.item:\n","                self.all_Item[i] = len(self.all_Item)\n","            self.testSet_u[u][i] = r\n","            self.testSet_i[i][u] = r\n","            self.testSetLength = index + 1\n","        # print(self.trainSetLength)\n","        # print(self.testSetLength)\n","        pass\n","\n","    # for cross validation\n","    def trainSet(self):\n","        k = self.k_current\n","        for i in range(self.config.k_fold_num):\n","            if i != k:\n","                data_path = self.config.rating_cv_path + self.config.dataset_name + \"-\" + str(i) + \".csv\"\n","                # if not os.path.exists\n","                if not os.path.isfile(data_path):\n","                    print(\"the format of ratings data is wrong!\")\n","                    sys.exit()\n","                with open(data_path, 'r') as f:\n","                    for index, line in enumerate(f):\n","                        u, i, r = line.strip('\\r\\n').split(self.config.sep)\n","                        r = normalize(float(r))  # scale the rating score to [0-1]\n","                        yield (int(float(u)), int(float(i)), float(r))\n","\n","    def testSet(self):\n","        k = self.k_current\n","        data_path = self.config.rating_cv_path + self.config.dataset_name + \"-\" + str(k) + \".csv\"\n","        if not os.path.isfile(data_path):\n","            print(\"the format of ratings data is wrong!\")\n","            sys.exit()\n","        with open(data_path, 'r') as f:\n","            for index, line in enumerate(f):\n","                u, i, r = line.strip('\\r\\n').split(self.config.sep)\n","                yield (int(float(u)), int(float(i)), float(r))\n","\n","    # for random\n","    # def trainSet(self):\n","    #     np.random.seed(self.config.random_state)\n","    #     with open(self.config.rating_path,'r') as f:\n","    #         for index,line in enumerate(f):\n","    #             rand_num=np.random.rand()\n","    #             if  rand_num \u003c self.config.size:\n","    #                 u,i,r=line.strip('\\r\\n').split(self.config.sep)\n","    #                 r=normalize(float(r)) #scale the rating score to [0-1]\n","    #                 yield (int(u),int(i),float(r))\n","\n","    # def testSet(self):\n","    #     np.random.seed(self.config.random_state)\n","    #     with open(self.config.rating_path,'r') as f:\n","    #         for index,line in enumerate(f):\n","    #             rand_num=np.random.rand()\n","    #             if  rand_num \u003e= self.config.size:\n","    #                 u,i,r=line.strip('\\r\\n').split(self.config.sep)\n","    #                 yield (int(u),int(i),float(r))\n","\n","    def getDataSet(self):\n","        with open(self.config.rating_path, 'r') as f:\n","            for index, line in enumerate(f):\n","                u, i, r = line.strip('\\r\\n').split(self.config.sep)\n","                self.dataSet_u[int(u)][int(i)] = float(r)\n","\n","    def get_train_size(self):\n","        return (len(self.user), len(self.item))\n","\n","    # get cold start users in test set\n","    def get_cold_start_users(self):\n","        for user in self.testSet_u.keys():\n","            rating_length = len(self.trainSet_u[user])\n","            if rating_length \u003c= self.config.coldUserRating:\n","                self.testColdUserSet_u[user] = self.testSet_u[user]\n","        # print('cold start users count', len(self.testColdUserSet_u))\n","\n","    def get_data_statistics(self):\n","\n","        total_rating = 0.0\n","        total_length = 0\n","        for u in self.user:\n","            u_total = sum(self.trainSet_u[u].values())\n","            u_length = len(self.trainSet_u[u])\n","            total_rating += u_total\n","            total_length += u_length\n","            self.userMeans[u] = u_total / float(u_length)\n","\n","        for i in self.item:\n","            self.itemMeans[i] = sum(self.trainSet_i[i].values()) / float(len(self.trainSet_i[i]))\n","\n","        if total_length == 0:\n","            self.globalMean = 0\n","        else:\n","            self.globalMean = total_rating / total_length\n","\n","    def containsUser(self, u):\n","        'whether user is in training set'\n","        if u in self.user:\n","            return True\n","        else:\n","            return False\n","\n","    def containsItem(self, i):\n","        'whether item is in training set'\n","        if i in self.item:\n","            return True\n","        else:\n","            return False\n","\n","    def containsUserItem(self, user, item):\n","        if user in self.trainSet_u:\n","            if item in self.trainSet_u[user]:\n","                # print(user)\n","                # print(item)\n","                # print(self.trainSet_u[user][item])\n","                return True\n","        return False\n","\n","    def get_row(self, u):\n","        return self.trainSet_u[u]\n","\n","    def get_col(self, c):\n","        return self.trainSet_i[c]\n","\n","    def user_rated_items(self, u):\n","        return self.trainSet_u[u].keys()\n","\n","\n","if __name__ == '__main__':\n","    rg = RatingGetter(0)\n","    # for ind,entry in enumerate(rg.testSet()):\n","    # \tif ind\u003c80:\n","    # \t\tprint(entry)\n","    # # \t\tuser,item,rating = entry\n","\n","    # print(rg.trainSet_u[52])\n","    # print(rg.trainSet_u[10])\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":604,"status":"ok","timestamp":1621245353686,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"wcHEvj8NWwHI"},"outputs":[],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")\n","import numpy as np\n","from math import sqrt\n","#from utility.tools import sigmoid_2\n","\n","\n","# x1,x2 is the form of np.array.\n","\n","def euclidean(x1, x2):\n","    # find common ratings\n","    new_x1, new_x2 = common(x1, x2)\n","    # compute the euclidean between two vectors\n","    diff = new_x1 - new_x2\n","    denom = sqrt((diff.dot(diff)))\n","    try:\n","        return 1 / denom\n","    except ZeroDivisionError:\n","        return 0\n","\n","\n","def cosine(x1, x2):\n","    # find common ratings\n","    new_x1, new_x2 = common(x1, x2)\n","    # compute the cosine similarity between two vectors\n","    sum = new_x1.dot(new_x2)\n","    denom = sqrt(new_x1.dot(new_x1) * new_x2.dot(new_x2))\n","    try:\n","        return float(sum) / denom\n","    except ZeroDivisionError:\n","        return 0\n","\n","\n","def pearson(x1, x2):\n","    # find common ratings\n","    new_x1, new_x2 = common(x1, x2)\n","    # compute the pearson similarity between two vectors\n","    ind1 = new_x1 \u003e 0\n","    ind2 = new_x2 \u003e 0\n","    try:\n","        mean_x1 = float(new_x1.sum()) / ind1.sum()\n","        mean_x2 = float(new_x2.sum()) / ind2.sum()\n","        new_x1 = new_x1 - mean_x1\n","        new_x2 = new_x2 - mean_x2\n","        sum = new_x1.dot(new_x2)\n","        denom = sqrt((new_x1.dot(new_x1)) * (new_x2.dot(new_x2)))\n","        return float(sum) / denom\n","    except ZeroDivisionError:\n","        return 0\n","\n","\n","def common(x1, x2):\n","    # find common ratings\n","    common = (x1 != 0) \u0026 (x2 != 0)\n","    new_x1 = x1[common]\n","    new_x2 = x2[common]\n","    return new_x1, new_x2\n","\n","\n","# x1,x2 is the form of dict.\n","\n","def cosine_sp(x1, x2):\n","    'x1,x2 are dicts,this version is for sparse representation'\n","    total = 0\n","    denom1 = 0\n","    denom2 = 0\n","    # x1_l,x2_l=len(x1),len(x2)\n","    # if x2_l\u003ex1_l:\n","    # x1,x2=x2,x1\n","    for k in x1:\n","        if k in x2:\n","            total += x1[k] * x2[k]\n","            denom1 += x1[k] ** 2\n","            denom2 += x2[k] ** 2  # .pop(k)\n","        # else:\n","        # denom1+=x1[k]**2\n","    # for j in x2:\n","    # \tdenom2+=x2[j]**2\n","    try:\n","        return (total + 0.0) / (sqrt(denom1) * sqrt(denom2))\n","    except ZeroDivisionError:\n","        return 0\n","\n","\n","def cosine_improved_sp(x1, x2):\n","    'x1,x2 are dicts,this version is for sparse representation'\n","    total = 0\n","    denom1 = 0\n","    denom2 = 0\n","    nu = 0\n","    for k in x1:\n","        if k in x2:\n","            nu += 1\n","            total += x1[k] * x2[k]\n","            denom1 += x1[k] ** 2\n","            denom2 += x2[k] ** 2\n","    try:\n","        return (total + 0.0) / (sqrt(denom1) * sqrt(denom2)) * sigmoid_2(nu)\n","    except ZeroDivisionError:\n","        return 0\n","\n","\n","# def pearson_sp(x1, x2):\n","#     total = 0\n","#     denom1 = 0\n","#     denom2 = 0\n","#     try:\n","#         mean1 = sum(x1.values()) / (len(x1) + 0.0)\n","#         mean2 = sum(x2.values()) / (len(x2) + 0.0)\n","#         for k in x1:\n","#             if k in x2:\n","#                 total += (x1[k] - mean1) * (x2[k] - mean2)\n","#                 denom1 += (x1[k] - mean1) ** 2\n","#                 denom2 += (x2[k] - mean2) ** 2\n","#         return (total + 0.0) / (sqrt(denom1) * sqrt(denom2))\n","#     except ZeroDivisionError:\n","#         return 0\n","\n","# improved pearson\n","def pearson_sp(x1, x2):\n","    common = set(x1.keys()) \u0026 set(x2.keys())\n","    if len(common) == 0:\n","        return 0\n","    ratingList1 = []\n","    ratingList2 = []\n","    for i in common:\n","        ratingList1.append(x1[i])\n","        ratingList2.append(x2[i])\n","    if len(ratingList1) == 0 or len(ratingList2) == 0:\n","        return 0\n","    avg1 = sum(ratingList1) / len(ratingList1)\n","    avg2 = sum(ratingList2) / len(ratingList2)\n","    mult = 0.0\n","    sum1 = 0.0\n","    sum2 = 0.0\n","    for i in range(len(ratingList1)):\n","        mult += (ratingList1[i] - avg1) * (ratingList2[i] - avg2)\n","        sum1 += pow(ratingList1[i] - avg1, 2)\n","        sum2 += pow(ratingList2[i] - avg2, 2)\n","    if sum1 == 0 or sum2 == 0:\n","        return 0\n","    return mult / (sqrt(sum1) * sqrt(sum2))\n","\n","\n","# TrustWalker userd\n","def pearson_improved_sp(x1, x2):\n","    total = 0.0\n","    denom1 = 0\n","    denom2 = 0\n","    nu = 0\n","    try:\n","        mean1 = sum(x1.values()) / (len(x1) + 0.0)\n","        mean2 = sum(x2.values()) / (len(x2) + 0.0)\n","        for k in x1:\n","            if k in x2:\n","                # print('k'+str(k))\n","                nu += 1\n","                total += (x1[k] - mean1) * (x2[k] - mean2)\n","                # print('t'+str(total))\n","                denom1 += (x1[k] - mean1) ** 2\n","                denom2 += (x2[k] - mean2) ** 2\n","        # print('nu:'+str(nu))\n","        # print(total)\n","        return (total + 0.0) / (sqrt(denom1) * sqrt(denom2)) * sigmoid_2(nu)\n","    except ZeroDivisionError:\n","        return 0\n","\n","\n","def euclidean_sp(x1, x2):\n","    total = 0.0\n","    for k in x1:\n","        if k in x2:\n","            total += sqrt(x1[k] - x2[k])\n","    try:\n","        return 1.0 / total\n","    except ZeroDivisionError:\n","        return 0\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1234,"status":"ok","timestamp":1621245365885,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"hjfTIeT4W6tt","outputId":"03125617-9d0c-4c2f-929e-f41e97868e57"},"outputs":[{"name":"stdout","output_type":"stream","text":["15006\n","17486\n","14948\n","58\n","2554\n","71\n"]}],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")\n","\n","#from metrics.metric import Metric\n","#from utility.tools import denormalize, sigmoid\n","#from reader.rating import RatingGetter\n","#from reader.trust import TrustGetter\n","#from configx.configx import ConfigX\n","\n","\n","class DataStatis(object):\n","    \"\"\"docstring for DataStatis\"\"\"\n","\n","    def __init__(self):\n","        super(DataStatis, self).__init__()\n","        self.config = ConfigX()\n","        self.rg = RatingGetter(0)  # loading rating data\n","        self.tg = TrustGetter()     \n","        self.cold_rating = 0\n","        self.cold_social = 0\n","        self.cold_rating_social = 0\n","        self.cold_rating_warm_social = 0\n","        self.warm_rating_cold_social = 0\n","        self.warm_rating_warm_social = 0\n","\n","    def getDataStatis(self):\n","        # print(self.rg.dataSet_u[2])\n","        for user in self.rg.dataSet_u:\n","            # print(user)\n","            num_rating = len(self.rg.dataSet_u[user])\n","            num_social = len(self.tg.followees[user])\n","\n","            if (num_rating \u003c 5):\n","                self.cold_rating += 1\n","            if (num_social \u003c 5):\n","                self.cold_social += 1\n","\n","            if (num_rating \u003c 5 and num_social \u003c 5):\n","                self.cold_rating_social += 1\n","            if (num_rating \u003c 5 and num_social \u003e= 5):\n","                self.cold_rating_warm_social += 1\n","            if (num_rating \u003e= 5 and num_social \u003c= 5):\n","                self.warm_rating_cold_social += 1\n","            if (num_rating \u003e= 5 and num_social \u003e= 5):\n","                self.warm_rating_warm_social += 1\n","\n","        pass\n","\n","\n","if __name__ == '__main__':\n","    ds = DataStatis()\n","    ds.getDataStatis()\n","    print(ds.cold_rating)\n","    print(ds.cold_social)\n","    print(ds.cold_rating_social)\n","    print(ds.cold_rating_warm_social)\n","    print(ds.warm_rating_cold_social)\n","    print(ds.warm_rating_warm_social)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":606,"status":"ok","timestamp":1621245362885,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"BkoZXIloU7Mn","outputId":"3f2f3268-51ad-4fc4-b99d-7ac27ddf4e09"},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys([966, 104, 1567])\n"]}],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")\n","import numpy as np\n","import os\n","from collections import defaultdict\n","\n","#from configx.configx import ConfigX\n","\n","\n","class TrustGetter(object):\n","    \"\"\"\n","    docstring for TrustGetter\n","    read trust data and save the global parameters\n","\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(TrustGetter, self).__init__()\n","        self.config = ConfigX()\n","\n","        self.user = {}  # used to store the order of users\n","        self.relations = self.get_relations()\n","        self.followees = defaultdict(dict)\n","        self.followers = {}\n","        self.matrix_User = {}\n","        self.matrix_Item = {}\n","        self.generate_data_set()\n","\n","    def generate_data_set(self):\n","        triple = []\n","        for line in self.relations:\n","            userId1, userId2, weight = line\n","            # add relations to dict\n","            if not userId1 in self.followees:\n","                self.followees[userId1] = {}\n","            self.followees[userId1][userId2] = weight\n","            if not userId2 in self.followers:\n","                self.followers[userId2] = {}\n","            self.followers[userId2][userId1] = weight\n","            # order the user\n","            if not userId1 in self.user:\n","                userid1 = self.user[userId1] = len(self.user)\n","            if not userId2 in self.user:\n","                userid2 = self.user[userId2] = len(self.user)\n","            if not userid1 in self.matrix_User:\n","                self.matrix_User[userid1] = {}\n","            if not userid2 in self.matrix_User:\n","                self.matrix_Item[userid2] = {}\n","            self.matrix_User[userid1][userid2] = weight\n","            self.matrix_Item[userid2][userid1] = weight\n","\n","    def get_relations(self):\n","        if not os.path.isfile(self.config.trust_path):\n","            print(\"the format of trust data is wrong\")\n","            sys.exit()\n","        with open(self.config.trust_path, 'r') as f:\n","            for index, line in enumerate(f):\n","                u_from, u_to, t = line.strip('\\r\\n').split(self.config.sep)\n","                yield (int(u_from), int(u_to), float(t))\n","\n","    def get_followees(self, u):\n","        if u in self.followees:\n","            return self.followees[u]\n","        else:\n","            return {}\n","\n","    def get_followers(self, u):\n","        if u in self.followers:\n","            return self.followers[u]\n","        else:\n","            return {}\n","\n","    def weight(self, u, k):\n","        if u in self.followees and k in self.followees[u]:\n","            return self.followees[u][k]\n","        else:\n","            return 0\n","\n","\n","if __name__ == '__main__':\n","    tg = TrustGetter()\n","    s = tg.get_followees(2).keys()\n","    print(s)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":957,"status":"ok","timestamp":1621245370537,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"dbdB3qyaXhcL"},"outputs":[],"source":["#encoding:utf-8\n","import  sys\n","sys.path.append(\"..\")\n","\n","import numpy as np\n","import matplotlib.pylab as plt\n","\n","#from prettyprinter import cpprint\n","#from metrics.metric import Metric\n","#from utility.tools import denormalize,sigmoid\n","#from reader.rating import RatingGetter\n","##from configx.configx import ConfigX\n","\n","\n","class MF(object):\n","    \"\"\"\n","    docstring for MF\n","    the base class for matrix factorization based model-parent class\n","\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(MF, self).__init__()\n","        self.config = ConfigX()\n","        print(self.config.__dict__)  #print the configuration\n","\n","        # self.rg = RatingGetter()  # loading raing data\n","        # self.init_model()\n","        self.iter_rmse = []\n","        self.iter_mae = []\n","        pass\n","\n","    def init_model(self,k):\n","        self.read_data(k)\n","        self.P = np.random.rand(self.rg.get_train_size()[0], self.config.factor) / (\n","        self.config.factor ** 0.5)  # latent user matrix\n","        self.Q = np.random.rand(self.rg.get_train_size()[1], self.config.factor) / (\n","        self.config.factor ** 0.5)  # latent item matrix\n","        self.loss, self.lastLoss = 0.0, 0.0\n","        self.lastRmse, self.lastMae = 10.0,10.0\n","        pass\n","\n","    def read_data(self,k):\n","        self.rg = RatingGetter(k)\n","        pass\n","\n","    def train_model(self,k):\n","        self.init_model(k)\n","        pass\n","\n","    # test all users in test set\n","    def predict_model(self):\n","        res = []\n","        for ind, entry in enumerate(self.rg.testSet()):\n","            user, item, rating = entry\n","            rating_length = len(self.rg.trainSet_u[user]) # remove cold start users for test\n","            if rating_length \u003c= self.config.coldUserRating:\n","                continue\n","\n","            prediction = self.predict(user, item)\n","            # denormalize\n","            prediction = denormalize(prediction, self.config.min_val, self.config.max_val)\n","\n","            pred = self.checkRatingBoundary(prediction)\n","            # add prediction in order to measure\n","            res.append([user, item, rating, pred])\n","        rmse = Metric.RMSE(res)\n","        mae = Metric.MAE(res)\n","        self.iter_rmse.append(rmse)  # for plot\n","        self.iter_mae.append(mae)\n","        return rmse, mae\n","\n","    # test cold start users among test set\n","    def predict_model_cold_users(self):\n","        res = []\n","        for user in self.rg.testColdUserSet_u.keys():\n","            for item in self.rg.testColdUserSet_u[user].keys():\n","                rating = self.rg.testColdUserSet_u[user][item]\n","                pred = self.predict(user, item)\n","                # pred = sigmoid(pred)\n","                # denormalize\n","                pred = denormalize(pred, self.config.min_val, self.config.max_val)\n","                pred = self.checkRatingBoundary(pred)\n","                res.append([user, item, rating, pred])\n","        rmse = Metric.RMSE(res)\n","        mae = Metric.MAE(res)\n","        return rmse,mae\n","\n","    def predict(self, u, i):\n","        if self.rg.containsUser(u) and self.rg.containsItem(i):\n","            return self.P[self.rg.user[u]].dot(self.Q[self.rg.item[i]])\n","        elif self.rg.containsUser(u) and not self.rg.containsItem(i):\n","            return self.rg.userMeans[u]\n","        elif not self.rg.containsUser(u) and self.rg.containsItem(i):\n","            return self.rg.itemMeans[i]\n","        else:\n","            return self.rg.globalMean\n","\n","    def checkRatingBoundary(self, prediction):\n","        prediction =round( min( max( prediction , self.config.min_val ) , self.config.max_val ) ,3)\n","        return prediction\n","\n","    def isConverged(self, iter):\n","        from math import isnan\n","        if isnan(self.loss):\n","            print(\n","                'Loss = NaN or Infinity: current settings does not fit the recommender! Change the settings and try again!')\n","            exit(-1)\n","\n","        deltaLoss = (self.lastLoss - self.loss)\n","        rmse, mae = self.predict_model()\n","\n","        # early stopping\n","        if self.config.isEarlyStopping == True:\n","            cond = self.lastRmse \u003c rmse\n","            if cond:\n","                print('test rmse increase, so early stopping')\n","                return cond\n","            self.lastRmse = rmse\n","            self.lastMae = mae\n","\n","        print('%s iteration %d: loss = %.4f, delta_loss = %.5f learning_Rate = %.5f rmse=%.5f mae=%.5f' % \\\n","              (self.__class__, iter, self.loss, deltaLoss, self.config.lr, rmse, mae))\n","\n","        # check if converged\n","        cond = abs(deltaLoss) \u003c self.config.threshold\n","        converged = cond\n","        # if not converged:\n","        # \tself.updateLearningRate(iter)\n","        self.lastLoss = self.loss\n","        # shuffle(self.dao.trainingData)\n","        return converged\n","\n","    def updateLearningRate(self, iter):\n","        if iter \u003e 1:\n","            if abs(self.lastLoss) \u003e abs(self.loss):\n","                self.config.lr *= 1.05\n","            else:\n","                self.config.lr *= 0.5\n","        if self.config.lr \u003e 1:\n","            self.config.lr = 1\n","\n","    def show_rmse(self):\n","        '''\n","        show figure for rmse and epoch\n","        '''\n","        nums = range(len(self.iter_rmse))\n","        plt.plot(nums, self.iter_rmse, label='RMSE')\n","        plt.plot(nums, self.iter_mae, label='MAE')\n","        plt.xlabel('# of epoch')\n","        plt.ylabel('metric')\n","        plt.title(self.__class__)\n","        plt.legend()\n","        plt.show()\n","        pass\n","    def show_loss(self,loss_all,faloss_all):\n","        '''\n","        show figure for rmse and epoch\n","        '''\n","        nums = range(len(loss_all))\n","        plt.plot(nums, loss_all, label='front')\n","        plt.plot(nums, faloss_all, label='rear')\n","        plt.xlabel('# of epoch')\n","        plt.ylabel('loss')\n","        plt.title('loss experiment')\n","        plt.legend()\n","        plt.show()\n","        pass\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3185919,"status":"ok","timestamp":1621248560003,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"EJrhbu6iMwMK","outputId":"a57f6b1f-8dfd-4975-9785-dc994e7815ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'dataset_name': 'CiaoDVD', 'k_fold_num': 5, 'rating_path': '/content/drive/MyDrive/data/ft_ratings.txt', 'rating_cv_path': '../data/cv/', 'trust_path': '/content/drive/MyDrive/data/ft_trust_SimRank.txt', 'sep': ' ', 'random_state': 0, 'size': 0.6, 'min_val': 0.5, 'max_val': 4.0, 'coldUserRating': 5, 'factor': 10, 'threshold': 0.0001, 'lr': 0.01, 'maxIter': 100, 'lambdaP': 0.001, 'lambdaQ': 0.001, 'gamma': 0, 'isEarlyStopping': False, 'result_path': '../results/', 'model_path': 'model/', 'result_log_path': 'log/'}\n","the 0th cross validation training\n","\u003cclass '__main__.SVDPP'\u003e iteration 1: loss = 90633.5701, delta_loss = -90633.57014 learning_Rate = 0.01000 rmse=1.46818 mae=1.05344\n","\u003cclass '__main__.SVDPP'\u003e iteration 2: loss = 28852.4464, delta_loss = 61781.12372 learning_Rate = 0.01000 rmse=1.38845 mae=1.01407\n","\u003cclass '__main__.SVDPP'\u003e iteration 3: loss = 16036.4260, delta_loss = 12816.02043 learning_Rate = 0.01000 rmse=1.31854 mae=0.97584\n","\u003cclass '__main__.SVDPP'\u003e iteration 4: loss = 12124.8256, delta_loss = 3911.60036 learning_Rate = 0.01000 rmse=1.27327 mae=0.95094\n","\u003cclass '__main__.SVDPP'\u003e iteration 5: loss = 9956.2448, delta_loss = 2168.58081 learning_Rate = 0.01000 rmse=1.24332 mae=0.93344\n","\u003cclass '__main__.SVDPP'\u003e iteration 6: loss = 8543.8948, delta_loss = 1412.35002 learning_Rate = 0.01000 rmse=1.22300 mae=0.92120\n","\u003cclass '__main__.SVDPP'\u003e iteration 7: loss = 7542.7112, delta_loss = 1001.18360 learning_Rate = 0.01000 rmse=1.20794 mae=0.91188\n","\u003cclass '__main__.SVDPP'\u003e iteration 8: loss = 6793.1791, delta_loss = 749.53206 learning_Rate = 0.01000 rmse=1.19711 mae=0.90468\n","\u003cclass '__main__.SVDPP'\u003e iteration 9: loss = 6209.7501, delta_loss = 583.42907 learning_Rate = 0.01000 rmse=1.18893 mae=0.89931\n","\u003cclass '__main__.SVDPP'\u003e iteration 10: loss = 5742.0041, delta_loss = 467.74597 learning_Rate = 0.01000 rmse=1.18248 mae=0.89515\n","\u003cclass '__main__.SVDPP'\u003e iteration 11: loss = 5358.1452, delta_loss = 383.85890 learning_Rate = 0.01000 rmse=1.17730 mae=0.89192\n","\u003cclass '__main__.SVDPP'\u003e iteration 12: loss = 5037.0689, delta_loss = 321.07634 learning_Rate = 0.01000 rmse=1.17296 mae=0.88911\n","\u003cclass '__main__.SVDPP'\u003e iteration 13: loss = 4764.2008, delta_loss = 272.86804 learning_Rate = 0.01000 rmse=1.16931 mae=0.88657\n","\u003cclass '__main__.SVDPP'\u003e iteration 14: loss = 4529.1505, delta_loss = 235.05032 learning_Rate = 0.01000 rmse=1.16629 mae=0.88453\n","\u003cclass '__main__.SVDPP'\u003e iteration 15: loss = 4324.3080, delta_loss = 204.84248 learning_Rate = 0.01000 rmse=1.16376 mae=0.88282\n","\u003cclass '__main__.SVDPP'\u003e iteration 16: loss = 4143.9683, delta_loss = 180.33969 learning_Rate = 0.01000 rmse=1.16158 mae=0.88138\n","\u003cclass '__main__.SVDPP'\u003e iteration 17: loss = 3983.7664, delta_loss = 160.20196 learning_Rate = 0.01000 rmse=1.15980 mae=0.88028\n","\u003cclass '__main__.SVDPP'\u003e iteration 18: loss = 3840.3027, delta_loss = 143.46369 learning_Rate = 0.01000 rmse=1.15835 mae=0.87935\n","\u003cclass '__main__.SVDPP'\u003e iteration 19: loss = 3710.8886, delta_loss = 129.41408 learning_Rate = 0.01000 rmse=1.15719 mae=0.87855\n","\u003cclass '__main__.SVDPP'\u003e iteration 20: loss = 3593.3686, delta_loss = 117.52003 learning_Rate = 0.01000 rmse=1.15615 mae=0.87779\n","\u003cclass '__main__.SVDPP'\u003e iteration 21: loss = 3485.9935, delta_loss = 107.37508 learning_Rate = 0.01000 rmse=1.15525 mae=0.87714\n","\u003cclass '__main__.SVDPP'\u003e iteration 22: loss = 3387.3288, delta_loss = 98.66467 learning_Rate = 0.01000 rmse=1.15444 mae=0.87656\n","\u003cclass '__main__.SVDPP'\u003e iteration 23: loss = 3296.1869, delta_loss = 91.14196 learning_Rate = 0.01000 rmse=1.15376 mae=0.87601\n","\u003cclass '__main__.SVDPP'\u003e iteration 24: loss = 3211.5761, delta_loss = 84.61075 learning_Rate = 0.01000 rmse=1.15322 mae=0.87556\n","\u003cclass '__main__.SVDPP'\u003e iteration 25: loss = 3132.6629, delta_loss = 78.91320 learning_Rate = 0.01000 rmse=1.15278 mae=0.87519\n","\u003cclass '__main__.SVDPP'\u003e iteration 26: loss = 3058.7420, delta_loss = 73.92094 learning_Rate = 0.01000 rmse=1.15247 mae=0.87489\n","\u003cclass '__main__.SVDPP'\u003e iteration 27: loss = 2989.2136, delta_loss = 69.52842 learning_Rate = 0.01000 rmse=1.15225 mae=0.87469\n","\u003cclass '__main__.SVDPP'\u003e iteration 28: loss = 2923.5654, delta_loss = 65.64811 learning_Rate = 0.01000 rmse=1.15212 mae=0.87455\n","\u003cclass '__main__.SVDPP'\u003e iteration 29: loss = 2861.3587, delta_loss = 62.20670 learning_Rate = 0.01000 rmse=1.15205 mae=0.87443\n","\u003cclass '__main__.SVDPP'\u003e iteration 30: loss = 2802.2164, delta_loss = 59.14239 learning_Rate = 0.01000 rmse=1.15205 mae=0.87433\n","\u003cclass '__main__.SVDPP'\u003e iteration 31: loss = 2745.8137, delta_loss = 56.40264 learning_Rate = 0.01000 rmse=1.15214 mae=0.87428\n","\u003cclass '__main__.SVDPP'\u003e iteration 32: loss = 2691.8711, delta_loss = 53.94257 learning_Rate = 0.01000 rmse=1.15224 mae=0.87421\n","\u003cclass '__main__.SVDPP'\u003e iteration 33: loss = 2640.1475, delta_loss = 51.72362 learning_Rate = 0.01000 rmse=1.15238 mae=0.87418\n","\u003cclass '__main__.SVDPP'\u003e iteration 34: loss = 2590.4349, delta_loss = 49.71259 learning_Rate = 0.01000 rmse=1.15253 mae=0.87417\n","\u003cclass '__main__.SVDPP'\u003e iteration 35: loss = 2542.5541, delta_loss = 47.88082 learning_Rate = 0.01000 rmse=1.15270 mae=0.87417\n","\u003cclass '__main__.SVDPP'\u003e iteration 36: loss = 2496.3505, delta_loss = 46.20358 learning_Rate = 0.01000 rmse=1.15291 mae=0.87417\n","\u003cclass '__main__.SVDPP'\u003e iteration 37: loss = 2451.6910, delta_loss = 44.65957 learning_Rate = 0.01000 rmse=1.15315 mae=0.87423\n","\u003cclass '__main__.SVDPP'\u003e iteration 38: loss = 2408.4604, delta_loss = 43.23055 learning_Rate = 0.01000 rmse=1.15338 mae=0.87430\n","\u003cclass '__main__.SVDPP'\u003e iteration 39: loss = 2366.5595, delta_loss = 41.90091 learning_Rate = 0.01000 rmse=1.15364 mae=0.87439\n","\u003cclass '__main__.SVDPP'\u003e iteration 40: loss = 2325.9020, delta_loss = 40.65747 learning_Rate = 0.01000 rmse=1.15393 mae=0.87451\n","\u003cclass '__main__.SVDPP'\u003e iteration 41: loss = 2286.4129, delta_loss = 39.48914 learning_Rate = 0.01000 rmse=1.15426 mae=0.87466\n","\u003cclass '__main__.SVDPP'\u003e iteration 42: loss = 2248.0262, delta_loss = 38.38667 learning_Rate = 0.01000 rmse=1.15460 mae=0.87481\n","\u003cclass '__main__.SVDPP'\u003e iteration 43: loss = 2210.6838, delta_loss = 37.34244 learning_Rate = 0.01000 rmse=1.15498 mae=0.87499\n","\u003cclass '__main__.SVDPP'\u003e iteration 44: loss = 2174.3336, delta_loss = 36.35020 learning_Rate = 0.01000 rmse=1.15540 mae=0.87519\n","\u003cclass '__main__.SVDPP'\u003e iteration 45: loss = 2138.9287, delta_loss = 35.40486 learning_Rate = 0.01000 rmse=1.15581 mae=0.87540\n","\u003cclass '__main__.SVDPP'\u003e iteration 46: loss = 2104.4265, delta_loss = 34.50227 learning_Rate = 0.01000 rmse=1.15624 mae=0.87563\n","\u003cclass '__main__.SVDPP'\u003e iteration 47: loss = 2070.7874, delta_loss = 33.63907 learning_Rate = 0.01000 rmse=1.15671 mae=0.87590\n","\u003cclass '__main__.SVDPP'\u003e iteration 48: loss = 2037.9749, delta_loss = 32.81246 learning_Rate = 0.01000 rmse=1.15719 mae=0.87618\n","\u003cclass '__main__.SVDPP'\u003e iteration 49: loss = 2005.9548, delta_loss = 32.02014 learning_Rate = 0.01000 rmse=1.15767 mae=0.87647\n","\u003cclass '__main__.SVDPP'\u003e iteration 50: loss = 1974.6947, delta_loss = 31.26009 learning_Rate = 0.01000 rmse=1.15816 mae=0.87676\n","\u003cclass '__main__.SVDPP'\u003e iteration 51: loss = 1944.1641, delta_loss = 30.53056 learning_Rate = 0.01000 rmse=1.15868 mae=0.87707\n","\u003cclass '__main__.SVDPP'\u003e iteration 52: loss = 1914.3342, delta_loss = 29.82996 learning_Rate = 0.01000 rmse=1.15920 mae=0.87740\n","\u003cclass '__main__.SVDPP'\u003e iteration 53: loss = 1885.1774, delta_loss = 29.15678 learning_Rate = 0.01000 rmse=1.15975 mae=0.87776\n","\u003cclass '__main__.SVDPP'\u003e iteration 54: loss = 1856.6678, delta_loss = 28.50962 learning_Rate = 0.01000 rmse=1.16029 mae=0.87812\n","\u003cclass '__main__.SVDPP'\u003e iteration 55: loss = 1828.7807, delta_loss = 27.88710 learning_Rate = 0.01000 rmse=1.16082 mae=0.87847\n","\u003cclass '__main__.SVDPP'\u003e iteration 56: loss = 1801.4928, delta_loss = 27.28787 learning_Rate = 0.01000 rmse=1.16136 mae=0.87883\n","\u003cclass '__main__.SVDPP'\u003e iteration 57: loss = 1774.7822, delta_loss = 26.71063 learning_Rate = 0.01000 rmse=1.16190 mae=0.87922\n","\u003cclass '__main__.SVDPP'\u003e iteration 58: loss = 1748.6281, delta_loss = 26.15410 learning_Rate = 0.01000 rmse=1.16245 mae=0.87961\n","\u003cclass '__main__.SVDPP'\u003e iteration 59: loss = 1723.0110, delta_loss = 25.61704 learning_Rate = 0.01000 rmse=1.16296 mae=0.87999\n","\u003cclass '__main__.SVDPP'\u003e iteration 60: loss = 1697.9128, delta_loss = 25.09824 learning_Rate = 0.01000 rmse=1.16343 mae=0.88035\n","\u003cclass '__main__.SVDPP'\u003e iteration 61: loss = 1673.3163, delta_loss = 24.59655 learning_Rate = 0.01000 rmse=1.16391 mae=0.88073\n","\u003cclass '__main__.SVDPP'\u003e iteration 62: loss = 1649.2054, delta_loss = 24.11087 learning_Rate = 0.01000 rmse=1.16439 mae=0.88109\n","\u003cclass '__main__.SVDPP'\u003e iteration 63: loss = 1625.5652, delta_loss = 23.64018 learning_Rate = 0.01000 rmse=1.16488 mae=0.88147\n","\u003cclass '__main__.SVDPP'\u003e iteration 64: loss = 1602.3817, delta_loss = 23.18350 learning_Rate = 0.01000 rmse=1.16538 mae=0.88185\n","\u003cclass '__main__.SVDPP'\u003e iteration 65: loss = 1579.6418, delta_loss = 22.73994 learning_Rate = 0.01000 rmse=1.16589 mae=0.88223\n","\u003cclass '__main__.SVDPP'\u003e iteration 66: loss = 1557.3331, delta_loss = 22.30868 learning_Rate = 0.01000 rmse=1.16641 mae=0.88262\n","\u003cclass '__main__.SVDPP'\u003e iteration 67: loss = 1535.4441, delta_loss = 21.88897 learning_Rate = 0.01000 rmse=1.16693 mae=0.88301\n","\u003cclass '__main__.SVDPP'\u003e iteration 68: loss = 1513.9640, delta_loss = 21.48012 learning_Rate = 0.01000 rmse=1.16745 mae=0.88339\n","\u003cclass '__main__.SVDPP'\u003e iteration 69: loss = 1492.8825, delta_loss = 21.08153 learning_Rate = 0.01000 rmse=1.16798 mae=0.88379\n","\u003cclass '__main__.SVDPP'\u003e iteration 70: loss = 1472.1898, delta_loss = 20.69265 learning_Rate = 0.01000 rmse=1.16851 mae=0.88418\n","\u003cclass '__main__.SVDPP'\u003e iteration 71: loss = 1451.8768, delta_loss = 20.31300 learning_Rate = 0.01000 rmse=1.16905 mae=0.88457\n","\u003cclass '__main__.SVDPP'\u003e iteration 72: loss = 1431.9347, delta_loss = 19.94213 learning_Rate = 0.01000 rmse=1.16960 mae=0.88496\n","\u003cclass '__main__.SVDPP'\u003e iteration 73: loss = 1412.3550, delta_loss = 19.57967 learning_Rate = 0.01000 rmse=1.17015 mae=0.88535\n","\u003cclass '__main__.SVDPP'\u003e iteration 74: loss = 1393.1297, delta_loss = 19.22528 learning_Rate = 0.01000 rmse=1.17071 mae=0.88575\n","\u003cclass '__main__.SVDPP'\u003e iteration 75: loss = 1374.2511, delta_loss = 18.87865 learning_Rate = 0.01000 rmse=1.17127 mae=0.88615\n","\u003cclass '__main__.SVDPP'\u003e iteration 76: loss = 1355.7116, delta_loss = 18.53953 learning_Rate = 0.01000 rmse=1.17183 mae=0.88655\n","\u003cclass '__main__.SVDPP'\u003e iteration 77: loss = 1337.5039, delta_loss = 18.20768 learning_Rate = 0.01000 rmse=1.17239 mae=0.88695\n","\u003cclass '__main__.SVDPP'\u003e iteration 78: loss = 1319.6210, delta_loss = 17.88287 learning_Rate = 0.01000 rmse=1.17295 mae=0.88735\n","\u003cclass '__main__.SVDPP'\u003e iteration 79: loss = 1302.0561, delta_loss = 17.56493 learning_Rate = 0.01000 rmse=1.17352 mae=0.88776\n","\u003cclass '__main__.SVDPP'\u003e iteration 80: loss = 1284.8024, delta_loss = 17.25366 learning_Rate = 0.01000 rmse=1.17409 mae=0.88818\n","\u003cclass '__main__.SVDPP'\u003e iteration 81: loss = 1267.8535, delta_loss = 16.94890 learning_Rate = 0.01000 rmse=1.17465 mae=0.88860\n","\u003cclass '__main__.SVDPP'\u003e iteration 82: loss = 1251.2030, delta_loss = 16.65051 learning_Rate = 0.01000 rmse=1.17523 mae=0.88902\n","\u003cclass '__main__.SVDPP'\u003e iteration 83: loss = 1234.8447, delta_loss = 16.35833 learning_Rate = 0.01000 rmse=1.17580 mae=0.88944\n","\u003cclass '__main__.SVDPP'\u003e iteration 84: loss = 1218.7724, delta_loss = 16.07223 learning_Rate = 0.01000 rmse=1.17637 mae=0.88985\n","\u003cclass '__main__.SVDPP'\u003e iteration 85: loss = 1202.9804, delta_loss = 15.79207 learning_Rate = 0.01000 rmse=1.17693 mae=0.89027\n","\u003cclass '__main__.SVDPP'\u003e iteration 86: loss = 1187.4627, delta_loss = 15.51772 learning_Rate = 0.01000 rmse=1.17749 mae=0.89067\n","\u003cclass '__main__.SVDPP'\u003e iteration 87: loss = 1172.2136, delta_loss = 15.24905 learning_Rate = 0.01000 rmse=1.17804 mae=0.89108\n","\u003cclass '__main__.SVDPP'\u003e iteration 88: loss = 1157.2277, delta_loss = 14.98594 learning_Rate = 0.01000 rmse=1.17860 mae=0.89149\n","\u003cclass '__main__.SVDPP'\u003e iteration 89: loss = 1142.4994, delta_loss = 14.72826 learning_Rate = 0.01000 rmse=1.17915 mae=0.89191\n","\u003cclass '__main__.SVDPP'\u003e iteration 90: loss = 1128.0235, delta_loss = 14.47589 learning_Rate = 0.01000 rmse=1.17971 mae=0.89233\n","\u003cclass '__main__.SVDPP'\u003e iteration 91: loss = 1113.7948, delta_loss = 14.22872 learning_Rate = 0.01000 rmse=1.18026 mae=0.89275\n","\u003cclass '__main__.SVDPP'\u003e iteration 92: loss = 1099.8082, delta_loss = 13.98661 learning_Rate = 0.01000 rmse=1.18082 mae=0.89316\n","\u003cclass '__main__.SVDPP'\u003e iteration 93: loss = 1086.0587, delta_loss = 13.74947 learning_Rate = 0.01000 rmse=1.18138 mae=0.89358\n","\u003cclass '__main__.SVDPP'\u003e iteration 94: loss = 1072.5416, delta_loss = 13.51716 learning_Rate = 0.01000 rmse=1.18194 mae=0.89400\n","\u003cclass '__main__.SVDPP'\u003e iteration 95: loss = 1059.2520, delta_loss = 13.28958 learning_Rate = 0.01000 rmse=1.18249 mae=0.89441\n","\u003cclass '__main__.SVDPP'\u003e iteration 96: loss = 1046.1854, delta_loss = 13.06662 learning_Rate = 0.01000 rmse=1.18304 mae=0.89481\n","\u003cclass '__main__.SVDPP'\u003e iteration 97: loss = 1033.3372, delta_loss = 12.84816 learning_Rate = 0.01000 rmse=1.18359 mae=0.89522\n","\u003cclass '__main__.SVDPP'\u003e iteration 98: loss = 1020.7031, delta_loss = 12.63410 learning_Rate = 0.01000 rmse=1.18414 mae=0.89562\n","\u003cclass '__main__.SVDPP'\u003e iteration 99: loss = 1008.2788, delta_loss = 12.42433 learning_Rate = 0.01000 rmse=1.18468 mae=0.89601\n","\u003cclass '__main__.SVDPP'\u003e iteration 100: loss = 996.0600, delta_loss = 12.21875 learning_Rate = 0.01000 rmse=1.18521 mae=0.89640\n","the 1th cross validation training\n","\u003cclass '__main__.SVDPP'\u003e iteration 1: loss = 90088.4536, delta_loss = -90088.45359 learning_Rate = 0.01000 rmse=1.47989 mae=1.06047\n","\u003cclass '__main__.SVDPP'\u003e iteration 2: loss = 28742.5393, delta_loss = 61345.91433 learning_Rate = 0.01000 rmse=1.39311 mae=1.01713\n","\u003cclass '__main__.SVDPP'\u003e iteration 3: loss = 16145.4294, delta_loss = 12597.10991 learning_Rate = 0.01000 rmse=1.32797 mae=0.97829\n","\u003cclass '__main__.SVDPP'\u003e iteration 4: loss = 12226.2553, delta_loss = 3919.17407 learning_Rate = 0.01000 rmse=1.28817 mae=0.95427\n","\u003cclass '__main__.SVDPP'\u003e iteration 5: loss = 10051.4068, delta_loss = 2174.84851 learning_Rate = 0.01000 rmse=1.26118 mae=0.93735\n","\u003cclass '__main__.SVDPP'\u003e iteration 6: loss = 8633.8913, delta_loss = 1417.51545 learning_Rate = 0.01000 rmse=1.24267 mae=0.92543\n","\u003cclass '__main__.SVDPP'\u003e iteration 7: loss = 7627.4788, delta_loss = 1006.41256 learning_Rate = 0.01000 rmse=1.22854 mae=0.91608\n","\u003cclass '__main__.SVDPP'\u003e iteration 8: loss = 6872.6190, delta_loss = 754.85981 learning_Rate = 0.01000 rmse=1.21762 mae=0.90882\n","\u003cclass '__main__.SVDPP'\u003e iteration 9: loss = 6283.9747, delta_loss = 588.64426 learning_Rate = 0.01000 rmse=1.20898 mae=0.90317\n","\u003cclass '__main__.SVDPP'\u003e iteration 10: loss = 5811.2498, delta_loss = 472.72488 learning_Rate = 0.01000 rmse=1.20201 mae=0.89884\n","\u003cclass '__main__.SVDPP'\u003e iteration 11: loss = 5422.6827, delta_loss = 388.56715 learning_Rate = 0.01000 rmse=1.19613 mae=0.89518\n","\u003cclass '__main__.SVDPP'\u003e iteration 12: loss = 5097.1641, delta_loss = 325.51853 learning_Rate = 0.01000 rmse=1.19126 mae=0.89214\n","\u003cclass '__main__.SVDPP'\u003e iteration 13: loss = 4820.1046, delta_loss = 277.05956 learning_Rate = 0.01000 rmse=1.18726 mae=0.88965\n","\u003cclass '__main__.SVDPP'\u003e iteration 14: loss = 4581.0972, delta_loss = 239.00743 learning_Rate = 0.01000 rmse=1.18371 mae=0.88746\n","\u003cclass '__main__.SVDPP'\u003e iteration 15: loss = 4372.5174, delta_loss = 208.57976 learning_Rate = 0.01000 rmse=1.18055 mae=0.88546\n","\u003cclass '__main__.SVDPP'\u003e iteration 16: loss = 4188.6475, delta_loss = 183.86994 learning_Rate = 0.01000 rmse=1.17767 mae=0.88372\n","\u003cclass '__main__.SVDPP'\u003e iteration 17: loss = 4025.1107, delta_loss = 163.53681 learning_Rate = 0.01000 rmse=1.17512 mae=0.88222\n","\u003cclass '__main__.SVDPP'\u003e iteration 18: loss = 3878.4962, delta_loss = 146.61446 learning_Rate = 0.01000 rmse=1.17287 mae=0.88084\n","\u003cclass '__main__.SVDPP'\u003e iteration 19: loss = 3746.1039, delta_loss = 132.39224 learning_Rate = 0.01000 rmse=1.17091 mae=0.87951\n","\u003cclass '__main__.SVDPP'\u003e iteration 20: loss = 3625.7666, delta_loss = 120.33733 learning_Rate = 0.01000 rmse=1.16925 mae=0.87838\n","\u003cclass '__main__.SVDPP'\u003e iteration 21: loss = 3515.7233, delta_loss = 110.04330 learning_Rate = 0.01000 rmse=1.16782 mae=0.87742\n","\u003cclass '__main__.SVDPP'\u003e iteration 22: loss = 3414.5281, delta_loss = 101.19523 learning_Rate = 0.01000 rmse=1.16661 mae=0.87655\n","\u003cclass '__main__.SVDPP'\u003e iteration 23: loss = 3320.9825, delta_loss = 93.54561 learning_Rate = 0.01000 rmse=1.16557 mae=0.87575\n","\u003cclass '__main__.SVDPP'\u003e iteration 24: loss = 3234.0852, delta_loss = 86.89728 learning_Rate = 0.01000 rmse=1.16461 mae=0.87501\n","\u003cclass '__main__.SVDPP'\u003e iteration 25: loss = 3152.9939, delta_loss = 81.09134 learning_Rate = 0.01000 rmse=1.16370 mae=0.87431\n","\u003cclass '__main__.SVDPP'\u003e iteration 26: loss = 3076.9956, delta_loss = 75.99830 learning_Rate = 0.01000 rmse=1.16288 mae=0.87369\n","\u003cclass '__main__.SVDPP'\u003e iteration 27: loss = 3005.4840, delta_loss = 71.51158 learning_Rate = 0.01000 rmse=1.16218 mae=0.87316\n","\u003cclass '__main__.SVDPP'\u003e iteration 28: loss = 2937.9413, delta_loss = 67.54273 learning_Rate = 0.01000 rmse=1.16164 mae=0.87277\n","\u003cclass '__main__.SVDPP'\u003e iteration 29: loss = 2873.9236, delta_loss = 64.01769 learning_Rate = 0.01000 rmse=1.16123 mae=0.87250\n","\u003cclass '__main__.SVDPP'\u003e iteration 30: loss = 2813.0495, delta_loss = 60.87408 learning_Rate = 0.01000 rmse=1.16093 mae=0.87231\n","\u003cclass '__main__.SVDPP'\u003e iteration 31: loss = 2754.9905, delta_loss = 58.05896 learning_Rate = 0.01000 rmse=1.16073 mae=0.87214\n","\u003cclass '__main__.SVDPP'\u003e iteration 32: loss = 2699.4633, delta_loss = 55.52723 learning_Rate = 0.01000 rmse=1.16062 mae=0.87200\n","\u003cclass '__main__.SVDPP'\u003e iteration 33: loss = 2646.2230, delta_loss = 53.24030 learning_Rate = 0.01000 rmse=1.16059 mae=0.87191\n","\u003cclass '__main__.SVDPP'\u003e iteration 34: loss = 2595.0579, delta_loss = 51.16504 learning_Rate = 0.01000 rmse=1.16061 mae=0.87187\n","\u003cclass '__main__.SVDPP'\u003e iteration 35: loss = 2545.7850, delta_loss = 49.27299 learning_Rate = 0.01000 rmse=1.16068 mae=0.87190\n","\u003cclass '__main__.SVDPP'\u003e iteration 36: loss = 2498.2453, delta_loss = 47.53966 learning_Rate = 0.01000 rmse=1.16075 mae=0.87197\n","\u003cclass '__main__.SVDPP'\u003e iteration 37: loss = 2452.3013, delta_loss = 45.94401 learning_Rate = 0.01000 rmse=1.16088 mae=0.87211\n","\u003cclass '__main__.SVDPP'\u003e iteration 38: loss = 2407.8333, delta_loss = 44.46801 learning_Rate = 0.01000 rmse=1.16106 mae=0.87227\n","\u003cclass '__main__.SVDPP'\u003e iteration 39: loss = 2364.7371, delta_loss = 43.09618 learning_Rate = 0.01000 rmse=1.16133 mae=0.87247\n","\u003cclass '__main__.SVDPP'\u003e iteration 40: loss = 2322.9218, delta_loss = 41.81532 learning_Rate = 0.01000 rmse=1.16163 mae=0.87268\n","\u003cclass '__main__.SVDPP'\u003e iteration 41: loss = 2282.3076, delta_loss = 40.61418 learning_Rate = 0.01000 rmse=1.16200 mae=0.87292\n","\u003cclass '__main__.SVDPP'\u003e iteration 42: loss = 2242.8244, delta_loss = 39.48318 learning_Rate = 0.01000 rmse=1.16235 mae=0.87316\n","\u003cclass '__main__.SVDPP'\u003e iteration 43: loss = 2204.4102, delta_loss = 38.41419 learning_Rate = 0.01000 rmse=1.16273 mae=0.87341\n","\u003cclass '__main__.SVDPP'\u003e iteration 44: loss = 2167.0099, delta_loss = 37.40031 learning_Rate = 0.01000 rmse=1.16311 mae=0.87368\n","\u003cclass '__main__.SVDPP'\u003e iteration 45: loss = 2130.5742, delta_loss = 36.43568 learning_Rate = 0.01000 rmse=1.16354 mae=0.87396\n","\u003cclass '__main__.SVDPP'\u003e iteration 46: loss = 2095.0589, delta_loss = 35.51534 learning_Rate = 0.01000 rmse=1.16398 mae=0.87425\n","\u003cclass '__main__.SVDPP'\u003e iteration 47: loss = 2060.4239, delta_loss = 34.63503 learning_Rate = 0.01000 rmse=1.16445 mae=0.87456\n","\u003cclass '__main__.SVDPP'\u003e iteration 48: loss = 2026.6327, delta_loss = 33.79115 learning_Rate = 0.01000 rmse=1.16495 mae=0.87489\n","\u003cclass '__main__.SVDPP'\u003e iteration 49: loss = 1993.6521, delta_loss = 32.98058 learning_Rate = 0.01000 rmse=1.16546 mae=0.87523\n","\u003cclass '__main__.SVDPP'\u003e iteration 50: loss = 1961.4515, delta_loss = 32.20065 learning_Rate = 0.01000 rmse=1.16597 mae=0.87558\n","\u003cclass '__main__.SVDPP'\u003e iteration 51: loss = 1930.0024, delta_loss = 31.44905 learning_Rate = 0.01000 rmse=1.16649 mae=0.87593\n","\u003cclass '__main__.SVDPP'\u003e iteration 52: loss = 1899.2787, delta_loss = 30.72376 learning_Rate = 0.01000 rmse=1.16703 mae=0.87630\n","\u003cclass '__main__.SVDPP'\u003e iteration 53: loss = 1869.2557, delta_loss = 30.02301 learning_Rate = 0.01000 rmse=1.16758 mae=0.87669\n","\u003cclass '__main__.SVDPP'\u003e iteration 54: loss = 1839.9104, delta_loss = 29.34526 learning_Rate = 0.01000 rmse=1.16816 mae=0.87710\n","\u003cclass '__main__.SVDPP'\u003e iteration 55: loss = 1811.2213, delta_loss = 28.68915 learning_Rate = 0.01000 rmse=1.16874 mae=0.87750\n","\u003cclass '__main__.SVDPP'\u003e iteration 56: loss = 1783.1678, delta_loss = 28.05344 learning_Rate = 0.01000 rmse=1.16934 mae=0.87792\n","\u003cclass '__main__.SVDPP'\u003e iteration 57: loss = 1755.7307, delta_loss = 27.43706 learning_Rate = 0.01000 rmse=1.16994 mae=0.87834\n","\u003cclass '__main__.SVDPP'\u003e iteration 58: loss = 1728.8917, delta_loss = 26.83904 learning_Rate = 0.01000 rmse=1.17054 mae=0.87876\n","\u003cclass '__main__.SVDPP'\u003e iteration 59: loss = 1702.6332, delta_loss = 26.25847 learning_Rate = 0.01000 rmse=1.17115 mae=0.87919\n","\u003cclass '__main__.SVDPP'\u003e iteration 60: loss = 1676.9387, delta_loss = 25.69457 learning_Rate = 0.01000 rmse=1.17176 mae=0.87961\n","\u003cclass '__main__.SVDPP'\u003e iteration 61: loss = 1651.7921, delta_loss = 25.14661 learning_Rate = 0.01000 rmse=1.17238 mae=0.88003\n","\u003cclass '__main__.SVDPP'\u003e iteration 62: loss = 1627.1782, delta_loss = 24.61390 learning_Rate = 0.01000 rmse=1.17300 mae=0.88045\n","\u003cclass '__main__.SVDPP'\u003e iteration 63: loss = 1603.0823, delta_loss = 24.09583 learning_Rate = 0.01000 rmse=1.17362 mae=0.88087\n","\u003cclass '__main__.SVDPP'\u003e iteration 64: loss = 1579.4905, delta_loss = 23.59182 learning_Rate = 0.01000 rmse=1.17424 mae=0.88128\n","\u003cclass '__main__.SVDPP'\u003e iteration 65: loss = 1556.3892, delta_loss = 23.10135 learning_Rate = 0.01000 rmse=1.17486 mae=0.88169\n","\u003cclass '__main__.SVDPP'\u003e iteration 66: loss = 1533.7653, delta_loss = 22.62389 learning_Rate = 0.01000 rmse=1.17549 mae=0.88210\n","\u003cclass '__main__.SVDPP'\u003e iteration 67: loss = 1511.6063, delta_loss = 22.15900 learning_Rate = 0.01000 rmse=1.17611 mae=0.88251\n","\u003cclass '__main__.SVDPP'\u003e iteration 68: loss = 1489.9000, delta_loss = 21.70622 learning_Rate = 0.01000 rmse=1.17675 mae=0.88294\n","\u003cclass '__main__.SVDPP'\u003e iteration 69: loss = 1468.6349, delta_loss = 21.26514 learning_Rate = 0.01000 rmse=1.17738 mae=0.88337\n","\u003cclass '__main__.SVDPP'\u003e iteration 70: loss = 1447.7995, delta_loss = 20.83537 learning_Rate = 0.01000 rmse=1.17801 mae=0.88381\n","\u003cclass '__main__.SVDPP'\u003e iteration 71: loss = 1427.3830, delta_loss = 20.41653 learning_Rate = 0.01000 rmse=1.17864 mae=0.88424\n","\u003cclass '__main__.SVDPP'\u003e iteration 72: loss = 1407.3747, delta_loss = 20.00828 learning_Rate = 0.01000 rmse=1.17927 mae=0.88467\n","\u003cclass '__main__.SVDPP'\u003e iteration 73: loss = 1387.7644, delta_loss = 19.61027 learning_Rate = 0.01000 rmse=1.17990 mae=0.88511\n","\u003cclass '__main__.SVDPP'\u003e iteration 74: loss = 1368.5423, delta_loss = 19.22220 learning_Rate = 0.01000 rmse=1.18053 mae=0.88554\n","\u003cclass '__main__.SVDPP'\u003e iteration 75: loss = 1349.6985, delta_loss = 18.84375 learning_Rate = 0.01000 rmse=1.18116 mae=0.88597\n","\u003cclass '__main__.SVDPP'\u003e iteration 76: loss = 1331.2239, delta_loss = 18.47463 learning_Rate = 0.01000 rmse=1.18179 mae=0.88641\n","\u003cclass '__main__.SVDPP'\u003e iteration 77: loss = 1313.1093, delta_loss = 18.11458 learning_Rate = 0.01000 rmse=1.18241 mae=0.88684\n","\u003cclass '__main__.SVDPP'\u003e iteration 78: loss = 1295.3460, delta_loss = 17.76333 learning_Rate = 0.01000 rmse=1.18303 mae=0.88726\n","\u003cclass '__main__.SVDPP'\u003e iteration 79: loss = 1277.9253, delta_loss = 17.42063 learning_Rate = 0.01000 rmse=1.18364 mae=0.88769\n","\u003cclass '__main__.SVDPP'\u003e iteration 80: loss = 1260.8391, delta_loss = 17.08623 learning_Rate = 0.01000 rmse=1.18426 mae=0.88812\n","\u003cclass '__main__.SVDPP'\u003e iteration 81: loss = 1244.0792, delta_loss = 16.75990 learning_Rate = 0.01000 rmse=1.18487 mae=0.88854\n","\u003cclass '__main__.SVDPP'\u003e iteration 82: loss = 1227.6378, delta_loss = 16.44142 learning_Rate = 0.01000 rmse=1.18548 mae=0.88896\n","\u003cclass '__main__.SVDPP'\u003e iteration 83: loss = 1211.5072, delta_loss = 16.13058 learning_Rate = 0.01000 rmse=1.18609 mae=0.88938\n","\u003cclass '__main__.SVDPP'\u003e iteration 84: loss = 1195.6800, delta_loss = 15.82716 learning_Rate = 0.01000 rmse=1.18669 mae=0.88981\n","\u003cclass '__main__.SVDPP'\u003e iteration 85: loss = 1180.1491, delta_loss = 15.53098 learning_Rate = 0.01000 rmse=1.18730 mae=0.89023\n","\u003cclass '__main__.SVDPP'\u003e iteration 86: loss = 1164.9072, delta_loss = 15.24183 learning_Rate = 0.01000 rmse=1.18791 mae=0.89066\n","\u003cclass '__main__.SVDPP'\u003e iteration 87: loss = 1149.9477, delta_loss = 14.95953 learning_Rate = 0.01000 rmse=1.18851 mae=0.89109\n","\u003cclass '__main__.SVDPP'\u003e iteration 88: loss = 1135.2638, delta_loss = 14.68390 learning_Rate = 0.01000 rmse=1.18912 mae=0.89151\n","\u003cclass '__main__.SVDPP'\u003e iteration 89: loss = 1120.8490, delta_loss = 14.41477 learning_Rate = 0.01000 rmse=1.18972 mae=0.89193\n","\u003cclass '__main__.SVDPP'\u003e iteration 90: loss = 1106.6971, delta_loss = 14.15196 learning_Rate = 0.01000 rmse=1.19032 mae=0.89234\n","\u003cclass '__main__.SVDPP'\u003e iteration 91: loss = 1092.8018, delta_loss = 13.89531 learning_Rate = 0.01000 rmse=1.19092 mae=0.89275\n","\u003cclass '__main__.SVDPP'\u003e iteration 92: loss = 1079.1571, delta_loss = 13.64465 learning_Rate = 0.01000 rmse=1.19153 mae=0.89316\n","\u003cclass '__main__.SVDPP'\u003e iteration 93: loss = 1065.7573, delta_loss = 13.39983 learning_Rate = 0.01000 rmse=1.19212 mae=0.89357\n","\u003cclass '__main__.SVDPP'\u003e iteration 94: loss = 1052.5966, delta_loss = 13.16070 learning_Rate = 0.01000 rmse=1.19272 mae=0.89398\n","\u003cclass '__main__.SVDPP'\u003e iteration 95: loss = 1039.6695, delta_loss = 12.92710 learning_Rate = 0.01000 rmse=1.19332 mae=0.89438\n","\u003cclass '__main__.SVDPP'\u003e iteration 96: loss = 1026.9706, delta_loss = 12.69890 learning_Rate = 0.01000 rmse=1.19391 mae=0.89477\n","\u003cclass '__main__.SVDPP'\u003e iteration 97: loss = 1014.4946, delta_loss = 12.47595 learning_Rate = 0.01000 rmse=1.19450 mae=0.89516\n","\u003cclass '__main__.SVDPP'\u003e iteration 98: loss = 1002.2365, delta_loss = 12.25810 learning_Rate = 0.01000 rmse=1.19507 mae=0.89555\n","\u003cclass '__main__.SVDPP'\u003e iteration 99: loss = 990.1913, delta_loss = 12.04523 learning_Rate = 0.01000 rmse=1.19564 mae=0.89593\n","\u003cclass '__main__.SVDPP'\u003e iteration 100: loss = 978.3541, delta_loss = 11.83720 learning_Rate = 0.01000 rmse=1.19621 mae=0.89631\n","the 2th cross validation training\n","\u003cclass '__main__.SVDPP'\u003e iteration 1: loss = 91342.4675, delta_loss = -91342.46753 learning_Rate = 0.01000 rmse=1.47394 mae=1.06522\n","\u003cclass '__main__.SVDPP'\u003e iteration 2: loss = 29283.3498, delta_loss = 62059.11772 learning_Rate = 0.01000 rmse=1.40162 mae=1.02833\n","\u003cclass '__main__.SVDPP'\u003e iteration 3: loss = 16237.4923, delta_loss = 13045.85749 learning_Rate = 0.01000 rmse=1.32717 mae=0.98728\n","\u003cclass '__main__.SVDPP'\u003e iteration 4: loss = 12282.6896, delta_loss = 3954.80274 learning_Rate = 0.01000 rmse=1.27465 mae=0.95772\n","\u003cclass '__main__.SVDPP'\u003e iteration 5: loss = 10097.1267, delta_loss = 2185.56290 learning_Rate = 0.01000 rmse=1.23653 mae=0.93591\n","\u003cclass '__main__.SVDPP'\u003e iteration 6: loss = 8675.5559, delta_loss = 1421.57081 learning_Rate = 0.01000 rmse=1.21057 mae=0.92064\n","\u003cclass '__main__.SVDPP'\u003e iteration 7: loss = 7667.3111, delta_loss = 1008.24475 learning_Rate = 0.01000 rmse=1.19282 mae=0.90970\n","\u003cclass '__main__.SVDPP'\u003e iteration 8: loss = 6911.2606, delta_loss = 756.05051 learning_Rate = 0.01000 rmse=1.18015 mae=0.90156\n","\u003cclass '__main__.SVDPP'\u003e iteration 9: loss = 6321.5828, delta_loss = 589.67779 learning_Rate = 0.01000 rmse=1.17049 mae=0.89513\n","\u003cclass '__main__.SVDPP'\u003e iteration 10: loss = 5847.9007, delta_loss = 473.68209 learning_Rate = 0.01000 rmse=1.16287 mae=0.88990\n","\u003cclass '__main__.SVDPP'\u003e iteration 11: loss = 5458.4698, delta_loss = 389.43089 learning_Rate = 0.01000 rmse=1.15683 mae=0.88595\n","\u003cclass '__main__.SVDPP'\u003e iteration 12: loss = 5132.2017, delta_loss = 326.26809 learning_Rate = 0.01000 rmse=1.15208 mae=0.88286\n","\u003cclass '__main__.SVDPP'\u003e iteration 13: loss = 4854.5154, delta_loss = 277.68638 learning_Rate = 0.01000 rmse=1.14793 mae=0.88018\n","\u003cclass '__main__.SVDPP'\u003e iteration 14: loss = 4615.0019, delta_loss = 239.51341 learning_Rate = 0.01000 rmse=1.14437 mae=0.87808\n","\u003cclass '__main__.SVDPP'\u003e iteration 15: loss = 4406.0278, delta_loss = 208.97418 learning_Rate = 0.01000 rmse=1.14155 mae=0.87631\n","\u003cclass '__main__.SVDPP'\u003e iteration 16: loss = 4221.8610, delta_loss = 184.16675 learning_Rate = 0.01000 rmse=1.13928 mae=0.87473\n","\u003cclass '__main__.SVDPP'\u003e iteration 17: loss = 4058.1088, delta_loss = 163.75224 learning_Rate = 0.01000 rmse=1.13717 mae=0.87327\n","\u003cclass '__main__.SVDPP'\u003e iteration 18: loss = 3911.3437, delta_loss = 146.76503 learning_Rate = 0.01000 rmse=1.13544 mae=0.87208\n","\u003cclass '__main__.SVDPP'\u003e iteration 19: loss = 3778.8503, delta_loss = 132.49346 learning_Rate = 0.01000 rmse=1.13404 mae=0.87107\n","\u003cclass '__main__.SVDPP'\u003e iteration 20: loss = 3658.4474, delta_loss = 120.40292 learning_Rate = 0.01000 rmse=1.13296 mae=0.87025\n","\u003cclass '__main__.SVDPP'\u003e iteration 21: loss = 3548.3625, delta_loss = 110.08486 learning_Rate = 0.01000 rmse=1.13214 mae=0.86954\n","\u003cclass '__main__.SVDPP'\u003e iteration 22: loss = 3447.1403, delta_loss = 101.22222 learning_Rate = 0.01000 rmse=1.13152 mae=0.86896\n","\u003cclass '__main__.SVDPP'\u003e iteration 23: loss = 3353.5747, delta_loss = 93.56554 learning_Rate = 0.01000 rmse=1.13106 mae=0.86850\n","\u003cclass '__main__.SVDPP'\u003e iteration 24: loss = 3266.6587, delta_loss = 86.91600 learning_Rate = 0.01000 rmse=1.13066 mae=0.86810\n","\u003cclass '__main__.SVDPP'\u003e iteration 25: loss = 3185.5454, delta_loss = 81.11338 learning_Rate = 0.01000 rmse=1.13035 mae=0.86779\n","\u003cclass '__main__.SVDPP'\u003e iteration 26: loss = 3109.5182, delta_loss = 76.02716 learning_Rate = 0.01000 rmse=1.13004 mae=0.86751\n","\u003cclass '__main__.SVDPP'\u003e iteration 27: loss = 3037.9682, delta_loss = 71.55000 learning_Rate = 0.01000 rmse=1.12962 mae=0.86718\n","\u003cclass '__main__.SVDPP'\u003e iteration 28: loss = 2970.3754, delta_loss = 67.59282 learning_Rate = 0.01000 rmse=1.12921 mae=0.86684\n","\u003cclass '__main__.SVDPP'\u003e iteration 29: loss = 2906.2943, delta_loss = 64.08107 learning_Rate = 0.01000 rmse=1.12884 mae=0.86651\n","\u003cclass '__main__.SVDPP'\u003e iteration 30: loss = 2845.3424, delta_loss = 60.95186 learning_Rate = 0.01000 rmse=1.12848 mae=0.86621\n","\u003cclass '__main__.SVDPP'\u003e iteration 31: loss = 2787.1906, delta_loss = 58.15184 learning_Rate = 0.01000 rmse=1.12820 mae=0.86594\n","\u003cclass '__main__.SVDPP'\u003e iteration 32: loss = 2731.5552, delta_loss = 55.63541 learning_Rate = 0.01000 rmse=1.12798 mae=0.86572\n","\u003cclass '__main__.SVDPP'\u003e iteration 33: loss = 2678.1917, delta_loss = 53.36349 learning_Rate = 0.01000 rmse=1.12783 mae=0.86557\n","\u003cclass '__main__.SVDPP'\u003e iteration 34: loss = 2626.8893, delta_loss = 51.30242 learning_Rate = 0.01000 rmse=1.12770 mae=0.86547\n","\u003cclass '__main__.SVDPP'\u003e iteration 35: loss = 2577.4660, delta_loss = 49.42323 learning_Rate = 0.01000 rmse=1.12756 mae=0.86541\n","\u003cclass '__main__.SVDPP'\u003e iteration 36: loss = 2529.7651, delta_loss = 47.70092 learning_Rate = 0.01000 rmse=1.12746 mae=0.86536\n","\u003cclass '__main__.SVDPP'\u003e iteration 37: loss = 2483.6511, delta_loss = 46.11402 learning_Rate = 0.01000 rmse=1.12737 mae=0.86532\n","\u003cclass '__main__.SVDPP'\u003e iteration 38: loss = 2439.0070, delta_loss = 44.64411 learning_Rate = 0.01000 rmse=1.12735 mae=0.86531\n","\u003cclass '__main__.SVDPP'\u003e iteration 39: loss = 2395.7315, delta_loss = 43.27550 learning_Rate = 0.01000 rmse=1.12738 mae=0.86532\n","\u003cclass '__main__.SVDPP'\u003e iteration 40: loss = 2353.7366, delta_loss = 41.99487 learning_Rate = 0.01000 rmse=1.12744 mae=0.86533\n","\u003cclass '__main__.SVDPP'\u003e iteration 41: loss = 2312.9456, delta_loss = 40.79102 learning_Rate = 0.01000 rmse=1.12754 mae=0.86537\n","\u003cclass '__main__.SVDPP'\u003e iteration 42: loss = 2273.2910, delta_loss = 39.65457 learning_Rate = 0.01000 rmse=1.12769 mae=0.86543\n","\u003cclass '__main__.SVDPP'\u003e iteration 43: loss = 2234.7133, delta_loss = 38.57773 learning_Rate = 0.01000 rmse=1.12785 mae=0.86550\n","\u003cclass '__main__.SVDPP'\u003e iteration 44: loss = 2197.1593, delta_loss = 37.55405 learning_Rate = 0.01000 rmse=1.12804 mae=0.86563\n","\u003cclass '__main__.SVDPP'\u003e iteration 45: loss = 2160.5811, delta_loss = 36.57819 learning_Rate = 0.01000 rmse=1.12827 mae=0.86577\n","\u003cclass '__main__.SVDPP'\u003e iteration 46: loss = 2124.9353, delta_loss = 35.64573 learning_Rate = 0.01000 rmse=1.12851 mae=0.86593\n","\u003cclass '__main__.SVDPP'\u003e iteration 47: loss = 2090.1824, delta_loss = 34.75297 learning_Rate = 0.01000 rmse=1.12875 mae=0.86609\n","\u003cclass '__main__.SVDPP'\u003e iteration 48: loss = 2056.2856, delta_loss = 33.89681 learning_Rate = 0.01000 rmse=1.12899 mae=0.86624\n","\u003cclass '__main__.SVDPP'\u003e iteration 49: loss = 2023.2110, delta_loss = 33.07459 learning_Rate = 0.01000 rmse=1.12927 mae=0.86643\n","\u003cclass '__main__.SVDPP'\u003e iteration 50: loss = 1990.9270, delta_loss = 32.28400 learning_Rate = 0.01000 rmse=1.12955 mae=0.86662\n","\u003cclass '__main__.SVDPP'\u003e iteration 51: loss = 1959.4039, delta_loss = 31.52303 learning_Rate = 0.01000 rmse=1.12986 mae=0.86683\n","\u003cclass '__main__.SVDPP'\u003e iteration 52: loss = 1928.6141, delta_loss = 30.78986 learning_Rate = 0.01000 rmse=1.13018 mae=0.86705\n","\u003cclass '__main__.SVDPP'\u003e iteration 53: loss = 1898.5312, delta_loss = 30.08286 learning_Rate = 0.01000 rmse=1.13052 mae=0.86727\n","\u003cclass '__main__.SVDPP'\u003e iteration 54: loss = 1869.1307, delta_loss = 29.40055 learning_Rate = 0.01000 rmse=1.13086 mae=0.86749\n","\u003cclass '__main__.SVDPP'\u003e iteration 55: loss = 1840.3891, delta_loss = 28.74158 learning_Rate = 0.01000 rmse=1.13120 mae=0.86772\n","\u003cclass '__main__.SVDPP'\u003e iteration 56: loss = 1812.2844, delta_loss = 28.10472 learning_Rate = 0.01000 rmse=1.13154 mae=0.86796\n","\u003cclass '__main__.SVDPP'\u003e iteration 57: loss = 1784.7956, delta_loss = 27.48882 learning_Rate = 0.01000 rmse=1.13189 mae=0.86820\n","\u003cclass '__main__.SVDPP'\u003e iteration 58: loss = 1757.9027, delta_loss = 26.89284 learning_Rate = 0.01000 rmse=1.13226 mae=0.86845\n","\u003cclass '__main__.SVDPP'\u003e iteration 59: loss = 1731.5869, delta_loss = 26.31581 learning_Rate = 0.01000 rmse=1.13264 mae=0.86870\n","\u003cclass '__main__.SVDPP'\u003e iteration 60: loss = 1705.8301, delta_loss = 25.75685 learning_Rate = 0.01000 rmse=1.13303 mae=0.86896\n","\u003cclass '__main__.SVDPP'\u003e iteration 61: loss = 1680.6149, delta_loss = 25.21513 learning_Rate = 0.01000 rmse=1.13344 mae=0.86923\n","\u003cclass '__main__.SVDPP'\u003e iteration 62: loss = 1655.9250, delta_loss = 24.68988 learning_Rate = 0.01000 rmse=1.13387 mae=0.86950\n","\u003cclass '__main__.SVDPP'\u003e iteration 63: loss = 1631.7447, delta_loss = 24.18037 learning_Rate = 0.01000 rmse=1.13429 mae=0.86978\n","\u003cclass '__main__.SVDPP'\u003e iteration 64: loss = 1608.0587, delta_loss = 23.68594 learning_Rate = 0.01000 rmse=1.13471 mae=0.87006\n","\u003cclass '__main__.SVDPP'\u003e iteration 65: loss = 1584.8528, delta_loss = 23.20593 learning_Rate = 0.01000 rmse=1.13513 mae=0.87034\n","\u003cclass '__main__.SVDPP'\u003e iteration 66: loss = 1562.1131, delta_loss = 22.73974 learning_Rate = 0.01000 rmse=1.13555 mae=0.87061\n","\u003cclass '__main__.SVDPP'\u003e iteration 67: loss = 1539.8263, delta_loss = 22.28678 learning_Rate = 0.01000 rmse=1.13598 mae=0.87088\n","\u003cclass '__main__.SVDPP'\u003e iteration 68: loss = 1517.9798, delta_loss = 21.84652 learning_Rate = 0.01000 rmse=1.13641 mae=0.87116\n","\u003cclass '__main__.SVDPP'\u003e iteration 69: loss = 1496.5614, delta_loss = 21.41841 learning_Rate = 0.01000 rmse=1.13684 mae=0.87143\n","\u003cclass '__main__.SVDPP'\u003e iteration 70: loss = 1475.5594, delta_loss = 21.00195 learning_Rate = 0.01000 rmse=1.13727 mae=0.87170\n","\u003cclass '__main__.SVDPP'\u003e iteration 71: loss = 1454.9628, delta_loss = 20.59666 learning_Rate = 0.01000 rmse=1.13769 mae=0.87196\n","\u003cclass '__main__.SVDPP'\u003e iteration 72: loss = 1434.7607, delta_loss = 20.20208 learning_Rate = 0.01000 rmse=1.13811 mae=0.87222\n","\u003cclass '__main__.SVDPP'\u003e iteration 73: loss = 1414.9429, delta_loss = 19.81777 learning_Rate = 0.01000 rmse=1.13853 mae=0.87247\n","\u003cclass '__main__.SVDPP'\u003e iteration 74: loss = 1395.4996, delta_loss = 19.44331 learning_Rate = 0.01000 rmse=1.13895 mae=0.87273\n","\u003cclass '__main__.SVDPP'\u003e iteration 75: loss = 1376.4213, delta_loss = 19.07830 learning_Rate = 0.01000 rmse=1.13939 mae=0.87300\n","\u003cclass '__main__.SVDPP'\u003e iteration 76: loss = 1357.6989, delta_loss = 18.72237 learning_Rate = 0.01000 rmse=1.13982 mae=0.87326\n","\u003cclass '__main__.SVDPP'\u003e iteration 77: loss = 1339.3238, delta_loss = 18.37515 learning_Rate = 0.01000 rmse=1.14027 mae=0.87353\n","\u003cclass '__main__.SVDPP'\u003e iteration 78: loss = 1321.2874, delta_loss = 18.03632 learning_Rate = 0.01000 rmse=1.14072 mae=0.87380\n","\u003cclass '__main__.SVDPP'\u003e iteration 79: loss = 1303.5819, delta_loss = 17.70554 learning_Rate = 0.01000 rmse=1.14115 mae=0.87408\n","\u003cclass '__main__.SVDPP'\u003e iteration 80: loss = 1286.1994, delta_loss = 17.38252 learning_Rate = 0.01000 rmse=1.14159 mae=0.87436\n","\u003cclass '__main__.SVDPP'\u003e iteration 81: loss = 1269.1324, delta_loss = 17.06697 learning_Rate = 0.01000 rmse=1.14203 mae=0.87465\n","\u003cclass '__main__.SVDPP'\u003e iteration 82: loss = 1252.3738, delta_loss = 16.75863 learning_Rate = 0.01000 rmse=1.14247 mae=0.87496\n","\u003cclass '__main__.SVDPP'\u003e iteration 83: loss = 1235.9166, delta_loss = 16.45724 learning_Rate = 0.01000 rmse=1.14292 mae=0.87527\n","\u003cclass '__main__.SVDPP'\u003e iteration 84: loss = 1219.7540, delta_loss = 16.16257 learning_Rate = 0.01000 rmse=1.14336 mae=0.87558\n","\u003cclass '__main__.SVDPP'\u003e iteration 85: loss = 1203.8796, delta_loss = 15.87439 learning_Rate = 0.01000 rmse=1.14381 mae=0.87590\n","\u003cclass '__main__.SVDPP'\u003e iteration 86: loss = 1188.2871, delta_loss = 15.59249 learning_Rate = 0.01000 rmse=1.14426 mae=0.87621\n","\u003cclass '__main__.SVDPP'\u003e iteration 87: loss = 1172.9704, delta_loss = 15.31669 learning_Rate = 0.01000 rmse=1.14471 mae=0.87654\n","\u003cclass '__main__.SVDPP'\u003e iteration 88: loss = 1157.9236, delta_loss = 15.04678 learning_Rate = 0.01000 rmse=1.14517 mae=0.87685\n","\u003cclass '__main__.SVDPP'\u003e iteration 89: loss = 1143.1410, delta_loss = 14.78261 learning_Rate = 0.01000 rmse=1.14562 mae=0.87717\n","\u003cclass '__main__.SVDPP'\u003e iteration 90: loss = 1128.6170, delta_loss = 14.52399 learning_Rate = 0.01000 rmse=1.14607 mae=0.87749\n","\u003cclass '__main__.SVDPP'\u003e iteration 91: loss = 1114.3462, delta_loss = 14.27079 learning_Rate = 0.01000 rmse=1.14651 mae=0.87780\n","\u003cclass '__main__.SVDPP'\u003e iteration 92: loss = 1100.3234, delta_loss = 14.02284 learning_Rate = 0.01000 rmse=1.14696 mae=0.87813\n","\u003cclass '__main__.SVDPP'\u003e iteration 93: loss = 1086.5434, delta_loss = 13.78002 learning_Rate = 0.01000 rmse=1.14742 mae=0.87845\n","\u003cclass '__main__.SVDPP'\u003e iteration 94: loss = 1073.0012, delta_loss = 13.54219 learning_Rate = 0.01000 rmse=1.14787 mae=0.87878\n","\u003cclass '__main__.SVDPP'\u003e iteration 95: loss = 1059.6920, delta_loss = 13.30923 learning_Rate = 0.01000 rmse=1.14832 mae=0.87911\n","\u003cclass '__main__.SVDPP'\u003e iteration 96: loss = 1046.6110, delta_loss = 13.08101 learning_Rate = 0.01000 rmse=1.14878 mae=0.87944\n","\u003cclass '__main__.SVDPP'\u003e iteration 97: loss = 1033.7535, delta_loss = 12.85743 learning_Rate = 0.01000 rmse=1.14924 mae=0.87977\n","\u003cclass '__main__.SVDPP'\u003e iteration 98: loss = 1021.1151, delta_loss = 12.63838 learning_Rate = 0.01000 rmse=1.14969 mae=0.88009\n","\u003cclass '__main__.SVDPP'\u003e iteration 99: loss = 1008.6914, delta_loss = 12.42375 learning_Rate = 0.01000 rmse=1.15015 mae=0.88042\n","\u003cclass '__main__.SVDPP'\u003e iteration 100: loss = 996.4780, delta_loss = 12.21345 learning_Rate = 0.01000 rmse=1.15060 mae=0.88075\n","the 3th cross validation training\n","\u003cclass '__main__.SVDPP'\u003e iteration 1: loss = 90448.8118, delta_loss = -90448.81184 learning_Rate = 0.01000 rmse=1.46709 mae=1.05315\n","\u003cclass '__main__.SVDPP'\u003e iteration 2: loss = 28790.4252, delta_loss = 61658.38661 learning_Rate = 0.01000 rmse=1.40626 mae=1.02489\n","\u003cclass '__main__.SVDPP'\u003e iteration 3: loss = 16134.0216, delta_loss = 12656.40367 learning_Rate = 0.01000 rmse=1.35016 mae=0.99463\n","\u003cclass '__main__.SVDPP'\u003e iteration 4: loss = 12223.1187, delta_loss = 3910.90288 learning_Rate = 0.01000 rmse=1.30720 mae=0.97091\n","\u003cclass '__main__.SVDPP'\u003e iteration 5: loss = 10060.1343, delta_loss = 2162.98443 learning_Rate = 0.01000 rmse=1.27578 mae=0.95196\n","\u003cclass '__main__.SVDPP'\u003e iteration 6: loss = 8649.8893, delta_loss = 1410.24492 learning_Rate = 0.01000 rmse=1.25317 mae=0.93824\n","\u003cclass '__main__.SVDPP'\u003e iteration 7: loss = 7646.7661, delta_loss = 1003.12323 learning_Rate = 0.01000 rmse=1.23647 mae=0.92811\n","\u003cclass '__main__.SVDPP'\u003e iteration 8: loss = 6892.6546, delta_loss = 754.11150 learning_Rate = 0.01000 rmse=1.22344 mae=0.92017\n","\u003cclass '__main__.SVDPP'\u003e iteration 9: loss = 6303.3443, delta_loss = 589.31034 learning_Rate = 0.01000 rmse=1.21302 mae=0.91371\n","\u003cclass '__main__.SVDPP'\u003e iteration 10: loss = 5829.2281, delta_loss = 474.11618 learning_Rate = 0.01000 rmse=1.20451 mae=0.90822\n","\u003cclass '__main__.SVDPP'\u003e iteration 11: loss = 5438.9362, delta_loss = 390.29192 learning_Rate = 0.01000 rmse=1.19770 mae=0.90374\n","\u003cclass '__main__.SVDPP'\u003e iteration 12: loss = 5111.5797, delta_loss = 327.35651 learning_Rate = 0.01000 rmse=1.19226 mae=0.90021\n","\u003cclass '__main__.SVDPP'\u003e iteration 13: loss = 4832.6904, delta_loss = 278.88927 learning_Rate = 0.01000 rmse=1.18772 mae=0.89774\n","\u003cclass '__main__.SVDPP'\u003e iteration 14: loss = 4591.9250, delta_loss = 240.76536 learning_Rate = 0.01000 rmse=1.18380 mae=0.89557\n","\u003cclass '__main__.SVDPP'\u003e iteration 15: loss = 4381.6893, delta_loss = 210.23570 learning_Rate = 0.01000 rmse=1.18040 mae=0.89361\n","\u003cclass '__main__.SVDPP'\u003e iteration 16: loss = 4196.2773, delta_loss = 185.41208 learning_Rate = 0.01000 rmse=1.17752 mae=0.89190\n","\u003cclass '__main__.SVDPP'\u003e iteration 17: loss = 4031.3142, delta_loss = 164.96301 learning_Rate = 0.01000 rmse=1.17513 mae=0.89049\n","\u003cclass '__main__.SVDPP'\u003e iteration 18: loss = 3883.3871, delta_loss = 147.92717 learning_Rate = 0.01000 rmse=1.17297 mae=0.88916\n","\u003cclass '__main__.SVDPP'\u003e iteration 19: loss = 3749.7915, delta_loss = 133.59555 learning_Rate = 0.01000 rmse=1.17115 mae=0.88794\n","\u003cclass '__main__.SVDPP'\u003e iteration 20: loss = 3628.3563, delta_loss = 121.43526 learning_Rate = 0.01000 rmse=1.16951 mae=0.88680\n","\u003cclass '__main__.SVDPP'\u003e iteration 21: loss = 3517.3173, delta_loss = 111.03900 learning_Rate = 0.01000 rmse=1.16803 mae=0.88572\n","\u003cclass '__main__.SVDPP'\u003e iteration 22: loss = 3415.2265, delta_loss = 102.09078 learning_Rate = 0.01000 rmse=1.16675 mae=0.88475\n","\u003cclass '__main__.SVDPP'\u003e iteration 23: loss = 3320.8843, delta_loss = 94.34216 learning_Rate = 0.01000 rmse=1.16564 mae=0.88386\n","\u003cclass '__main__.SVDPP'\u003e iteration 24: loss = 3233.2889, delta_loss = 87.59543 learning_Rate = 0.01000 rmse=1.16466 mae=0.88308\n","\u003cclass '__main__.SVDPP'\u003e iteration 25: loss = 3151.5974, delta_loss = 81.69148 learning_Rate = 0.01000 rmse=1.16382 mae=0.88239\n","\u003cclass '__main__.SVDPP'\u003e iteration 26: loss = 3075.0964, delta_loss = 76.50102 learning_Rate = 0.01000 rmse=1.16313 mae=0.88179\n","\u003cclass '__main__.SVDPP'\u003e iteration 27: loss = 3003.1784, delta_loss = 71.91799 learning_Rate = 0.01000 rmse=1.16253 mae=0.88130\n","\u003cclass '__main__.SVDPP'\u003e iteration 28: loss = 2935.3238, delta_loss = 67.85463 learning_Rate = 0.01000 rmse=1.16205 mae=0.88088\n","\u003cclass '__main__.SVDPP'\u003e iteration 29: loss = 2871.0860, delta_loss = 64.23780 learning_Rate = 0.01000 rmse=1.16165 mae=0.88052\n","\u003cclass '__main__.SVDPP'\u003e iteration 30: loss = 2810.0799, delta_loss = 61.00609 learning_Rate = 0.01000 rmse=1.16132 mae=0.88024\n","\u003cclass '__main__.SVDPP'\u003e iteration 31: loss = 2751.9723, delta_loss = 58.10759 learning_Rate = 0.01000 rmse=1.16108 mae=0.87999\n","\u003cclass '__main__.SVDPP'\u003e iteration 32: loss = 2696.4741, delta_loss = 55.49819 learning_Rate = 0.01000 rmse=1.16089 mae=0.87980\n","\u003cclass '__main__.SVDPP'\u003e iteration 33: loss = 2643.3339, delta_loss = 53.14018 learning_Rate = 0.01000 rmse=1.16082 mae=0.87969\n","\u003cclass '__main__.SVDPP'\u003e iteration 34: loss = 2592.3327, delta_loss = 51.00122 learning_Rate = 0.01000 rmse=1.16084 mae=0.87964\n","\u003cclass '__main__.SVDPP'\u003e iteration 35: loss = 2543.2793, delta_loss = 49.05340 learning_Rate = 0.01000 rmse=1.16088 mae=0.87965\n","\u003cclass '__main__.SVDPP'\u003e iteration 36: loss = 2496.0067, delta_loss = 47.27263 learning_Rate = 0.01000 rmse=1.16094 mae=0.87968\n","\u003cclass '__main__.SVDPP'\u003e iteration 37: loss = 2450.3687, delta_loss = 45.63801 learning_Rate = 0.01000 rmse=1.16102 mae=0.87976\n","\u003cclass '__main__.SVDPP'\u003e iteration 38: loss = 2406.2373, delta_loss = 44.13140 learning_Rate = 0.01000 rmse=1.16115 mae=0.87985\n","\u003cclass '__main__.SVDPP'\u003e iteration 39: loss = 2363.5002, delta_loss = 42.73702 learning_Rate = 0.01000 rmse=1.16133 mae=0.88000\n","\u003cclass '__main__.SVDPP'\u003e iteration 40: loss = 2322.0591, delta_loss = 41.44117 learning_Rate = 0.01000 rmse=1.16155 mae=0.88018\n","\u003cclass '__main__.SVDPP'\u003e iteration 41: loss = 2281.8271, delta_loss = 40.23194 learning_Rate = 0.01000 rmse=1.16183 mae=0.88041\n","\u003cclass '__main__.SVDPP'\u003e iteration 42: loss = 2242.7281, delta_loss = 39.09899 learning_Rate = 0.01000 rmse=1.16214 mae=0.88063\n","\u003cclass '__main__.SVDPP'\u003e iteration 43: loss = 2204.6948, delta_loss = 38.03337 learning_Rate = 0.01000 rmse=1.16242 mae=0.88086\n","\u003cclass '__main__.SVDPP'\u003e iteration 44: loss = 2167.6674, delta_loss = 37.02733 learning_Rate = 0.01000 rmse=1.16272 mae=0.88110\n","\u003cclass '__main__.SVDPP'\u003e iteration 45: loss = 2131.5932, delta_loss = 36.07420 learning_Rate = 0.01000 rmse=1.16304 mae=0.88135\n","\u003cclass '__main__.SVDPP'\u003e iteration 46: loss = 2096.4250, delta_loss = 35.16824 learning_Rate = 0.01000 rmse=1.16338 mae=0.88160\n","\u003cclass '__main__.SVDPP'\u003e iteration 47: loss = 2062.1205, delta_loss = 34.30452 learning_Rate = 0.01000 rmse=1.16374 mae=0.88185\n","\u003cclass '__main__.SVDPP'\u003e iteration 48: loss = 2028.6417, delta_loss = 33.47881 learning_Rate = 0.01000 rmse=1.16411 mae=0.88211\n","\u003cclass '__main__.SVDPP'\u003e iteration 49: loss = 1995.9542, delta_loss = 32.68751 learning_Rate = 0.01000 rmse=1.16451 mae=0.88238\n","\u003cclass '__main__.SVDPP'\u003e iteration 50: loss = 1964.0267, delta_loss = 31.92752 learning_Rate = 0.01000 rmse=1.16493 mae=0.88265\n","\u003cclass '__main__.SVDPP'\u003e iteration 51: loss = 1932.8305, delta_loss = 31.19619 learning_Rate = 0.01000 rmse=1.16536 mae=0.88293\n","\u003cclass '__main__.SVDPP'\u003e iteration 52: loss = 1902.3392, delta_loss = 30.49126 learning_Rate = 0.01000 rmse=1.16580 mae=0.88322\n","\u003cclass '__main__.SVDPP'\u003e iteration 53: loss = 1872.5285, delta_loss = 29.81075 learning_Rate = 0.01000 rmse=1.16626 mae=0.88351\n","\u003cclass '__main__.SVDPP'\u003e iteration 54: loss = 1843.3755, delta_loss = 29.15298 learning_Rate = 0.01000 rmse=1.16674 mae=0.88384\n","\u003cclass '__main__.SVDPP'\u003e iteration 55: loss = 1814.8590, delta_loss = 28.51647 learning_Rate = 0.01000 rmse=1.16724 mae=0.88417\n","\u003cclass '__main__.SVDPP'\u003e iteration 56: loss = 1786.9591, delta_loss = 27.89994 learning_Rate = 0.01000 rmse=1.16776 mae=0.88451\n","\u003cclass '__main__.SVDPP'\u003e iteration 57: loss = 1759.6568, delta_loss = 27.30223 learning_Rate = 0.01000 rmse=1.16830 mae=0.88487\n","\u003cclass '__main__.SVDPP'\u003e iteration 58: loss = 1732.9345, delta_loss = 26.72236 learning_Rate = 0.01000 rmse=1.16886 mae=0.88522\n","\u003cclass '__main__.SVDPP'\u003e iteration 59: loss = 1706.7751, delta_loss = 26.15941 learning_Rate = 0.01000 rmse=1.16942 mae=0.88557\n","\u003cclass '__main__.SVDPP'\u003e iteration 60: loss = 1681.1625, delta_loss = 25.61258 learning_Rate = 0.01000 rmse=1.16998 mae=0.88591\n","\u003cclass '__main__.SVDPP'\u003e iteration 61: loss = 1656.0813, delta_loss = 25.08114 learning_Rate = 0.01000 rmse=1.17056 mae=0.88627\n","\u003cclass '__main__.SVDPP'\u003e iteration 62: loss = 1631.5169, delta_loss = 24.56443 learning_Rate = 0.01000 rmse=1.17115 mae=0.88666\n","\u003cclass '__main__.SVDPP'\u003e iteration 63: loss = 1607.4551, delta_loss = 24.06185 learning_Rate = 0.01000 rmse=1.17175 mae=0.88705\n","\u003cclass '__main__.SVDPP'\u003e iteration 64: loss = 1583.8822, delta_loss = 23.57283 learning_Rate = 0.01000 rmse=1.17237 mae=0.88744\n","\u003cclass '__main__.SVDPP'\u003e iteration 65: loss = 1560.7854, delta_loss = 23.09687 learning_Rate = 0.01000 rmse=1.17301 mae=0.88785\n","\u003cclass '__main__.SVDPP'\u003e iteration 66: loss = 1538.1519, delta_loss = 22.63349 learning_Rate = 0.01000 rmse=1.17365 mae=0.88827\n","\u003cclass '__main__.SVDPP'\u003e iteration 67: loss = 1515.9696, delta_loss = 22.18226 learning_Rate = 0.01000 rmse=1.17431 mae=0.88870\n","\u003cclass '__main__.SVDPP'\u003e iteration 68: loss = 1494.2269, delta_loss = 21.74275 learning_Rate = 0.01000 rmse=1.17496 mae=0.88913\n","\u003cclass '__main__.SVDPP'\u003e iteration 69: loss = 1472.9123, delta_loss = 21.31459 learning_Rate = 0.01000 rmse=1.17560 mae=0.88956\n","\u003cclass '__main__.SVDPP'\u003e iteration 70: loss = 1452.0149, delta_loss = 20.89739 learning_Rate = 0.01000 rmse=1.17625 mae=0.88999\n","\u003cclass '__main__.SVDPP'\u003e iteration 71: loss = 1431.5241, delta_loss = 20.49081 learning_Rate = 0.01000 rmse=1.17689 mae=0.89044\n","\u003cclass '__main__.SVDPP'\u003e iteration 72: loss = 1411.4295, delta_loss = 20.09452 learning_Rate = 0.01000 rmse=1.17755 mae=0.89090\n","\u003cclass '__main__.SVDPP'\u003e iteration 73: loss = 1391.7214, delta_loss = 19.70819 learning_Rate = 0.01000 rmse=1.17821 mae=0.89135\n","\u003cclass '__main__.SVDPP'\u003e iteration 74: loss = 1372.3898, delta_loss = 19.33151 learning_Rate = 0.01000 rmse=1.17886 mae=0.89181\n","\u003cclass '__main__.SVDPP'\u003e iteration 75: loss = 1353.4257, delta_loss = 18.96419 learning_Rate = 0.01000 rmse=1.17951 mae=0.89225\n","\u003cclass '__main__.SVDPP'\u003e iteration 76: loss = 1334.8197, delta_loss = 18.60593 learning_Rate = 0.01000 rmse=1.18018 mae=0.89272\n","\u003cclass '__main__.SVDPP'\u003e iteration 77: loss = 1316.5633, delta_loss = 18.25647 learning_Rate = 0.01000 rmse=1.18083 mae=0.89317\n","\u003cclass '__main__.SVDPP'\u003e iteration 78: loss = 1298.6477, delta_loss = 17.91552 learning_Rate = 0.01000 rmse=1.18148 mae=0.89361\n","\u003cclass '__main__.SVDPP'\u003e iteration 79: loss = 1281.0649, delta_loss = 17.58282 learning_Rate = 0.01000 rmse=1.18212 mae=0.89406\n","\u003cclass '__main__.SVDPP'\u003e iteration 80: loss = 1263.8068, delta_loss = 17.25811 learning_Rate = 0.01000 rmse=1.18276 mae=0.89451\n","\u003cclass '__main__.SVDPP'\u003e iteration 81: loss = 1246.8657, delta_loss = 16.94116 learning_Rate = 0.01000 rmse=1.18340 mae=0.89495\n","\u003cclass '__main__.SVDPP'\u003e iteration 82: loss = 1230.2339, delta_loss = 16.63171 learning_Rate = 0.01000 rmse=1.18405 mae=0.89541\n","\u003cclass '__main__.SVDPP'\u003e iteration 83: loss = 1213.9044, delta_loss = 16.32953 learning_Rate = 0.01000 rmse=1.18467 mae=0.89584\n","\u003cclass '__main__.SVDPP'\u003e iteration 84: loss = 1197.8700, delta_loss = 16.03439 learning_Rate = 0.01000 rmse=1.18532 mae=0.89629\n","\u003cclass '__main__.SVDPP'\u003e iteration 85: loss = 1182.1240, delta_loss = 15.74608 learning_Rate = 0.01000 rmse=1.18595 mae=0.89673\n","\u003cclass '__main__.SVDPP'\u003e iteration 86: loss = 1166.6596, delta_loss = 15.46438 learning_Rate = 0.01000 rmse=1.18659 mae=0.89717\n","\u003cclass '__main__.SVDPP'\u003e iteration 87: loss = 1151.4705, delta_loss = 15.18908 learning_Rate = 0.01000 rmse=1.18722 mae=0.89761\n","\u003cclass '__main__.SVDPP'\u003e iteration 88: loss = 1136.5505, delta_loss = 14.91998 learning_Rate = 0.01000 rmse=1.18785 mae=0.89804\n","\u003cclass '__main__.SVDPP'\u003e iteration 89: loss = 1121.8936, delta_loss = 14.65690 learning_Rate = 0.01000 rmse=1.18848 mae=0.89847\n","\u003cclass '__main__.SVDPP'\u003e iteration 90: loss = 1107.4940, delta_loss = 14.39964 learning_Rate = 0.01000 rmse=1.18910 mae=0.89889\n","\u003cclass '__main__.SVDPP'\u003e iteration 91: loss = 1093.3459, delta_loss = 14.14803 learning_Rate = 0.01000 rmse=1.18972 mae=0.89931\n","\u003cclass '__main__.SVDPP'\u003e iteration 92: loss = 1079.4441, delta_loss = 13.90189 learning_Rate = 0.01000 rmse=1.19033 mae=0.89973\n","\u003cclass '__main__.SVDPP'\u003e iteration 93: loss = 1065.7830, delta_loss = 13.66107 learning_Rate = 0.01000 rmse=1.19093 mae=0.90013\n","\u003cclass '__main__.SVDPP'\u003e iteration 94: loss = 1052.3576, delta_loss = 13.42540 learning_Rate = 0.01000 rmse=1.19153 mae=0.90054\n","\u003cclass '__main__.SVDPP'\u003e iteration 95: loss = 1039.1629, delta_loss = 13.19472 learning_Rate = 0.01000 rmse=1.19213 mae=0.90094\n","\u003cclass '__main__.SVDPP'\u003e iteration 96: loss = 1026.1940, delta_loss = 12.96890 learning_Rate = 0.01000 rmse=1.19273 mae=0.90134\n","\u003cclass '__main__.SVDPP'\u003e iteration 97: loss = 1013.4462, delta_loss = 12.74779 learning_Rate = 0.01000 rmse=1.19332 mae=0.90173\n","\u003cclass '__main__.SVDPP'\u003e iteration 98: loss = 1000.9149, delta_loss = 12.53126 learning_Rate = 0.01000 rmse=1.19390 mae=0.90213\n","\u003cclass '__main__.SVDPP'\u003e iteration 99: loss = 988.5958, delta_loss = 12.31917 learning_Rate = 0.01000 rmse=1.19448 mae=0.90253\n","\u003cclass '__main__.SVDPP'\u003e iteration 100: loss = 976.4843, delta_loss = 12.11142 learning_Rate = 0.01000 rmse=1.19505 mae=0.90293\n","the 4th cross validation training\n","\u003cclass '__main__.SVDPP'\u003e iteration 1: loss = 91562.7419, delta_loss = -91562.74187 learning_Rate = 0.01000 rmse=1.47085 mae=1.05394\n","\u003cclass '__main__.SVDPP'\u003e iteration 2: loss = 29173.4434, delta_loss = 62389.29843 learning_Rate = 0.01000 rmse=1.39553 mae=1.01645\n","\u003cclass '__main__.SVDPP'\u003e iteration 3: loss = 16231.5481, delta_loss = 12941.89531 learning_Rate = 0.01000 rmse=1.33167 mae=0.98073\n","\u003cclass '__main__.SVDPP'\u003e iteration 4: loss = 12288.7900, delta_loss = 3942.75817 learning_Rate = 0.01000 rmse=1.28416 mae=0.95255\n","\u003cclass '__main__.SVDPP'\u003e iteration 5: loss = 10104.9389, delta_loss = 2183.85101 learning_Rate = 0.01000 rmse=1.25076 mae=0.93160\n","\u003cclass '__main__.SVDPP'\u003e iteration 6: loss = 8681.1058, delta_loss = 1423.83310 learning_Rate = 0.01000 rmse=1.22740 mae=0.91663\n","\u003cclass '__main__.SVDPP'\u003e iteration 7: loss = 7669.6801, delta_loss = 1011.42572 learning_Rate = 0.01000 rmse=1.21130 mae=0.90672\n","\u003cclass '__main__.SVDPP'\u003e iteration 8: loss = 6910.4941, delta_loss = 759.18607 learning_Rate = 0.01000 rmse=1.19912 mae=0.89932\n","\u003cclass '__main__.SVDPP'\u003e iteration 9: loss = 6317.9383, delta_loss = 592.55580 learning_Rate = 0.01000 rmse=1.18957 mae=0.89342\n","\u003cclass '__main__.SVDPP'\u003e iteration 10: loss = 5841.6463, delta_loss = 476.29191 learning_Rate = 0.01000 rmse=1.18221 mae=0.88878\n","\u003cclass '__main__.SVDPP'\u003e iteration 11: loss = 5449.8657, delta_loss = 391.78061 learning_Rate = 0.01000 rmse=1.17648 mae=0.88491\n","\u003cclass '__main__.SVDPP'\u003e iteration 12: loss = 5121.4989, delta_loss = 328.36688 learning_Rate = 0.01000 rmse=1.17195 mae=0.88195\n","\u003cclass '__main__.SVDPP'\u003e iteration 13: loss = 4841.9430, delta_loss = 279.55583 learning_Rate = 0.01000 rmse=1.16834 mae=0.87971\n","\u003cclass '__main__.SVDPP'\u003e iteration 14: loss = 4600.7570, delta_loss = 241.18605 learning_Rate = 0.01000 rmse=1.16558 mae=0.87795\n","\u003cclass '__main__.SVDPP'\u003e iteration 15: loss = 4390.2728, delta_loss = 210.48420 learning_Rate = 0.01000 rmse=1.16340 mae=0.87654\n","\u003cclass '__main__.SVDPP'\u003e iteration 16: loss = 4204.7299, delta_loss = 185.54285 learning_Rate = 0.01000 rmse=1.16137 mae=0.87535\n","\u003cclass '__main__.SVDPP'\u003e iteration 17: loss = 4039.7147, delta_loss = 165.01521 learning_Rate = 0.01000 rmse=1.15960 mae=0.87419\n","\u003cclass '__main__.SVDPP'\u003e iteration 18: loss = 3891.7863, delta_loss = 147.92848 learning_Rate = 0.01000 rmse=1.15804 mae=0.87315\n","\u003cclass '__main__.SVDPP'\u003e iteration 19: loss = 3758.2206, delta_loss = 133.56569 learning_Rate = 0.01000 rmse=1.15666 mae=0.87224\n","\u003cclass '__main__.SVDPP'\u003e iteration 20: loss = 3636.8318, delta_loss = 121.38874 learning_Rate = 0.01000 rmse=1.15543 mae=0.87148\n","\u003cclass '__main__.SVDPP'\u003e iteration 21: loss = 3525.8447, delta_loss = 110.98710 learning_Rate = 0.01000 rmse=1.15435 mae=0.87082\n","\u003cclass '__main__.SVDPP'\u003e iteration 22: loss = 3423.8020, delta_loss = 102.04268 learning_Rate = 0.01000 rmse=1.15348 mae=0.87025\n","\u003cclass '__main__.SVDPP'\u003e iteration 23: loss = 3329.4965, delta_loss = 94.30559 learning_Rate = 0.01000 rmse=1.15279 mae=0.86976\n","\u003cclass '__main__.SVDPP'\u003e iteration 24: loss = 3241.9196, delta_loss = 87.57688 learning_Rate = 0.01000 rmse=1.15230 mae=0.86936\n","\u003cclass '__main__.SVDPP'\u003e iteration 25: loss = 3160.2233, delta_loss = 81.69628 learning_Rate = 0.01000 rmse=1.15193 mae=0.86899\n","\u003cclass '__main__.SVDPP'\u003e iteration 26: loss = 3083.6900, delta_loss = 76.53331 learning_Rate = 0.01000 rmse=1.15160 mae=0.86862\n","\u003cclass '__main__.SVDPP'\u003e iteration 27: loss = 3011.7093, delta_loss = 71.98066 learning_Rate = 0.01000 rmse=1.15125 mae=0.86829\n","\u003cclass '__main__.SVDPP'\u003e iteration 28: loss = 2943.7599, delta_loss = 67.94938 learning_Rate = 0.01000 rmse=1.15096 mae=0.86803\n","\u003cclass '__main__.SVDPP'\u003e iteration 29: loss = 2879.3948, delta_loss = 64.36514 learning_Rate = 0.01000 rmse=1.15073 mae=0.86782\n","\u003cclass '__main__.SVDPP'\u003e iteration 30: loss = 2818.2294, delta_loss = 61.16544 learning_Rate = 0.01000 rmse=1.15056 mae=0.86763\n","\u003cclass '__main__.SVDPP'\u003e iteration 31: loss = 2759.9320, delta_loss = 58.29738 learning_Rate = 0.01000 rmse=1.15049 mae=0.86748\n","\u003cclass '__main__.SVDPP'\u003e iteration 32: loss = 2704.2160, delta_loss = 55.71601 learning_Rate = 0.01000 rmse=1.15041 mae=0.86736\n","\u003cclass '__main__.SVDPP'\u003e iteration 33: loss = 2650.8330, delta_loss = 53.38295 learning_Rate = 0.01000 rmse=1.15037 mae=0.86729\n","\u003cclass '__main__.SVDPP'\u003e iteration 34: loss = 2599.5677, delta_loss = 51.26534 learning_Rate = 0.01000 rmse=1.15037 mae=0.86721\n","\u003cclass '__main__.SVDPP'\u003e iteration 35: loss = 2550.2328, delta_loss = 49.33495 learning_Rate = 0.01000 rmse=1.15042 mae=0.86716\n","\u003cclass '__main__.SVDPP'\u003e iteration 36: loss = 2502.6652, delta_loss = 47.56752 learning_Rate = 0.01000 rmse=1.15050 mae=0.86715\n","\u003cclass '__main__.SVDPP'\u003e iteration 37: loss = 2456.7231, delta_loss = 45.94214 learning_Rate = 0.01000 rmse=1.15059 mae=0.86715\n","\u003cclass '__main__.SVDPP'\u003e iteration 38: loss = 2412.2823, delta_loss = 44.44081 learning_Rate = 0.01000 rmse=1.15071 mae=0.86719\n","\u003cclass '__main__.SVDPP'\u003e iteration 39: loss = 2369.2343, delta_loss = 43.04801 learning_Rate = 0.01000 rmse=1.15088 mae=0.86725\n","\u003cclass '__main__.SVDPP'\u003e iteration 40: loss = 2327.4839, delta_loss = 41.75039 learning_Rate = 0.01000 rmse=1.15106 mae=0.86737\n","\u003cclass '__main__.SVDPP'\u003e iteration 41: loss = 2286.9474, delta_loss = 40.53646 learning_Rate = 0.01000 rmse=1.15124 mae=0.86748\n","\u003cclass '__main__.SVDPP'\u003e iteration 42: loss = 2247.5511, delta_loss = 39.39631 learning_Rate = 0.01000 rmse=1.15144 mae=0.86759\n","\u003cclass '__main__.SVDPP'\u003e iteration 43: loss = 2209.2297, delta_loss = 38.32145 learning_Rate = 0.01000 rmse=1.15168 mae=0.86776\n","\u003cclass '__main__.SVDPP'\u003e iteration 44: loss = 2171.9251, delta_loss = 37.30457 learning_Rate = 0.01000 rmse=1.15194 mae=0.86794\n","\u003cclass '__main__.SVDPP'\u003e iteration 45: loss = 2135.5857, delta_loss = 36.33941 learning_Rate = 0.01000 rmse=1.15221 mae=0.86812\n","\u003cclass '__main__.SVDPP'\u003e iteration 46: loss = 2100.1651, delta_loss = 35.42056 learning_Rate = 0.01000 rmse=1.15250 mae=0.86832\n","\u003cclass '__main__.SVDPP'\u003e iteration 47: loss = 2065.6217, delta_loss = 34.54341 learning_Rate = 0.01000 rmse=1.15280 mae=0.86851\n","\u003cclass '__main__.SVDPP'\u003e iteration 48: loss = 2031.9178, delta_loss = 33.70396 learning_Rate = 0.01000 rmse=1.15312 mae=0.86873\n","\u003cclass '__main__.SVDPP'\u003e iteration 49: loss = 1999.0190, delta_loss = 32.89879 learning_Rate = 0.01000 rmse=1.15344 mae=0.86895\n","\u003cclass '__main__.SVDPP'\u003e iteration 50: loss = 1966.8940, delta_loss = 32.12495 learning_Rate = 0.01000 rmse=1.15378 mae=0.86920\n","\u003cclass '__main__.SVDPP'\u003e iteration 51: loss = 1935.5141, delta_loss = 31.37989 learning_Rate = 0.01000 rmse=1.15412 mae=0.86946\n","\u003cclass '__main__.SVDPP'\u003e iteration 52: loss = 1904.8527, delta_loss = 30.66140 learning_Rate = 0.01000 rmse=1.15448 mae=0.86974\n","\u003cclass '__main__.SVDPP'\u003e iteration 53: loss = 1874.8852, delta_loss = 29.96757 learning_Rate = 0.01000 rmse=1.15485 mae=0.87002\n","\u003cclass '__main__.SVDPP'\u003e iteration 54: loss = 1845.5884, delta_loss = 29.29675 learning_Rate = 0.01000 rmse=1.15522 mae=0.87030\n","\u003cclass '__main__.SVDPP'\u003e iteration 55: loss = 1816.9409, delta_loss = 28.64748 learning_Rate = 0.01000 rmse=1.15561 mae=0.87059\n","\u003cclass '__main__.SVDPP'\u003e iteration 56: loss = 1788.9224, delta_loss = 28.01851 learning_Rate = 0.01000 rmse=1.15600 mae=0.87088\n","\u003cclass '__main__.SVDPP'\u003e iteration 57: loss = 1761.5137, delta_loss = 27.40872 learning_Rate = 0.01000 rmse=1.15640 mae=0.87118\n","\u003cclass '__main__.SVDPP'\u003e iteration 58: loss = 1734.6965, delta_loss = 26.81714 learning_Rate = 0.01000 rmse=1.15681 mae=0.87148\n","\u003cclass '__main__.SVDPP'\u003e iteration 59: loss = 1708.4537, delta_loss = 26.24287 learning_Rate = 0.01000 rmse=1.15723 mae=0.87179\n","\u003cclass '__main__.SVDPP'\u003e iteration 60: loss = 1682.7685, delta_loss = 25.68516 learning_Rate = 0.01000 rmse=1.15764 mae=0.87210\n","\u003cclass '__main__.SVDPP'\u003e iteration 61: loss = 1657.6252, delta_loss = 25.14327 learning_Rate = 0.01000 rmse=1.15807 mae=0.87241\n","\u003cclass '__main__.SVDPP'\u003e iteration 62: loss = 1633.0087, delta_loss = 24.61657 learning_Rate = 0.01000 rmse=1.15851 mae=0.87273\n","\u003cclass '__main__.SVDPP'\u003e iteration 63: loss = 1608.9042, delta_loss = 24.10446 learning_Rate = 0.01000 rmse=1.15897 mae=0.87305\n","\u003cclass '__main__.SVDPP'\u003e iteration 64: loss = 1585.2978, delta_loss = 23.60639 learning_Rate = 0.01000 rmse=1.15945 mae=0.87337\n","\u003cclass '__main__.SVDPP'\u003e iteration 65: loss = 1562.1760, delta_loss = 23.12182 learning_Rate = 0.01000 rmse=1.15994 mae=0.87369\n","\u003cclass '__main__.SVDPP'\u003e iteration 66: loss = 1539.5257, delta_loss = 22.65027 learning_Rate = 0.01000 rmse=1.16044 mae=0.87401\n","\u003cclass '__main__.SVDPP'\u003e iteration 67: loss = 1517.3344, delta_loss = 22.19127 learning_Rate = 0.01000 rmse=1.16095 mae=0.87433\n","\u003cclass '__main__.SVDPP'\u003e iteration 68: loss = 1495.5901, delta_loss = 21.74436 learning_Rate = 0.01000 rmse=1.16146 mae=0.87465\n","\u003cclass '__main__.SVDPP'\u003e iteration 69: loss = 1474.2810, delta_loss = 21.30910 learning_Rate = 0.01000 rmse=1.16197 mae=0.87498\n","\u003cclass '__main__.SVDPP'\u003e iteration 70: loss = 1453.3959, delta_loss = 20.88509 learning_Rate = 0.01000 rmse=1.16249 mae=0.87531\n","\u003cclass '__main__.SVDPP'\u003e iteration 71: loss = 1432.9240, delta_loss = 20.47192 learning_Rate = 0.01000 rmse=1.16302 mae=0.87564\n","\u003cclass '__main__.SVDPP'\u003e iteration 72: loss = 1412.8548, delta_loss = 20.06921 learning_Rate = 0.01000 rmse=1.16355 mae=0.87599\n","\u003cclass '__main__.SVDPP'\u003e iteration 73: loss = 1393.1782, delta_loss = 19.67658 learning_Rate = 0.01000 rmse=1.16409 mae=0.87633\n","\u003cclass '__main__.SVDPP'\u003e iteration 74: loss = 1373.8845, delta_loss = 19.29368 learning_Rate = 0.01000 rmse=1.16463 mae=0.87669\n","\u003cclass '__main__.SVDPP'\u003e iteration 75: loss = 1354.9643, delta_loss = 18.92018 learning_Rate = 0.01000 rmse=1.16518 mae=0.87705\n","\u003cclass '__main__.SVDPP'\u003e iteration 76: loss = 1336.4086, delta_loss = 18.55574 learning_Rate = 0.01000 rmse=1.16572 mae=0.87741\n","\u003cclass '__main__.SVDPP'\u003e iteration 77: loss = 1318.2085, delta_loss = 18.20007 learning_Rate = 0.01000 rmse=1.16626 mae=0.87777\n","\u003cclass '__main__.SVDPP'\u003e iteration 78: loss = 1300.3556, delta_loss = 17.85288 learning_Rate = 0.01000 rmse=1.16680 mae=0.87813\n","\u003cclass '__main__.SVDPP'\u003e iteration 79: loss = 1282.8418, delta_loss = 17.51388 learning_Rate = 0.01000 rmse=1.16734 mae=0.87850\n","\u003cclass '__main__.SVDPP'\u003e iteration 80: loss = 1265.6589, delta_loss = 17.18282 learning_Rate = 0.01000 rmse=1.16789 mae=0.87886\n","\u003cclass '__main__.SVDPP'\u003e iteration 81: loss = 1248.7995, delta_loss = 16.85946 learning_Rate = 0.01000 rmse=1.16843 mae=0.87922\n","\u003cclass '__main__.SVDPP'\u003e iteration 82: loss = 1232.2559, delta_loss = 16.54356 learning_Rate = 0.01000 rmse=1.16899 mae=0.87959\n","\u003cclass '__main__.SVDPP'\u003e iteration 83: loss = 1216.0210, delta_loss = 16.23490 learning_Rate = 0.01000 rmse=1.16956 mae=0.87996\n","\u003cclass '__main__.SVDPP'\u003e iteration 84: loss = 1200.0877, delta_loss = 15.93328 learning_Rate = 0.01000 rmse=1.17011 mae=0.88033\n","\u003cclass '__main__.SVDPP'\u003e iteration 85: loss = 1184.4492, delta_loss = 15.63851 learning_Rate = 0.01000 rmse=1.17067 mae=0.88069\n","\u003cclass '__main__.SVDPP'\u003e iteration 86: loss = 1169.0988, delta_loss = 15.35040 learning_Rate = 0.01000 rmse=1.17123 mae=0.88106\n","\u003cclass '__main__.SVDPP'\u003e iteration 87: loss = 1154.0300, delta_loss = 15.06878 learning_Rate = 0.01000 rmse=1.17178 mae=0.88142\n","\u003cclass '__main__.SVDPP'\u003e iteration 88: loss = 1139.2366, delta_loss = 14.79348 learning_Rate = 0.01000 rmse=1.17235 mae=0.88179\n","\u003cclass '__main__.SVDPP'\u003e iteration 89: loss = 1124.7122, delta_loss = 14.52435 learning_Rate = 0.01000 rmse=1.17292 mae=0.88216\n","\u003cclass '__main__.SVDPP'\u003e iteration 90: loss = 1110.4510, delta_loss = 14.26123 learning_Rate = 0.01000 rmse=1.17349 mae=0.88253\n","\u003cclass '__main__.SVDPP'\u003e iteration 91: loss = 1096.4470, delta_loss = 14.00399 learning_Rate = 0.01000 rmse=1.17406 mae=0.88290\n","\u003cclass '__main__.SVDPP'\u003e iteration 92: loss = 1082.6945, delta_loss = 13.75247 learning_Rate = 0.01000 rmse=1.17464 mae=0.88327\n","\u003cclass '__main__.SVDPP'\u003e iteration 93: loss = 1069.1880, delta_loss = 13.50656 learning_Rate = 0.01000 rmse=1.17521 mae=0.88364\n","\u003cclass '__main__.SVDPP'\u003e iteration 94: loss = 1055.9218, delta_loss = 13.26611 learning_Rate = 0.01000 rmse=1.17579 mae=0.88401\n","\u003cclass '__main__.SVDPP'\u003e iteration 95: loss = 1042.8908, delta_loss = 13.03101 learning_Rate = 0.01000 rmse=1.17636 mae=0.88437\n","\u003cclass '__main__.SVDPP'\u003e iteration 96: loss = 1030.0897, delta_loss = 12.80113 learning_Rate = 0.01000 rmse=1.17693 mae=0.88473\n","\u003cclass '__main__.SVDPP'\u003e iteration 97: loss = 1017.5133, delta_loss = 12.57635 learning_Rate = 0.01000 rmse=1.17749 mae=0.88510\n","\u003cclass '__main__.SVDPP'\u003e iteration 98: loss = 1005.1568, delta_loss = 12.35655 learning_Rate = 0.01000 rmse=1.17805 mae=0.88546\n","\u003cclass '__main__.SVDPP'\u003e iteration 99: loss = 993.0152, delta_loss = 12.14162 learning_Rate = 0.01000 rmse=1.17859 mae=0.88582\n","\u003cclass '__main__.SVDPP'\u003e iteration 100: loss = 981.0837, delta_loss = 11.93145 learning_Rate = 0.01000 rmse=1.17915 mae=0.88617\n","the rmses are [1.1852129928886972, 1.1962098053592007, 1.150603779199221, 1.1950516902579735, 1.179146046526472]\n","the maes are [0.8963992145084899, 0.8963085937499994, 0.8807467063810295, 0.9029266949638641, 0.8861740075506244]\n","the average of rmses is 1.1812448628463128 \n","the average of maes is 0.8925110434308016 \n"]}],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")\n","#from prettyprinter import cpprint\n","import numpy as np\n","#from mf import MF\n","\n","\n","class SVDPP(MF):\n","    \"\"\"\n","    docstring for SVDPP\n","    implement the SVDPP\n","\n","    Koren Y. Factor in the neighbors: Scalable and accurate collaborative filtering[J]. ACM Transactions on Knowledge Discovery from Data (TKDD), 2010, 4(1): 1.\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(SVDPP, self).__init__()\n","        self.config.lambdaP = 0.001\n","        self.config.lambdaQ = 0.001\n","\n","        self.config.lambdaY = 0.001\n","        self.config.lambdaB = 0.001\n","        # self.init_model()\n","\n","    def init_model(self, k):\n","        super(SVDPP, self).init_model(k)\n","        self.Bu = np.random.rand(self.rg.get_train_size()[0]) / (self.config.factor ** 0.5)  # bias value of user\n","        self.Bi = np.random.rand(self.rg.get_train_size()[1]) / (self.config.factor ** 0.5)  # bias value of item\n","        self.Y = np.random.rand(self.rg.get_train_size()[1], self.config.factor) / (\n","                self.config.factor ** 0.5)  # implicit preference\n","        self.SY = dict()\n","\n","    def train_model(self, k):\n","        super(SVDPP, self).train_model(k)\n","        iteration = 0\n","        while iteration \u003c self.config.maxIter:\n","            self.loss = 0\n","            for index, line in enumerate(self.rg.trainSet()):\n","                user, item, rating = line\n","                u = self.rg.user[user]\n","                i = self.rg.item[item]\n","                error = rating - self.predict(user, item)\n","                self.loss += error ** 2\n","\n","                p, q = self.P[u], self.Q[i]\n","                nu, sum_y = self.get_sum_y(user)\n","\n","                # update latent vectors\n","                self.P[u] += self.config.lr * (error * q - self.config.lambdaP * p)\n","                self.Q[i] += self.config.lr * (error * (p + sum_y) - self.config.lambdaQ * q)\n","\n","                self.Bu[u] += self.config.lr * (error - self.config.lambdaB * self.Bu[u])\n","                self.Bi[i] += self.config.lr * (error - self.config.lambdaB * self.Bi[i])\n","\n","                u_items = self.rg.user_rated_items(u)\n","                for j in u_items:\n","                    idj = self.rg.item[j]\n","                    self.Y[idj] += self.config.lr * (error / np.sqrt(nu) * q - self.config.lambdaY * self.Y[idj])\n","\n","            self.loss += self.config.lambdaP * (self.P * self.P).sum() + self.config.lambdaQ * (self.Q * self.Q).sum() \\\n","                         + self.config.lambdaB * (\n","                                 (self.Bu * self.Bu).sum() + (self.Bi * self.Bi).sum()) + self.config.lambdaY * (\n","                                     self.Y * self.Y).sum()\n","            iteration += 1\n","            if self.isConverged(iteration):\n","                break\n","\n","    def predict(self, u, i):\n","        if self.rg.containsUser(u) and self.rg.containsItem(i):\n","            _, sum_y = self.get_sum_y(u)\n","            u = self.rg.user[u]\n","            i = self.rg.item[i]\n","            return self.Q[i].dot(self.P[u] + sum_y) + self.rg.globalMean + self.Bi[i] + self.Bu[u]\n","        else:\n","            return self.rg.globalMean\n","\n","    def get_sum_y(self, u):\n","        if u in self.SY:\n","            return self.SY[u]\n","        u_items = self.rg.user_rated_items(u)\n","        nu = len(u_items)\n","        sum_y = np.zeros(self.config.factor)\n","        for j in u_items:\n","            sum_y += self.Y[self.rg.item[j]]\n","        sum_y /= (np.sqrt(nu))\n","        self.SY[u] = [nu, sum_y]\n","        return nu, sum_y\n","\n","\n","if __name__ == '__main__':\n","    rmses = []\n","    maes = []\n","    tcsr = SVDPP()\n","    # print(bmf.rg.trainSet_u[1])\n","    for i in range(tcsr.config.k_fold_num):\n","        print('the %dth cross validation training' % i)\n","        tcsr.train_model(i)\n","        rmse, mae = tcsr.predict_model()\n","        rmses.append(rmse)\n","        maes.append(mae)\n","    rmse_avg = sum(rmses) / 5\n","    mae_avg = sum(maes) / 5\n","    print(\"the rmses are %s\" % rmses)\n","    print(\"the maes are %s\" % maes)\n","    print(\"the average of rmses is %s \" % rmse_avg)\n","    print(\"the average of maes is %s \" % mae_avg)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1812701,"status":"ok","timestamp":1621250391890,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"dkNr5XcXXu3U","outputId":"cd69687e-31b9-4499-e89a-0caa29ef3cf3"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'dataset_name': 'CiaoDVD', 'k_fold_num': 5, 'rating_path': '/content/drive/MyDrive/data/ft_ratings.txt', 'rating_cv_path': '../data/cv/', 'trust_path': '/content/drive/MyDrive/data/ft_trust_SimRank.txt', 'sep': ' ', 'random_state': 0, 'size': 0.6, 'min_val': 0.5, 'max_val': 4.0, 'coldUserRating': 5, 'factor': 10, 'threshold': 0.0001, 'lr': 0.01, 'maxIter': 100, 'lambdaP': 0.001, 'lambdaQ': 0.001, 'gamma': 0, 'isEarlyStopping': False, 'result_path': '../results/', 'model_path': 'model/', 'result_log_path': 'log/'}\n","the 0th cross validation training\n","\u003cclass '__main__.SocialMF'\u003e iteration 1: loss = 37708.0129, delta_loss = -37708.01287 learning_Rate = 0.01000 rmse=2.27724 mae=1.96592\n","\u003cclass '__main__.SocialMF'\u003e iteration 2: loss = 30242.3352, delta_loss = 7465.67765 learning_Rate = 0.01000 rmse=2.02701 mae=1.71733\n","\u003cclass '__main__.SocialMF'\u003e iteration 3: loss = 25695.5346, delta_loss = 4546.80059 learning_Rate = 0.01000 rmse=1.85721 mae=1.55199\n","\u003cclass '__main__.SocialMF'\u003e iteration 4: loss = 22612.6574, delta_loss = 3082.87726 learning_Rate = 0.01000 rmse=1.73609 mae=1.43620\n","\u003cclass '__main__.SocialMF'\u003e iteration 5: loss = 20354.5034, delta_loss = 2258.15394 learning_Rate = 0.01000 rmse=1.64586 mae=1.35146\n","\u003cclass '__main__.SocialMF'\u003e iteration 6: loss = 18598.7055, delta_loss = 1755.79793 learning_Rate = 0.01000 rmse=1.57617 mae=1.28630\n","\u003cclass '__main__.SocialMF'\u003e iteration 7: loss = 17175.1645, delta_loss = 1423.54105 learning_Rate = 0.01000 rmse=1.52099 mae=1.23507\n","\u003cclass '__main__.SocialMF'\u003e iteration 8: loss = 15986.7030, delta_loss = 1188.46142 learning_Rate = 0.01000 rmse=1.47627 mae=1.19360\n","\u003cclass '__main__.SocialMF'\u003e iteration 9: loss = 14973.2445, delta_loss = 1013.45857 learning_Rate = 0.01000 rmse=1.43936 mae=1.15963\n","\u003cclass '__main__.SocialMF'\u003e iteration 10: loss = 14095.0219, delta_loss = 878.22254 learning_Rate = 0.01000 rmse=1.40848 mae=1.13120\n","\u003cclass '__main__.SocialMF'\u003e iteration 11: loss = 13324.2330, delta_loss = 770.78890 learning_Rate = 0.01000 rmse=1.38242 mae=1.10720\n","\u003cclass '__main__.SocialMF'\u003e iteration 12: loss = 12640.6153, delta_loss = 683.61773 learning_Rate = 0.01000 rmse=1.36026 mae=1.08684\n","\u003cclass '__main__.SocialMF'\u003e iteration 13: loss = 12028.9331, delta_loss = 611.68222 learning_Rate = 0.01000 rmse=1.34118 mae=1.06948\n","\u003cclass '__main__.SocialMF'\u003e iteration 14: loss = 11477.4520, delta_loss = 551.48104 learning_Rate = 0.01000 rmse=1.32446 mae=1.05425\n","\u003cclass '__main__.SocialMF'\u003e iteration 15: loss = 10976.9591, delta_loss = 500.49298 learning_Rate = 0.01000 rmse=1.30977 mae=1.04090\n","\u003cclass '__main__.SocialMF'\u003e iteration 16: loss = 10520.1038, delta_loss = 456.85531 learning_Rate = 0.01000 rmse=1.29678 mae=1.02920\n","\u003cclass '__main__.SocialMF'\u003e iteration 17: loss = 10100.9407, delta_loss = 419.16304 learning_Rate = 0.01000 rmse=1.28520 mae=1.01879\n","\u003cclass '__main__.SocialMF'\u003e iteration 18: loss = 9714.6026, delta_loss = 386.33814 learning_Rate = 0.01000 rmse=1.27483 mae=1.00947\n","\u003cclass '__main__.SocialMF'\u003e iteration 19: loss = 9357.0615, delta_loss = 357.54111 learning_Rate = 0.01000 rmse=1.26550 mae=1.00117\n","\u003cclass '__main__.SocialMF'\u003e iteration 20: loss = 9024.9516, delta_loss = 332.10984 learning_Rate = 0.01000 rmse=1.25705 mae=0.99365\n","\u003cclass '__main__.SocialMF'\u003e iteration 21: loss = 8715.4355, delta_loss = 309.51612 learning_Rate = 0.01000 rmse=1.24937 mae=0.98679\n","\u003cclass '__main__.SocialMF'\u003e iteration 22: loss = 8426.1013, delta_loss = 289.33420 learning_Rate = 0.01000 rmse=1.24236 mae=0.98055\n","\u003cclass '__main__.SocialMF'\u003e iteration 23: loss = 8154.8836, delta_loss = 271.21768 learning_Rate = 0.01000 rmse=1.23590 mae=0.97478\n","\u003cclass '__main__.SocialMF'\u003e iteration 24: loss = 7900.0014, delta_loss = 254.88219 learning_Rate = 0.01000 rmse=1.22993 mae=0.96940\n","\u003cclass '__main__.SocialMF'\u003e iteration 25: loss = 7659.9091, delta_loss = 240.09238 learning_Rate = 0.01000 rmse=1.22446 mae=0.96450\n","\u003cclass '__main__.SocialMF'\u003e iteration 26: loss = 7433.2571, delta_loss = 226.65194 learning_Rate = 0.01000 rmse=1.21940 mae=0.95997\n","\u003cclass '__main__.SocialMF'\u003e iteration 27: loss = 7218.8613, delta_loss = 214.39585 learning_Rate = 0.01000 rmse=1.21468 mae=0.95573\n","\u003cclass '__main__.SocialMF'\u003e iteration 28: loss = 7015.6768, delta_loss = 203.18443 learning_Rate = 0.01000 rmse=1.21027 mae=0.95176\n","\u003cclass '__main__.SocialMF'\u003e iteration 29: loss = 6822.7782, delta_loss = 192.89866 learning_Rate = 0.01000 rmse=1.20612 mae=0.94802\n","\u003cclass '__main__.SocialMF'\u003e iteration 30: loss = 6639.3417, delta_loss = 183.43644 learning_Rate = 0.01000 rmse=1.20225 mae=0.94453\n","\u003cclass '__main__.SocialMF'\u003e iteration 31: loss = 6464.6321, delta_loss = 174.70966 learning_Rate = 0.01000 rmse=1.19863 mae=0.94125\n","\u003cclass '__main__.SocialMF'\u003e iteration 32: loss = 6297.9902, delta_loss = 166.64184 learning_Rate = 0.01000 rmse=1.19524 mae=0.93814\n","\u003cclass '__main__.SocialMF'\u003e iteration 33: loss = 6138.8240, delta_loss = 159.16623 learning_Rate = 0.01000 rmse=1.19205 mae=0.93523\n","\u003cclass '__main__.SocialMF'\u003e iteration 34: loss = 5986.5997, delta_loss = 152.22430 learning_Rate = 0.01000 rmse=1.18905 mae=0.93247\n","\u003cclass '__main__.SocialMF'\u003e iteration 35: loss = 5840.8352, delta_loss = 145.76447 learning_Rate = 0.01000 rmse=1.18621 mae=0.92987\n","\u003cclass '__main__.SocialMF'\u003e iteration 36: loss = 5701.0942, delta_loss = 139.74107 learning_Rate = 0.01000 rmse=1.18354 mae=0.92741\n","\u003cclass '__main__.SocialMF'\u003e iteration 37: loss = 5566.9806, delta_loss = 134.11355 learning_Rate = 0.01000 rmse=1.18101 mae=0.92507\n","\u003cclass '__main__.SocialMF'\u003e iteration 38: loss = 5438.1349, delta_loss = 128.84573 learning_Rate = 0.01000 rmse=1.17862 mae=0.92285\n","\u003cclass '__main__.SocialMF'\u003e iteration 39: loss = 5314.2296, delta_loss = 123.90527 learning_Rate = 0.01000 rmse=1.17636 mae=0.92075\n","\u003cclass '__main__.SocialMF'\u003e iteration 40: loss = 5194.9664, delta_loss = 119.26316 learning_Rate = 0.01000 rmse=1.17423 mae=0.91878\n","\u003cclass '__main__.SocialMF'\u003e iteration 41: loss = 5080.0731, delta_loss = 114.89334 learning_Rate = 0.01000 rmse=1.17221 mae=0.91690\n","\u003cclass '__main__.SocialMF'\u003e iteration 42: loss = 4969.3007, delta_loss = 110.77235 learning_Rate = 0.01000 rmse=1.17031 mae=0.91515\n","\u003cclass '__main__.SocialMF'\u003e iteration 43: loss = 4862.4217, delta_loss = 106.87902 learning_Rate = 0.01000 rmse=1.16851 mae=0.91349\n","\u003cclass '__main__.SocialMF'\u003e iteration 44: loss = 4759.2274, delta_loss = 103.19428 learning_Rate = 0.01000 rmse=1.16680 mae=0.91189\n","\u003cclass '__main__.SocialMF'\u003e iteration 45: loss = 4659.5265, delta_loss = 99.70091 learning_Rate = 0.01000 rmse=1.16517 mae=0.91035\n","\u003cclass '__main__.SocialMF'\u003e iteration 46: loss = 4563.1432, delta_loss = 96.38336 learning_Rate = 0.01000 rmse=1.16361 mae=0.90888\n","\u003cclass '__main__.SocialMF'\u003e iteration 47: loss = 4469.9156, delta_loss = 93.22759 learning_Rate = 0.01000 rmse=1.16213 mae=0.90748\n","\u003cclass '__main__.SocialMF'\u003e iteration 48: loss = 4379.6946, delta_loss = 90.22096 learning_Rate = 0.01000 rmse=1.16072 mae=0.90615\n","\u003cclass '__main__.SocialMF'\u003e iteration 49: loss = 4292.3426, delta_loss = 87.35206 learning_Rate = 0.01000 rmse=1.15939 mae=0.90489\n","\u003cclass '__main__.SocialMF'\u003e iteration 50: loss = 4207.7319, delta_loss = 84.61062 learning_Rate = 0.01000 rmse=1.15811 mae=0.90369\n","\u003cclass '__main__.SocialMF'\u003e iteration 51: loss = 4125.7445, delta_loss = 81.98740 learning_Rate = 0.01000 rmse=1.15690 mae=0.90255\n","\u003cclass '__main__.SocialMF'\u003e iteration 52: loss = 4046.2704, delta_loss = 79.47410 learning_Rate = 0.01000 rmse=1.15575 mae=0.90146\n","\u003cclass '__main__.SocialMF'\u003e iteration 53: loss = 3969.2072, delta_loss = 77.06327 learning_Rate = 0.01000 rmse=1.15466 mae=0.90042\n","\u003cclass '__main__.SocialMF'\u003e iteration 54: loss = 3894.4590, delta_loss = 74.74821 learning_Rate = 0.01000 rmse=1.15362 mae=0.89942\n","\u003cclass '__main__.SocialMF'\u003e iteration 55: loss = 3821.9360, delta_loss = 72.52295 learning_Rate = 0.01000 rmse=1.15262 mae=0.89847\n","\u003cclass '__main__.SocialMF'\u003e iteration 56: loss = 3751.5539, delta_loss = 70.38208 learning_Rate = 0.01000 rmse=1.15166 mae=0.89754\n","\u003cclass '__main__.SocialMF'\u003e iteration 57: loss = 3683.2331, delta_loss = 68.32080 learning_Rate = 0.01000 rmse=1.15075 mae=0.89666\n","\u003cclass '__main__.SocialMF'\u003e iteration 58: loss = 3616.8984, delta_loss = 66.33477 learning_Rate = 0.01000 rmse=1.14987 mae=0.89581\n","\u003cclass '__main__.SocialMF'\u003e iteration 59: loss = 3552.4783, delta_loss = 64.42009 learning_Rate = 0.01000 rmse=1.14906 mae=0.89500\n","\u003cclass '__main__.SocialMF'\u003e iteration 60: loss = 3489.9050, delta_loss = 62.57324 learning_Rate = 0.01000 rmse=1.14829 mae=0.89424\n","\u003cclass '__main__.SocialMF'\u003e iteration 61: loss = 3429.1140, delta_loss = 60.79103 learning_Rate = 0.01000 rmse=1.14756 mae=0.89352\n","\u003cclass '__main__.SocialMF'\u003e iteration 62: loss = 3370.0434, delta_loss = 59.07057 learning_Rate = 0.01000 rmse=1.14687 mae=0.89282\n","\u003cclass '__main__.SocialMF'\u003e iteration 63: loss = 3312.6342, delta_loss = 57.40921 learning_Rate = 0.01000 rmse=1.14622 mae=0.89216\n","\u003cclass '__main__.SocialMF'\u003e iteration 64: loss = 3256.8297, delta_loss = 55.80450 learning_Rate = 0.01000 rmse=1.14560 mae=0.89153\n","\u003cclass '__main__.SocialMF'\u003e iteration 65: loss = 3202.5755, delta_loss = 54.25421 learning_Rate = 0.01000 rmse=1.14502 mae=0.89093\n","\u003cclass '__main__.SocialMF'\u003e iteration 66: loss = 3149.8193, delta_loss = 52.75622 learning_Rate = 0.01000 rmse=1.14448 mae=0.89035\n","\u003cclass '__main__.SocialMF'\u003e iteration 67: loss = 3098.5107, delta_loss = 51.30858 learning_Rate = 0.01000 rmse=1.14398 mae=0.88981\n","\u003cclass '__main__.SocialMF'\u003e iteration 68: loss = 3048.6013, delta_loss = 49.90941 learning_Rate = 0.01000 rmse=1.14350 mae=0.88929\n","\u003cclass '__main__.SocialMF'\u003e iteration 69: loss = 3000.0443, delta_loss = 48.55697 learning_Rate = 0.01000 rmse=1.14306 mae=0.88880\n","\u003cclass '__main__.SocialMF'\u003e iteration 70: loss = 2952.7948, delta_loss = 47.24957 learning_Rate = 0.01000 rmse=1.14265 mae=0.88834\n","\u003cclass '__main__.SocialMF'\u003e iteration 71: loss = 2906.8092, delta_loss = 45.98560 learning_Rate = 0.01000 rmse=1.14227 mae=0.88790\n","\u003cclass '__main__.SocialMF'\u003e iteration 72: loss = 2862.0457, delta_loss = 44.76351 learning_Rate = 0.01000 rmse=1.14192 mae=0.88748\n","\u003cclass '__main__.SocialMF'\u003e iteration 73: loss = 2818.4638, delta_loss = 43.58183 learning_Rate = 0.01000 rmse=1.14159 mae=0.88708\n","\u003cclass '__main__.SocialMF'\u003e iteration 74: loss = 2776.0247, delta_loss = 42.43909 learning_Rate = 0.01000 rmse=1.14129 mae=0.88671\n","\u003cclass '__main__.SocialMF'\u003e iteration 75: loss = 2734.6908, delta_loss = 41.33392 learning_Rate = 0.01000 rmse=1.14102 mae=0.88635\n","\u003cclass '__main__.SocialMF'\u003e iteration 76: loss = 2694.4258, delta_loss = 40.26497 learning_Rate = 0.01000 rmse=1.14077 mae=0.88601\n","\u003cclass '__main__.SocialMF'\u003e iteration 77: loss = 2655.1949, delta_loss = 39.23093 learning_Rate = 0.01000 rmse=1.14053 mae=0.88569\n","\u003cclass '__main__.SocialMF'\u003e iteration 78: loss = 2616.9644, delta_loss = 38.23053 learning_Rate = 0.01000 rmse=1.14031 mae=0.88538\n","\u003cclass '__main__.SocialMF'\u003e iteration 79: loss = 2579.7018, delta_loss = 37.26255 learning_Rate = 0.01000 rmse=1.14012 mae=0.88510\n","\u003cclass '__main__.SocialMF'\u003e iteration 80: loss = 2543.3760, delta_loss = 36.32582 learning_Rate = 0.01000 rmse=1.13995 mae=0.88483\n","\u003cclass '__main__.SocialMF'\u003e iteration 81: loss = 2507.9568, delta_loss = 35.41917 learning_Rate = 0.01000 rmse=1.13980 mae=0.88458\n","\u003cclass '__main__.SocialMF'\u003e iteration 82: loss = 2473.4153, delta_loss = 34.54152 learning_Rate = 0.01000 rmse=1.13965 mae=0.88434\n","\u003cclass '__main__.SocialMF'\u003e iteration 83: loss = 2439.7235, delta_loss = 33.69179 learning_Rate = 0.01000 rmse=1.13953 mae=0.88413\n","\u003cclass '__main__.SocialMF'\u003e iteration 84: loss = 2406.8546, delta_loss = 32.86895 learning_Rate = 0.01000 rmse=1.13942 mae=0.88392\n","\u003cclass '__main__.SocialMF'\u003e iteration 85: loss = 2374.7826, delta_loss = 32.07200 learning_Rate = 0.01000 rmse=1.13932 mae=0.88373\n","\u003cclass '__main__.SocialMF'\u003e iteration 86: loss = 2343.4826, delta_loss = 31.30000 learning_Rate = 0.01000 rmse=1.13923 mae=0.88355\n","\u003cclass '__main__.SocialMF'\u003e iteration 87: loss = 2312.9306, delta_loss = 30.55202 learning_Rate = 0.01000 rmse=1.13916 mae=0.88340\n","\u003cclass '__main__.SocialMF'\u003e iteration 88: loss = 2283.1034, delta_loss = 29.82718 learning_Rate = 0.01000 rmse=1.13910 mae=0.88325\n","\u003cclass '__main__.SocialMF'\u003e iteration 89: loss = 2253.9788, delta_loss = 29.12462 learning_Rate = 0.01000 rmse=1.13906 mae=0.88313\n","\u003cclass '__main__.SocialMF'\u003e iteration 90: loss = 2225.5352, delta_loss = 28.44354 learning_Rate = 0.01000 rmse=1.13902 mae=0.88302\n","\u003cclass '__main__.SocialMF'\u003e iteration 91: loss = 2197.7521, delta_loss = 27.78313 learning_Rate = 0.01000 rmse=1.13899 mae=0.88291\n","\u003cclass '__main__.SocialMF'\u003e iteration 92: loss = 2170.6094, delta_loss = 27.14265 learning_Rate = 0.01000 rmse=1.13896 mae=0.88281\n","\u003cclass '__main__.SocialMF'\u003e iteration 93: loss = 2144.0881, delta_loss = 26.52137 learning_Rate = 0.01000 rmse=1.13894 mae=0.88272\n","\u003cclass '__main__.SocialMF'\u003e iteration 94: loss = 2118.1695, delta_loss = 25.91861 learning_Rate = 0.01000 rmse=1.13893 mae=0.88263\n","\u003cclass '__main__.SocialMF'\u003e iteration 95: loss = 2092.8358, delta_loss = 25.33368 learning_Rate = 0.01000 rmse=1.13893 mae=0.88255\n","\u003cclass '__main__.SocialMF'\u003e iteration 96: loss = 2068.0698, delta_loss = 24.76595 learning_Rate = 0.01000 rmse=1.13894 mae=0.88248\n","\u003cclass '__main__.SocialMF'\u003e iteration 97: loss = 2043.8550, delta_loss = 24.21480 learning_Rate = 0.01000 rmse=1.13895 mae=0.88241\n","\u003cclass '__main__.SocialMF'\u003e iteration 98: loss = 2020.1754, delta_loss = 23.67965 learning_Rate = 0.01000 rmse=1.13897 mae=0.88235\n","\u003cclass '__main__.SocialMF'\u003e iteration 99: loss = 1997.0155, delta_loss = 23.15992 learning_Rate = 0.01000 rmse=1.13901 mae=0.88229\n","\u003cclass '__main__.SocialMF'\u003e iteration 100: loss = 1974.3604, delta_loss = 22.65508 learning_Rate = 0.01000 rmse=1.13904 mae=0.88223\n","the 1th cross validation training\n","\u003cclass '__main__.SocialMF'\u003e iteration 1: loss = 37810.0427, delta_loss = -37810.04271 learning_Rate = 0.01000 rmse=2.31090 mae=1.99464\n","\u003cclass '__main__.SocialMF'\u003e iteration 2: loss = 30436.0821, delta_loss = 7373.96064 learning_Rate = 0.01000 rmse=2.06003 mae=1.74552\n","\u003cclass '__main__.SocialMF'\u003e iteration 3: loss = 25900.1355, delta_loss = 4535.94656 learning_Rate = 0.01000 rmse=1.88585 mae=1.57377\n","\u003cclass '__main__.SocialMF'\u003e iteration 4: loss = 22799.4577, delta_loss = 3100.67779 learning_Rate = 0.01000 rmse=1.76175 mae=1.45347\n","\u003cclass '__main__.SocialMF'\u003e iteration 5: loss = 20519.5770, delta_loss = 2279.88069 learning_Rate = 0.01000 rmse=1.66965 mae=1.36570\n","\u003cclass '__main__.SocialMF'\u003e iteration 6: loss = 18746.7646, delta_loss = 1772.81242 learning_Rate = 0.01000 rmse=1.59835 mae=1.29887\n","\u003cclass '__main__.SocialMF'\u003e iteration 7: loss = 17311.3052, delta_loss = 1435.45945 learning_Rate = 0.01000 rmse=1.54167 mae=1.24645\n","\u003cclass '__main__.SocialMF'\u003e iteration 8: loss = 16114.2928, delta_loss = 1197.01236 learning_Rate = 0.01000 rmse=1.49568 mae=1.20418\n","\u003cclass '__main__.SocialMF'\u003e iteration 9: loss = 15094.1133, delta_loss = 1020.17948 learning_Rate = 0.01000 rmse=1.45772 mae=1.16916\n","\u003cclass '__main__.SocialMF'\u003e iteration 10: loss = 14210.0584, delta_loss = 884.05488 learning_Rate = 0.01000 rmse=1.42600 mae=1.14011\n","\u003cclass '__main__.SocialMF'\u003e iteration 11: loss = 13433.8403, delta_loss = 776.21814 learning_Rate = 0.01000 rmse=1.39919 mae=1.11597\n","\u003cclass '__main__.SocialMF'\u003e iteration 12: loss = 12744.9751, delta_loss = 688.86517 learning_Rate = 0.01000 rmse=1.37616 mae=1.09515\n","\u003cclass '__main__.SocialMF'\u003e iteration 13: loss = 12128.1391, delta_loss = 616.83600 learning_Rate = 0.01000 rmse=1.35619 mae=1.07703\n","\u003cclass '__main__.SocialMF'\u003e iteration 14: loss = 11571.5708, delta_loss = 556.56830 learning_Rate = 0.01000 rmse=1.33874 mae=1.06118\n","\u003cclass '__main__.SocialMF'\u003e iteration 15: loss = 11066.0556, delta_loss = 505.51527 learning_Rate = 0.01000 rmse=1.32337 mae=1.04721\n","\u003cclass '__main__.SocialMF'\u003e iteration 16: loss = 10604.2508, delta_loss = 461.80472 learning_Rate = 0.01000 rmse=1.30972 mae=1.03473\n","\u003cclass '__main__.SocialMF'\u003e iteration 17: loss = 10180.2216, delta_loss = 424.02926 learning_Rate = 0.01000 rmse=1.29755 mae=1.02358\n","\u003cclass '__main__.SocialMF'\u003e iteration 18: loss = 9789.1103, delta_loss = 391.11132 learning_Rate = 0.01000 rmse=1.28669 mae=1.01368\n","\u003cclass '__main__.SocialMF'\u003e iteration 19: loss = 9426.8973, delta_loss = 362.21299 learning_Rate = 0.01000 rmse=1.27691 mae=1.00474\n","\u003cclass '__main__.SocialMF'\u003e iteration 20: loss = 9090.2233, delta_loss = 336.67398 learning_Rate = 0.01000 rmse=1.26803 mae=0.99661\n","\u003cclass '__main__.SocialMF'\u003e iteration 21: loss = 8776.2555, delta_loss = 313.96778 learning_Rate = 0.01000 rmse=1.25994 mae=0.98918\n","\u003cclass '__main__.SocialMF'\u003e iteration 22: loss = 8482.5854, delta_loss = 293.67009 learning_Rate = 0.01000 rmse=1.25255 mae=0.98240\n","\u003cclass '__main__.SocialMF'\u003e iteration 23: loss = 8207.1497, delta_loss = 275.43569 learning_Rate = 0.01000 rmse=1.24572 mae=0.97611\n","\u003cclass '__main__.SocialMF'\u003e iteration 24: loss = 7948.1686, delta_loss = 258.98110 learning_Rate = 0.01000 rmse=1.23944 mae=0.97032\n","\u003cclass '__main__.SocialMF'\u003e iteration 25: loss = 7704.0970, delta_loss = 244.07163 learning_Rate = 0.01000 rmse=1.23366 mae=0.96493\n","\u003cclass '__main__.SocialMF'\u003e iteration 26: loss = 7473.5856, delta_loss = 230.51140 learning_Rate = 0.01000 rmse=1.22831 mae=0.95997\n","\u003cclass '__main__.SocialMF'\u003e iteration 27: loss = 7255.4499, delta_loss = 218.13569 learning_Rate = 0.01000 rmse=1.22335 mae=0.95536\n","\u003cclass '__main__.SocialMF'\u003e iteration 28: loss = 7048.6449, delta_loss = 206.80497 learning_Rate = 0.01000 rmse=1.21873 mae=0.95106\n","\u003cclass '__main__.SocialMF'\u003e iteration 29: loss = 6852.2447, delta_loss = 196.40028 learning_Rate = 0.01000 rmse=1.21438 mae=0.94703\n","\u003cclass '__main__.SocialMF'\u003e iteration 30: loss = 6665.4252, delta_loss = 186.81950 learning_Rate = 0.01000 rmse=1.21031 mae=0.94326\n","\u003cclass '__main__.SocialMF'\u003e iteration 31: loss = 6487.4507, delta_loss = 177.97441 learning_Rate = 0.01000 rmse=1.20647 mae=0.93970\n","\u003cclass '__main__.SocialMF'\u003e iteration 32: loss = 6317.6623, delta_loss = 169.78843 learning_Rate = 0.01000 rmse=1.20286 mae=0.93637\n","\u003cclass '__main__.SocialMF'\u003e iteration 33: loss = 6155.4677, delta_loss = 162.19464 learning_Rate = 0.01000 rmse=1.19944 mae=0.93323\n","\u003cclass '__main__.SocialMF'\u003e iteration 34: loss = 6000.3333, delta_loss = 155.13433 learning_Rate = 0.01000 rmse=1.19622 mae=0.93026\n","\u003cclass '__main__.SocialMF'\u003e iteration 35: loss = 5851.7776, delta_loss = 148.55575 learning_Rate = 0.01000 rmse=1.19317 mae=0.92744\n","\u003cclass '__main__.SocialMF'\u003e iteration 36: loss = 5709.3645, delta_loss = 142.41308 learning_Rate = 0.01000 rmse=1.19028 mae=0.92476\n","\u003cclass '__main__.SocialMF'\u003e iteration 37: loss = 5572.6989, delta_loss = 136.66563 learning_Rate = 0.01000 rmse=1.18753 mae=0.92220\n","\u003cclass '__main__.SocialMF'\u003e iteration 38: loss = 5441.4218, delta_loss = 131.27713 learning_Rate = 0.01000 rmse=1.18491 mae=0.91976\n","\u003cclass '__main__.SocialMF'\u003e iteration 39: loss = 5315.2066, delta_loss = 126.21519 learning_Rate = 0.01000 rmse=1.18242 mae=0.91744\n","\u003cclass '__main__.SocialMF'\u003e iteration 40: loss = 5193.7557, delta_loss = 121.45083 learning_Rate = 0.01000 rmse=1.18005 mae=0.91523\n","\u003cclass '__main__.SocialMF'\u003e iteration 41: loss = 5076.7977, delta_loss = 116.95805 learning_Rate = 0.01000 rmse=1.17782 mae=0.91313\n","\u003cclass '__main__.SocialMF'\u003e iteration 42: loss = 4964.0841, delta_loss = 112.71354 learning_Rate = 0.01000 rmse=1.17569 mae=0.91114\n","\u003cclass '__main__.SocialMF'\u003e iteration 43: loss = 4855.3878, delta_loss = 108.69636 learning_Rate = 0.01000 rmse=1.17368 mae=0.90925\n","\u003cclass '__main__.SocialMF'\u003e iteration 44: loss = 4750.5001, delta_loss = 104.88770 learning_Rate = 0.01000 rmse=1.17178 mae=0.90745\n","\u003cclass '__main__.SocialMF'\u003e iteration 45: loss = 4649.2294, delta_loss = 101.27066 learning_Rate = 0.01000 rmse=1.16997 mae=0.90575\n","\u003cclass '__main__.SocialMF'\u003e iteration 46: loss = 4551.3993, delta_loss = 97.83010 learning_Rate = 0.01000 rmse=1.16826 mae=0.90415\n","\u003cclass '__main__.SocialMF'\u003e iteration 47: loss = 4456.8469, delta_loss = 94.55240 learning_Rate = 0.01000 rmse=1.16664 mae=0.90262\n","\u003cclass '__main__.SocialMF'\u003e iteration 48: loss = 4365.4216, delta_loss = 91.42537 learning_Rate = 0.01000 rmse=1.16510 mae=0.90116\n","\u003cclass '__main__.SocialMF'\u003e iteration 49: loss = 4276.9835, delta_loss = 88.43808 learning_Rate = 0.01000 rmse=1.16364 mae=0.89976\n","\u003cclass '__main__.SocialMF'\u003e iteration 50: loss = 4191.4027, delta_loss = 85.58074 learning_Rate = 0.01000 rmse=1.16226 mae=0.89842\n","\u003cclass '__main__.SocialMF'\u003e iteration 51: loss = 4108.5582, delta_loss = 82.84456 learning_Rate = 0.01000 rmse=1.16094 mae=0.89714\n","\u003cclass '__main__.SocialMF'\u003e iteration 52: loss = 4028.3365, delta_loss = 80.22170 learning_Rate = 0.01000 rmse=1.15968 mae=0.89593\n","\u003cclass '__main__.SocialMF'\u003e iteration 53: loss = 3950.6314, delta_loss = 77.70511 learning_Rate = 0.01000 rmse=1.15849 mae=0.89476\n","\u003cclass '__main__.SocialMF'\u003e iteration 54: loss = 3875.3429, delta_loss = 75.28846 learning_Rate = 0.01000 rmse=1.15736 mae=0.89366\n","\u003cclass '__main__.SocialMF'\u003e iteration 55: loss = 3802.3768, delta_loss = 72.96608 learning_Rate = 0.01000 rmse=1.15629 mae=0.89262\n","\u003cclass '__main__.SocialMF'\u003e iteration 56: loss = 3731.6440, delta_loss = 70.73284 learning_Rate = 0.01000 rmse=1.15527 mae=0.89164\n","\u003cclass '__main__.SocialMF'\u003e iteration 57: loss = 3663.0599, delta_loss = 68.58410 learning_Rate = 0.01000 rmse=1.15431 mae=0.89071\n","\u003cclass '__main__.SocialMF'\u003e iteration 58: loss = 3596.5442, delta_loss = 66.51568 learning_Rate = 0.01000 rmse=1.15339 mae=0.88981\n","\u003cclass '__main__.SocialMF'\u003e iteration 59: loss = 3532.0205, delta_loss = 64.52373 learning_Rate = 0.01000 rmse=1.15253 mae=0.88895\n","\u003cclass '__main__.SocialMF'\u003e iteration 60: loss = 3469.4158, delta_loss = 62.60473 learning_Rate = 0.01000 rmse=1.15171 mae=0.88814\n","\u003cclass '__main__.SocialMF'\u003e iteration 61: loss = 3408.6603, delta_loss = 60.75547 learning_Rate = 0.01000 rmse=1.15094 mae=0.88736\n","\u003cclass '__main__.SocialMF'\u003e iteration 62: loss = 3349.6873, delta_loss = 58.97294 learning_Rate = 0.01000 rmse=1.15020 mae=0.88663\n","\u003cclass '__main__.SocialMF'\u003e iteration 63: loss = 3292.4330, delta_loss = 57.25435 learning_Rate = 0.01000 rmse=1.14951 mae=0.88593\n","\u003cclass '__main__.SocialMF'\u003e iteration 64: loss = 3236.8359, delta_loss = 55.59709 learning_Rate = 0.01000 rmse=1.14885 mae=0.88528\n","\u003cclass '__main__.SocialMF'\u003e iteration 65: loss = 3182.8372, delta_loss = 53.99868 learning_Rate = 0.01000 rmse=1.14823 mae=0.88468\n","\u003cclass '__main__.SocialMF'\u003e iteration 66: loss = 3130.3804, delta_loss = 52.45682 learning_Rate = 0.01000 rmse=1.14764 mae=0.88409\n","\u003cclass '__main__.SocialMF'\u003e iteration 67: loss = 3079.4111, delta_loss = 50.96927 learning_Rate = 0.01000 rmse=1.14708 mae=0.88352\n","\u003cclass '__main__.SocialMF'\u003e iteration 68: loss = 3029.8772, delta_loss = 49.53395 learning_Rate = 0.01000 rmse=1.14654 mae=0.88299\n","\u003cclass '__main__.SocialMF'\u003e iteration 69: loss = 2981.7284, delta_loss = 48.14882 learning_Rate = 0.01000 rmse=1.14605 mae=0.88249\n","\u003cclass '__main__.SocialMF'\u003e iteration 70: loss = 2934.9164, delta_loss = 46.81195 learning_Rate = 0.01000 rmse=1.14558 mae=0.88202\n","\u003cclass '__main__.SocialMF'\u003e iteration 71: loss = 2889.3949, delta_loss = 45.52150 learning_Rate = 0.01000 rmse=1.14513 mae=0.88156\n","\u003cclass '__main__.SocialMF'\u003e iteration 72: loss = 2845.1192, delta_loss = 44.27569 learning_Rate = 0.01000 rmse=1.14471 mae=0.88112\n","\u003cclass '__main__.SocialMF'\u003e iteration 73: loss = 2802.0464, delta_loss = 43.07278 learning_Rate = 0.01000 rmse=1.14432 mae=0.88071\n","\u003cclass '__main__.SocialMF'\u003e iteration 74: loss = 2760.1353, delta_loss = 41.91114 learning_Rate = 0.01000 rmse=1.14397 mae=0.88032\n","\u003cclass '__main__.SocialMF'\u003e iteration 75: loss = 2719.3461, delta_loss = 40.78918 learning_Rate = 0.01000 rmse=1.14364 mae=0.87997\n","\u003cclass '__main__.SocialMF'\u003e iteration 76: loss = 2679.6407, delta_loss = 39.70537 learning_Rate = 0.01000 rmse=1.14333 mae=0.87963\n","\u003cclass '__main__.SocialMF'\u003e iteration 77: loss = 2640.9825, delta_loss = 38.65823 learning_Rate = 0.01000 rmse=1.14304 mae=0.87931\n","\u003cclass '__main__.SocialMF'\u003e iteration 78: loss = 2603.3362, delta_loss = 37.64634 learning_Rate = 0.01000 rmse=1.14277 mae=0.87901\n","\u003cclass '__main__.SocialMF'\u003e iteration 79: loss = 2566.6678, delta_loss = 36.66835 learning_Rate = 0.01000 rmse=1.14252 mae=0.87872\n","\u003cclass '__main__.SocialMF'\u003e iteration 80: loss = 2530.9449, delta_loss = 35.72294 learning_Rate = 0.01000 rmse=1.14231 mae=0.87844\n","\u003cclass '__main__.SocialMF'\u003e iteration 81: loss = 2496.1360, delta_loss = 34.80886 learning_Rate = 0.01000 rmse=1.14212 mae=0.87818\n","\u003cclass '__main__.SocialMF'\u003e iteration 82: loss = 2462.2111, delta_loss = 33.92489 learning_Rate = 0.01000 rmse=1.14195 mae=0.87794\n","\u003cclass '__main__.SocialMF'\u003e iteration 83: loss = 2429.1413, delta_loss = 33.06987 learning_Rate = 0.01000 rmse=1.14180 mae=0.87773\n","\u003cclass '__main__.SocialMF'\u003e iteration 84: loss = 2396.8986, delta_loss = 32.24268 learning_Rate = 0.01000 rmse=1.14167 mae=0.87752\n","\u003cclass '__main__.SocialMF'\u003e iteration 85: loss = 2365.4563, delta_loss = 31.44225 learning_Rate = 0.01000 rmse=1.14155 mae=0.87733\n","\u003cclass '__main__.SocialMF'\u003e iteration 86: loss = 2334.7888, delta_loss = 30.66756 learning_Rate = 0.01000 rmse=1.14145 mae=0.87715\n","\u003cclass '__main__.SocialMF'\u003e iteration 87: loss = 2304.8712, delta_loss = 29.91761 learning_Rate = 0.01000 rmse=1.14135 mae=0.87697\n","\u003cclass '__main__.SocialMF'\u003e iteration 88: loss = 2275.6797, delta_loss = 29.19148 learning_Rate = 0.01000 rmse=1.14128 mae=0.87680\n","\u003cclass '__main__.SocialMF'\u003e iteration 89: loss = 2247.1915, delta_loss = 28.48824 learning_Rate = 0.01000 rmse=1.14122 mae=0.87666\n","\u003cclass '__main__.SocialMF'\u003e iteration 90: loss = 2219.3844, delta_loss = 27.80703 learning_Rate = 0.01000 rmse=1.14117 mae=0.87652\n","\u003cclass '__main__.SocialMF'\u003e iteration 91: loss = 2192.2374, delta_loss = 27.14703 learning_Rate = 0.01000 rmse=1.14112 mae=0.87639\n","\u003cclass '__main__.SocialMF'\u003e iteration 92: loss = 2165.7299, delta_loss = 26.50744 learning_Rate = 0.01000 rmse=1.14109 mae=0.87627\n","\u003cclass '__main__.SocialMF'\u003e iteration 93: loss = 2139.8424, delta_loss = 25.88750 learning_Rate = 0.01000 rmse=1.14108 mae=0.87616\n","\u003cclass '__main__.SocialMF'\u003e iteration 94: loss = 2114.5560, delta_loss = 25.28647 learning_Rate = 0.01000 rmse=1.14108 mae=0.87606\n","\u003cclass '__main__.SocialMF'\u003e iteration 95: loss = 2089.8523, delta_loss = 24.70367 learning_Rate = 0.01000 rmse=1.14109 mae=0.87598\n","\u003cclass '__main__.SocialMF'\u003e iteration 96: loss = 2065.7139, delta_loss = 24.13841 learning_Rate = 0.01000 rmse=1.14111 mae=0.87590\n","\u003cclass '__main__.SocialMF'\u003e iteration 97: loss = 2042.1238, delta_loss = 23.59008 learning_Rate = 0.01000 rmse=1.14113 mae=0.87583\n","\u003cclass '__main__.SocialMF'\u003e iteration 98: loss = 2019.0658, delta_loss = 23.05804 learning_Rate = 0.01000 rmse=1.14117 mae=0.87576\n","\u003cclass '__main__.SocialMF'\u003e iteration 99: loss = 1996.5240, delta_loss = 22.54173 learning_Rate = 0.01000 rmse=1.14122 mae=0.87571\n","\u003cclass '__main__.SocialMF'\u003e iteration 100: loss = 1974.4835, delta_loss = 22.04057 learning_Rate = 0.01000 rmse=1.14128 mae=0.87566\n","the 2th cross validation training\n","\u003cclass '__main__.SocialMF'\u003e iteration 1: loss = 37630.7128, delta_loss = -37630.71279 learning_Rate = 0.01000 rmse=2.28138 mae=1.98624\n","\u003cclass '__main__.SocialMF'\u003e iteration 2: loss = 30254.5130, delta_loss = 7376.19979 learning_Rate = 0.01000 rmse=2.03093 mae=1.73487\n","\u003cclass '__main__.SocialMF'\u003e iteration 3: loss = 25769.6882, delta_loss = 4484.82483 learning_Rate = 0.01000 rmse=1.85860 mae=1.56434\n","\u003cclass '__main__.SocialMF'\u003e iteration 4: loss = 22717.9147, delta_loss = 3051.77348 learning_Rate = 0.01000 rmse=1.73530 mae=1.44499\n","\u003cclass '__main__.SocialMF'\u003e iteration 5: loss = 20471.2204, delta_loss = 2246.69427 learning_Rate = 0.01000 rmse=1.64339 mae=1.35748\n","\u003cclass '__main__.SocialMF'\u003e iteration 6: loss = 18717.7067, delta_loss = 1753.51372 learning_Rate = 0.01000 rmse=1.57221 mae=1.29079\n","\u003cclass '__main__.SocialMF'\u003e iteration 7: loss = 17292.8540, delta_loss = 1424.85271 learning_Rate = 0.01000 rmse=1.51561 mae=1.23831\n","\u003cclass '__main__.SocialMF'\u003e iteration 8: loss = 16101.7367, delta_loss = 1191.11733 learning_Rate = 0.01000 rmse=1.46943 mae=1.19610\n","\u003cclass '__main__.SocialMF'\u003e iteration 9: loss = 15085.0086, delta_loss = 1016.72806 learning_Rate = 0.01000 rmse=1.43109 mae=1.16132\n","\u003cclass '__main__.SocialMF'\u003e iteration 10: loss = 14203.1294, delta_loss = 881.87919 learning_Rate = 0.01000 rmse=1.39892 mae=1.13217\n","\u003cclass '__main__.SocialMF'\u003e iteration 11: loss = 13428.4118, delta_loss = 774.71764 learning_Rate = 0.01000 rmse=1.37165 mae=1.10755\n","\u003cclass '__main__.SocialMF'\u003e iteration 12: loss = 12740.6992, delta_loss = 687.71261 learning_Rate = 0.01000 rmse=1.34828 mae=1.08663\n","\u003cclass '__main__.SocialMF'\u003e iteration 13: loss = 12124.8591, delta_loss = 615.84010 learning_Rate = 0.01000 rmse=1.32804 mae=1.06871\n","\u003cclass '__main__.SocialMF'\u003e iteration 14: loss = 11569.2459, delta_loss = 555.61315 learning_Rate = 0.01000 rmse=1.31043 mae=1.05320\n","\u003cclass '__main__.SocialMF'\u003e iteration 15: loss = 11064.7139, delta_loss = 504.53205 learning_Rate = 0.01000 rmse=1.29498 mae=1.03969\n","\u003cclass '__main__.SocialMF'\u003e iteration 16: loss = 10603.9577, delta_loss = 460.75618 learning_Rate = 0.01000 rmse=1.28123 mae=1.02772\n","\u003cclass '__main__.SocialMF'\u003e iteration 17: loss = 10181.0582, delta_loss = 422.89947 learning_Rate = 0.01000 rmse=1.26892 mae=1.01696\n","\u003cclass '__main__.SocialMF'\u003e iteration 18: loss = 9791.1599, delta_loss = 389.89827 learning_Rate = 0.01000 rmse=1.25784 mae=1.00733\n","\u003cclass '__main__.SocialMF'\u003e iteration 19: loss = 9430.2368, delta_loss = 360.92317 learning_Rate = 0.01000 rmse=1.24786 mae=0.99870\n","\u003cclass '__main__.SocialMF'\u003e iteration 20: loss = 9094.9182, delta_loss = 335.31852 learning_Rate = 0.01000 rmse=1.23878 mae=0.99084\n","\u003cclass '__main__.SocialMF'\u003e iteration 21: loss = 8782.3583, delta_loss = 312.55994 learning_Rate = 0.01000 rmse=1.23053 mae=0.98370\n","\u003cclass '__main__.SocialMF'\u003e iteration 22: loss = 8490.1347, delta_loss = 292.22360 learning_Rate = 0.01000 rmse=1.22298 mae=0.97722\n","\u003cclass '__main__.SocialMF'\u003e iteration 23: loss = 8216.1710, delta_loss = 273.96375 learning_Rate = 0.01000 rmse=1.21599 mae=0.97124\n","\u003cclass '__main__.SocialMF'\u003e iteration 24: loss = 7958.6751, delta_loss = 257.49590 learning_Rate = 0.01000 rmse=1.20954 mae=0.96571\n","\u003cclass '__main__.SocialMF'\u003e iteration 25: loss = 7716.0910, delta_loss = 242.58410 learning_Rate = 0.01000 rmse=1.20361 mae=0.96062\n","\u003cclass '__main__.SocialMF'\u003e iteration 26: loss = 7487.0598, delta_loss = 229.03117 learning_Rate = 0.01000 rmse=1.19810 mae=0.95585\n","\u003cclass '__main__.SocialMF'\u003e iteration 27: loss = 7270.3887, delta_loss = 216.67108 learning_Rate = 0.01000 rmse=1.19297 mae=0.95142\n","\u003cclass '__main__.SocialMF'\u003e iteration 28: loss = 7065.0256, delta_loss = 205.36315 learning_Rate = 0.01000 rmse=1.18820 mae=0.94725\n","\u003cclass '__main__.SocialMF'\u003e iteration 29: loss = 6870.0382, delta_loss = 194.98731 learning_Rate = 0.01000 rmse=1.18371 mae=0.94336\n","\u003cclass '__main__.SocialMF'\u003e iteration 30: loss = 6684.5978, delta_loss = 185.44046 learning_Rate = 0.01000 rmse=1.17952 mae=0.93974\n","\u003cclass '__main__.SocialMF'\u003e iteration 31: loss = 6507.9642, delta_loss = 176.63354 learning_Rate = 0.01000 rmse=1.17557 mae=0.93631\n","\u003cclass '__main__.SocialMF'\u003e iteration 32: loss = 6339.4751, delta_loss = 168.48918 learning_Rate = 0.01000 rmse=1.17186 mae=0.93308\n","\u003cclass '__main__.SocialMF'\u003e iteration 33: loss = 6178.5352, delta_loss = 160.93982 learning_Rate = 0.01000 rmse=1.16837 mae=0.93001\n","\u003cclass '__main__.SocialMF'\u003e iteration 34: loss = 6024.6091, delta_loss = 153.92615 learning_Rate = 0.01000 rmse=1.16509 mae=0.92717\n","\u003cclass '__main__.SocialMF'\u003e iteration 35: loss = 5877.2132, delta_loss = 147.39591 learning_Rate = 0.01000 rmse=1.16198 mae=0.92450\n","\u003cclass '__main__.SocialMF'\u003e iteration 36: loss = 5735.9103, delta_loss = 141.30284 learning_Rate = 0.01000 rmse=1.15906 mae=0.92196\n","\u003cclass '__main__.SocialMF'\u003e iteration 37: loss = 5600.3045, delta_loss = 135.60587 learning_Rate = 0.01000 rmse=1.15630 mae=0.91955\n","\u003cclass '__main__.SocialMF'\u003e iteration 38: loss = 5470.0361, delta_loss = 130.26840 learning_Rate = 0.01000 rmse=1.15369 mae=0.91727\n","\u003cclass '__main__.SocialMF'\u003e iteration 39: loss = 5344.7783, delta_loss = 125.25777 learning_Rate = 0.01000 rmse=1.15121 mae=0.91511\n","\u003cclass '__main__.SocialMF'\u003e iteration 40: loss = 5224.2336, delta_loss = 120.54475 learning_Rate = 0.01000 rmse=1.14885 mae=0.91306\n","\u003cclass '__main__.SocialMF'\u003e iteration 41: loss = 5108.1304, delta_loss = 116.10314 learning_Rate = 0.01000 rmse=1.14661 mae=0.91110\n","\u003cclass '__main__.SocialMF'\u003e iteration 42: loss = 4996.2210, delta_loss = 111.90944 learning_Rate = 0.01000 rmse=1.14446 mae=0.90923\n","\u003cclass '__main__.SocialMF'\u003e iteration 43: loss = 4888.2784, delta_loss = 107.94257 learning_Rate = 0.01000 rmse=1.14242 mae=0.90743\n","\u003cclass '__main__.SocialMF'\u003e iteration 44: loss = 4784.0948, delta_loss = 104.18358 learning_Rate = 0.01000 rmse=1.14047 mae=0.90571\n","\u003cclass '__main__.SocialMF'\u003e iteration 45: loss = 4683.4794, delta_loss = 100.61548 learning_Rate = 0.01000 rmse=1.13861 mae=0.90408\n","\u003cclass '__main__.SocialMF'\u003e iteration 46: loss = 4586.2564, delta_loss = 97.22299 learning_Rate = 0.01000 rmse=1.13684 mae=0.90252\n","\u003cclass '__main__.SocialMF'\u003e iteration 47: loss = 4492.2639, delta_loss = 93.99244 learning_Rate = 0.01000 rmse=1.13516 mae=0.90103\n","\u003cclass '__main__.SocialMF'\u003e iteration 48: loss = 4401.3524, delta_loss = 90.91154 learning_Rate = 0.01000 rmse=1.13356 mae=0.89962\n","\u003cclass '__main__.SocialMF'\u003e iteration 49: loss = 4313.3831, delta_loss = 87.96931 learning_Rate = 0.01000 rmse=1.13203 mae=0.89825\n","\u003cclass '__main__.SocialMF'\u003e iteration 50: loss = 4228.2272, delta_loss = 85.15589 learning_Rate = 0.01000 rmse=1.13056 mae=0.89693\n","\u003cclass '__main__.SocialMF'\u003e iteration 51: loss = 4145.7647, delta_loss = 82.46247 learning_Rate = 0.01000 rmse=1.12916 mae=0.89567\n","\u003cclass '__main__.SocialMF'\u003e iteration 52: loss = 4065.8836, delta_loss = 79.88114 learning_Rate = 0.01000 rmse=1.12782 mae=0.89445\n","\u003cclass '__main__.SocialMF'\u003e iteration 53: loss = 3988.4787, delta_loss = 77.40485 learning_Rate = 0.01000 rmse=1.12654 mae=0.89329\n","\u003cclass '__main__.SocialMF'\u003e iteration 54: loss = 3913.4515, delta_loss = 75.02723 learning_Rate = 0.01000 rmse=1.12533 mae=0.89219\n","\u003cclass '__main__.SocialMF'\u003e iteration 55: loss = 3840.7089, delta_loss = 72.74258 learning_Rate = 0.01000 rmse=1.12417 mae=0.89112\n","\u003cclass '__main__.SocialMF'\u003e iteration 56: loss = 3770.1631, delta_loss = 70.54576 learning_Rate = 0.01000 rmse=1.12306 mae=0.89010\n","\u003cclass '__main__.SocialMF'\u003e iteration 57: loss = 3701.7310, delta_loss = 68.43212 learning_Rate = 0.01000 rmse=1.12200 mae=0.88911\n","\u003cclass '__main__.SocialMF'\u003e iteration 58: loss = 3635.3336, delta_loss = 66.39743 learning_Rate = 0.01000 rmse=1.12099 mae=0.88817\n","\u003cclass '__main__.SocialMF'\u003e iteration 59: loss = 3570.8958, delta_loss = 64.43784 learning_Rate = 0.01000 rmse=1.12003 mae=0.88728\n","\u003cclass '__main__.SocialMF'\u003e iteration 60: loss = 3508.3459, delta_loss = 62.54981 learning_Rate = 0.01000 rmse=1.11912 mae=0.88641\n","\u003cclass '__main__.SocialMF'\u003e iteration 61: loss = 3447.6158, delta_loss = 60.73009 learning_Rate = 0.01000 rmse=1.11825 mae=0.88559\n","\u003cclass '__main__.SocialMF'\u003e iteration 62: loss = 3388.6402, delta_loss = 58.97566 learning_Rate = 0.01000 rmse=1.11744 mae=0.88479\n","\u003cclass '__main__.SocialMF'\u003e iteration 63: loss = 3331.3565, delta_loss = 57.28371 learning_Rate = 0.01000 rmse=1.11666 mae=0.88402\n","\u003cclass '__main__.SocialMF'\u003e iteration 64: loss = 3275.7049, delta_loss = 55.65161 learning_Rate = 0.01000 rmse=1.11592 mae=0.88329\n","\u003cclass '__main__.SocialMF'\u003e iteration 65: loss = 3221.6280, delta_loss = 54.07688 learning_Rate = 0.01000 rmse=1.11521 mae=0.88256\n","\u003cclass '__main__.SocialMF'\u003e iteration 66: loss = 3169.0708, delta_loss = 52.55720 learning_Rate = 0.01000 rmse=1.11452 mae=0.88187\n","\u003cclass '__main__.SocialMF'\u003e iteration 67: loss = 3117.9804, delta_loss = 51.09037 learning_Rate = 0.01000 rmse=1.11387 mae=0.88120\n","\u003cclass '__main__.SocialMF'\u003e iteration 68: loss = 3068.3061, delta_loss = 49.67428 learning_Rate = 0.01000 rmse=1.11325 mae=0.88057\n","\u003cclass '__main__.SocialMF'\u003e iteration 69: loss = 3019.9992, delta_loss = 48.30694 learning_Rate = 0.01000 rmse=1.11267 mae=0.87997\n","\u003cclass '__main__.SocialMF'\u003e iteration 70: loss = 2973.0127, delta_loss = 46.98646 learning_Rate = 0.01000 rmse=1.11212 mae=0.87941\n","\u003cclass '__main__.SocialMF'\u003e iteration 71: loss = 2927.3017, delta_loss = 45.71103 learning_Rate = 0.01000 rmse=1.11161 mae=0.87888\n","\u003cclass '__main__.SocialMF'\u003e iteration 72: loss = 2882.8228, delta_loss = 44.47891 learning_Rate = 0.01000 rmse=1.11110 mae=0.87836\n","\u003cclass '__main__.SocialMF'\u003e iteration 73: loss = 2839.5343, delta_loss = 43.28845 learning_Rate = 0.01000 rmse=1.11063 mae=0.87785\n","\u003cclass '__main__.SocialMF'\u003e iteration 74: loss = 2797.3963, delta_loss = 42.13806 learning_Rate = 0.01000 rmse=1.11017 mae=0.87736\n","\u003cclass '__main__.SocialMF'\u003e iteration 75: loss = 2756.3701, delta_loss = 41.02623 learning_Rate = 0.01000 rmse=1.10976 mae=0.87690\n","\u003cclass '__main__.SocialMF'\u003e iteration 76: loss = 2716.4186, delta_loss = 39.95149 learning_Rate = 0.01000 rmse=1.10937 mae=0.87648\n","\u003cclass '__main__.SocialMF'\u003e iteration 77: loss = 2677.5061, delta_loss = 38.91245 learning_Rate = 0.01000 rmse=1.10900 mae=0.87607\n","\u003cclass '__main__.SocialMF'\u003e iteration 78: loss = 2639.5984, delta_loss = 37.90776 learning_Rate = 0.01000 rmse=1.10865 mae=0.87568\n","\u003cclass '__main__.SocialMF'\u003e iteration 79: loss = 2602.6622, delta_loss = 36.93613 learning_Rate = 0.01000 rmse=1.10834 mae=0.87531\n","\u003cclass '__main__.SocialMF'\u003e iteration 80: loss = 2566.6659, delta_loss = 35.99632 learning_Rate = 0.01000 rmse=1.10803 mae=0.87496\n","\u003cclass '__main__.SocialMF'\u003e iteration 81: loss = 2531.5788, delta_loss = 35.08714 learning_Rate = 0.01000 rmse=1.10775 mae=0.87463\n","\u003cclass '__main__.SocialMF'\u003e iteration 82: loss = 2497.3713, delta_loss = 34.20744 learning_Rate = 0.01000 rmse=1.10748 mae=0.87431\n","\u003cclass '__main__.SocialMF'\u003e iteration 83: loss = 2464.0152, delta_loss = 33.35612 learning_Rate = 0.01000 rmse=1.10724 mae=0.87401\n","\u003cclass '__main__.SocialMF'\u003e iteration 84: loss = 2431.4831, delta_loss = 32.53211 learning_Rate = 0.01000 rmse=1.10701 mae=0.87372\n","\u003cclass '__main__.SocialMF'\u003e iteration 85: loss = 2399.7487, delta_loss = 31.73440 learning_Rate = 0.01000 rmse=1.10681 mae=0.87345\n","\u003cclass '__main__.SocialMF'\u003e iteration 86: loss = 2368.7867, delta_loss = 30.96199 learning_Rate = 0.01000 rmse=1.10662 mae=0.87320\n","\u003cclass '__main__.SocialMF'\u003e iteration 87: loss = 2338.5728, delta_loss = 30.21395 learning_Rate = 0.01000 rmse=1.10645 mae=0.87298\n","\u003cclass '__main__.SocialMF'\u003e iteration 88: loss = 2309.0834, delta_loss = 29.48936 learning_Rate = 0.01000 rmse=1.10628 mae=0.87275\n","\u003cclass '__main__.SocialMF'\u003e iteration 89: loss = 2280.2961, delta_loss = 28.78734 learning_Rate = 0.01000 rmse=1.10614 mae=0.87256\n","\u003cclass '__main__.SocialMF'\u003e iteration 90: loss = 2252.1890, delta_loss = 28.10706 learning_Rate = 0.01000 rmse=1.10602 mae=0.87239\n","\u003cclass '__main__.SocialMF'\u003e iteration 91: loss = 2224.7413, delta_loss = 27.44772 learning_Rate = 0.01000 rmse=1.10590 mae=0.87222\n","\u003cclass '__main__.SocialMF'\u003e iteration 92: loss = 2197.9328, delta_loss = 26.80852 learning_Rate = 0.01000 rmse=1.10580 mae=0.87207\n","\u003cclass '__main__.SocialMF'\u003e iteration 93: loss = 2171.7440, delta_loss = 26.18873 learning_Rate = 0.01000 rmse=1.10571 mae=0.87193\n","\u003cclass '__main__.SocialMF'\u003e iteration 94: loss = 2146.1564, delta_loss = 25.58764 learning_Rate = 0.01000 rmse=1.10564 mae=0.87180\n","\u003cclass '__main__.SocialMF'\u003e iteration 95: loss = 2121.1518, delta_loss = 25.00456 learning_Rate = 0.01000 rmse=1.10558 mae=0.87169\n","\u003cclass '__main__.SocialMF'\u003e iteration 96: loss = 2096.7130, delta_loss = 24.43883 learning_Rate = 0.01000 rmse=1.10553 mae=0.87159\n","\u003cclass '__main__.SocialMF'\u003e iteration 97: loss = 2072.8232, delta_loss = 23.88982 learning_Rate = 0.01000 rmse=1.10549 mae=0.87151\n","\u003cclass '__main__.SocialMF'\u003e iteration 98: loss = 2049.4663, delta_loss = 23.35693 learning_Rate = 0.01000 rmse=1.10546 mae=0.87143\n","\u003cclass '__main__.SocialMF'\u003e iteration 99: loss = 2026.6267, delta_loss = 22.83958 learning_Rate = 0.01000 rmse=1.10545 mae=0.87136\n","\u003cclass '__main__.SocialMF'\u003e iteration 100: loss = 2004.2895, delta_loss = 22.33722 learning_Rate = 0.01000 rmse=1.10544 mae=0.87130\n","the 3th cross validation training\n","\u003cclass '__main__.SocialMF'\u003e iteration 1: loss = 37814.4945, delta_loss = -37814.49453 learning_Rate = 0.01000 rmse=2.29799 mae=1.98940\n","\u003cclass '__main__.SocialMF'\u003e iteration 2: loss = 30345.2364, delta_loss = 7469.25817 learning_Rate = 0.01000 rmse=2.04827 mae=1.74186\n","\u003cclass '__main__.SocialMF'\u003e iteration 3: loss = 25784.5571, delta_loss = 4560.67923 learning_Rate = 0.01000 rmse=1.87780 mae=1.57353\n","\u003cclass '__main__.SocialMF'\u003e iteration 4: loss = 22693.5300, delta_loss = 3091.02708 learning_Rate = 0.01000 rmse=1.75572 mae=1.45396\n","\u003cclass '__main__.SocialMF'\u003e iteration 5: loss = 20429.2264, delta_loss = 2264.30363 learning_Rate = 0.01000 rmse=1.66475 mae=1.36645\n","\u003cclass '__main__.SocialMF'\u003e iteration 6: loss = 18667.3932, delta_loss = 1761.83319 learning_Rate = 0.01000 rmse=1.59463 mae=1.30023\n","\u003cclass '__main__.SocialMF'\u003e iteration 7: loss = 17237.7286, delta_loss = 1429.66463 learning_Rate = 0.01000 rmse=1.53896 mae=1.24815\n","\u003cclass '__main__.SocialMF'\u003e iteration 8: loss = 16043.1974, delta_loss = 1194.53117 learning_Rate = 0.01000 rmse=1.49406 mae=1.20690\n","\u003cclass '__main__.SocialMF'\u003e iteration 9: loss = 15023.7699, delta_loss = 1019.42756 learning_Rate = 0.01000 rmse=1.45700 mae=1.17276\n","\u003cclass '__main__.SocialMF'\u003e iteration 10: loss = 14139.6408, delta_loss = 884.12902 learning_Rate = 0.01000 rmse=1.42581 mae=1.14432\n","\u003cclass '__main__.SocialMF'\u003e iteration 11: loss = 13362.9757, delta_loss = 776.66519 learning_Rate = 0.01000 rmse=1.39920 mae=1.12016\n","\u003cclass '__main__.SocialMF'\u003e iteration 12: loss = 12673.5294, delta_loss = 689.44622 learning_Rate = 0.01000 rmse=1.37634 mae=1.09947\n","\u003cclass '__main__.SocialMF'\u003e iteration 13: loss = 12056.1288, delta_loss = 617.40067 learning_Rate = 0.01000 rmse=1.35661 mae=1.08160\n","\u003cclass '__main__.SocialMF'\u003e iteration 14: loss = 11499.1212, delta_loss = 557.00757 learning_Rate = 0.01000 rmse=1.33935 mae=1.06605\n","\u003cclass '__main__.SocialMF'\u003e iteration 15: loss = 10993.3718, delta_loss = 505.74937 learning_Rate = 0.01000 rmse=1.32418 mae=1.05253\n","\u003cclass '__main__.SocialMF'\u003e iteration 16: loss = 10531.5908, delta_loss = 461.78105 learning_Rate = 0.01000 rmse=1.31080 mae=1.04068\n","\u003cclass '__main__.SocialMF'\u003e iteration 17: loss = 10107.8702, delta_loss = 423.72056 learning_Rate = 0.01000 rmse=1.29884 mae=1.03000\n","\u003cclass '__main__.SocialMF'\u003e iteration 18: loss = 9717.3583, delta_loss = 390.51197 learning_Rate = 0.01000 rmse=1.28808 mae=1.02039\n","\u003cclass '__main__.SocialMF'\u003e iteration 19: loss = 9356.0242, delta_loss = 361.33406 learning_Rate = 0.01000 rmse=1.27835 mae=1.01169\n","\u003cclass '__main__.SocialMF'\u003e iteration 20: loss = 9020.4861, delta_loss = 335.53814 learning_Rate = 0.01000 rmse=1.26950 mae=1.00377\n","\u003cclass '__main__.SocialMF'\u003e iteration 21: loss = 8707.8813, delta_loss = 312.60471 learning_Rate = 0.01000 rmse=1.26141 mae=0.99653\n","\u003cclass '__main__.SocialMF'\u003e iteration 22: loss = 8415.7685, delta_loss = 292.11282 learning_Rate = 0.01000 rmse=1.25400 mae=0.98987\n","\u003cclass '__main__.SocialMF'\u003e iteration 23: loss = 8142.0507, delta_loss = 273.71779 learning_Rate = 0.01000 rmse=1.24721 mae=0.98379\n","\u003cclass '__main__.SocialMF'\u003e iteration 24: loss = 7884.9159, delta_loss = 257.13484 learning_Rate = 0.01000 rmse=1.24097 mae=0.97823\n","\u003cclass '__main__.SocialMF'\u003e iteration 25: loss = 7642.7892, delta_loss = 242.12669 learning_Rate = 0.01000 rmse=1.23519 mae=0.97304\n","\u003cclass '__main__.SocialMF'\u003e iteration 26: loss = 7414.2950, delta_loss = 228.49425 learning_Rate = 0.01000 rmse=1.22985 mae=0.96820\n","\u003cclass '__main__.SocialMF'\u003e iteration 27: loss = 7198.2257, delta_loss = 216.06923 learning_Rate = 0.01000 rmse=1.22484 mae=0.96368\n","\u003cclass '__main__.SocialMF'\u003e iteration 28: loss = 6993.5171, delta_loss = 204.70859 learning_Rate = 0.01000 rmse=1.22015 mae=0.95948\n","\u003cclass '__main__.SocialMF'\u003e iteration 29: loss = 6799.2272, delta_loss = 194.28995 learning_Rate = 0.01000 rmse=1.21578 mae=0.95556\n","\u003cclass '__main__.SocialMF'\u003e iteration 30: loss = 6614.5191, delta_loss = 184.70807 learning_Rate = 0.01000 rmse=1.21167 mae=0.95188\n","\u003cclass '__main__.SocialMF'\u003e iteration 31: loss = 6438.6471, delta_loss = 175.87201 learning_Rate = 0.01000 rmse=1.20782 mae=0.94845\n","\u003cclass '__main__.SocialMF'\u003e iteration 32: loss = 6270.9443, delta_loss = 167.70281 learning_Rate = 0.01000 rmse=1.20421 mae=0.94524\n","\u003cclass '__main__.SocialMF'\u003e iteration 33: loss = 6110.8127, delta_loss = 160.13160 learning_Rate = 0.01000 rmse=1.20081 mae=0.94221\n","\u003cclass '__main__.SocialMF'\u003e iteration 34: loss = 5957.7146, delta_loss = 153.09812 learning_Rate = 0.01000 rmse=1.19760 mae=0.93934\n","\u003cclass '__main__.SocialMF'\u003e iteration 35: loss = 5811.1652, delta_loss = 146.54942 learning_Rate = 0.01000 rmse=1.19457 mae=0.93661\n","\u003cclass '__main__.SocialMF'\u003e iteration 36: loss = 5670.7263, delta_loss = 140.43886 learning_Rate = 0.01000 rmse=1.19170 mae=0.93403\n","\u003cclass '__main__.SocialMF'\u003e iteration 37: loss = 5536.0011, delta_loss = 134.72522 learning_Rate = 0.01000 rmse=1.18900 mae=0.93160\n","\u003cclass '__main__.SocialMF'\u003e iteration 38: loss = 5406.6291, delta_loss = 129.37200 learning_Rate = 0.01000 rmse=1.18642 mae=0.92930\n","\u003cclass '__main__.SocialMF'\u003e iteration 39: loss = 5282.2823, delta_loss = 124.34678 learning_Rate = 0.01000 rmse=1.18397 mae=0.92712\n","\u003cclass '__main__.SocialMF'\u003e iteration 40: loss = 5162.6616, delta_loss = 119.62071 learning_Rate = 0.01000 rmse=1.18165 mae=0.92503\n","\u003cclass '__main__.SocialMF'\u003e iteration 41: loss = 5047.4935, delta_loss = 115.16809 learning_Rate = 0.01000 rmse=1.17944 mae=0.92303\n","\u003cclass '__main__.SocialMF'\u003e iteration 42: loss = 4936.5276, delta_loss = 110.96592 learning_Rate = 0.01000 rmse=1.17735 mae=0.92115\n","\u003cclass '__main__.SocialMF'\u003e iteration 43: loss = 4829.5340, delta_loss = 106.99363 learning_Rate = 0.01000 rmse=1.17537 mae=0.91938\n","\u003cclass '__main__.SocialMF'\u003e iteration 44: loss = 4726.3012, delta_loss = 103.23276 learning_Rate = 0.01000 rmse=1.17348 mae=0.91768\n","\u003cclass '__main__.SocialMF'\u003e iteration 45: loss = 4626.6345, delta_loss = 99.66670 learning_Rate = 0.01000 rmse=1.17169 mae=0.91607\n","\u003cclass '__main__.SocialMF'\u003e iteration 46: loss = 4530.3540, delta_loss = 96.28050 learning_Rate = 0.01000 rmse=1.16999 mae=0.91453\n","\u003cclass '__main__.SocialMF'\u003e iteration 47: loss = 4437.2934, delta_loss = 93.06064 learning_Rate = 0.01000 rmse=1.16835 mae=0.91305\n","\u003cclass '__main__.SocialMF'\u003e iteration 48: loss = 4347.2985, delta_loss = 89.99491 learning_Rate = 0.01000 rmse=1.16680 mae=0.91165\n","\u003cclass '__main__.SocialMF'\u003e iteration 49: loss = 4260.2262, delta_loss = 87.07222 learning_Rate = 0.01000 rmse=1.16531 mae=0.91031\n","\u003cclass '__main__.SocialMF'\u003e iteration 50: loss = 4175.9437, delta_loss = 84.28251 learning_Rate = 0.01000 rmse=1.16389 mae=0.90903\n","\u003cclass '__main__.SocialMF'\u003e iteration 51: loss = 4094.3271, delta_loss = 81.61665 learning_Rate = 0.01000 rmse=1.16252 mae=0.90779\n","\u003cclass '__main__.SocialMF'\u003e iteration 52: loss = 4015.2608, delta_loss = 79.06630 learning_Rate = 0.01000 rmse=1.16121 mae=0.90661\n","\u003cclass '__main__.SocialMF'\u003e iteration 53: loss = 3938.6369, delta_loss = 76.62390 learning_Rate = 0.01000 rmse=1.15996 mae=0.90547\n","\u003cclass '__main__.SocialMF'\u003e iteration 54: loss = 3864.3543, delta_loss = 74.28254 learning_Rate = 0.01000 rmse=1.15875 mae=0.90437\n","\u003cclass '__main__.SocialMF'\u003e iteration 55: loss = 3792.3184, delta_loss = 72.03594 learning_Rate = 0.01000 rmse=1.15759 mae=0.90332\n","\u003cclass '__main__.SocialMF'\u003e iteration 56: loss = 3722.4400, delta_loss = 69.87835 learning_Rate = 0.01000 rmse=1.15647 mae=0.90230\n","\u003cclass '__main__.SocialMF'\u003e iteration 57: loss = 3654.6355, delta_loss = 67.80458 learning_Rate = 0.01000 rmse=1.15541 mae=0.90136\n","\u003cclass '__main__.SocialMF'\u003e iteration 58: loss = 3588.8256, delta_loss = 65.80985 learning_Rate = 0.01000 rmse=1.15441 mae=0.90046\n","\u003cclass '__main__.SocialMF'\u003e iteration 59: loss = 3524.9358, delta_loss = 63.88983 learning_Rate = 0.01000 rmse=1.15345 mae=0.89959\n","\u003cclass '__main__.SocialMF'\u003e iteration 60: loss = 3462.8952, delta_loss = 62.04058 learning_Rate = 0.01000 rmse=1.15254 mae=0.89876\n","\u003cclass '__main__.SocialMF'\u003e iteration 61: loss = 3402.6367, delta_loss = 60.25850 learning_Rate = 0.01000 rmse=1.15168 mae=0.89798\n","\u003cclass '__main__.SocialMF'\u003e iteration 62: loss = 3344.0964, delta_loss = 58.54028 learning_Rate = 0.01000 rmse=1.15086 mae=0.89724\n","\u003cclass '__main__.SocialMF'\u003e iteration 63: loss = 3287.2135, delta_loss = 56.88291 learning_Rate = 0.01000 rmse=1.15007 mae=0.89653\n","\u003cclass '__main__.SocialMF'\u003e iteration 64: loss = 3231.9299, delta_loss = 55.28364 learning_Rate = 0.01000 rmse=1.14932 mae=0.89585\n","\u003cclass '__main__.SocialMF'\u003e iteration 65: loss = 3178.1900, delta_loss = 53.73991 learning_Rate = 0.01000 rmse=1.14861 mae=0.89521\n","\u003cclass '__main__.SocialMF'\u003e iteration 66: loss = 3125.9406, delta_loss = 52.24938 learning_Rate = 0.01000 rmse=1.14793 mae=0.89457\n","\u003cclass '__main__.SocialMF'\u003e iteration 67: loss = 3075.1307, delta_loss = 50.80986 learning_Rate = 0.01000 rmse=1.14728 mae=0.89397\n","\u003cclass '__main__.SocialMF'\u003e iteration 68: loss = 3025.7114, delta_loss = 49.41933 learning_Rate = 0.01000 rmse=1.14666 mae=0.89339\n","\u003cclass '__main__.SocialMF'\u003e iteration 69: loss = 2977.6355, delta_loss = 48.07588 learning_Rate = 0.01000 rmse=1.14606 mae=0.89282\n","\u003cclass '__main__.SocialMF'\u003e iteration 70: loss = 2930.8578, delta_loss = 46.77772 learning_Rate = 0.01000 rmse=1.14549 mae=0.89228\n","\u003cclass '__main__.SocialMF'\u003e iteration 71: loss = 2885.3346, delta_loss = 45.52316 learning_Rate = 0.01000 rmse=1.14495 mae=0.89177\n","\u003cclass '__main__.SocialMF'\u003e iteration 72: loss = 2841.0241, delta_loss = 44.31058 learning_Rate = 0.01000 rmse=1.14445 mae=0.89129\n","\u003cclass '__main__.SocialMF'\u003e iteration 73: loss = 2797.8856, delta_loss = 43.13846 learning_Rate = 0.01000 rmse=1.14397 mae=0.89083\n","\u003cclass '__main__.SocialMF'\u003e iteration 74: loss = 2755.8803, delta_loss = 42.00533 learning_Rate = 0.01000 rmse=1.14352 mae=0.89039\n","\u003cclass '__main__.SocialMF'\u003e iteration 75: loss = 2714.9705, delta_loss = 40.90977 learning_Rate = 0.01000 rmse=1.14309 mae=0.88997\n","\u003cclass '__main__.SocialMF'\u003e iteration 76: loss = 2675.1201, delta_loss = 39.85042 learning_Rate = 0.01000 rmse=1.14269 mae=0.88957\n","\u003cclass '__main__.SocialMF'\u003e iteration 77: loss = 2636.2941, delta_loss = 38.82598 learning_Rate = 0.01000 rmse=1.14232 mae=0.88919\n","\u003cclass '__main__.SocialMF'\u003e iteration 78: loss = 2598.4589, delta_loss = 37.83516 learning_Rate = 0.01000 rmse=1.14196 mae=0.88881\n","\u003cclass '__main__.SocialMF'\u003e iteration 79: loss = 2561.5822, delta_loss = 36.87675 learning_Rate = 0.01000 rmse=1.14163 mae=0.88845\n","\u003cclass '__main__.SocialMF'\u003e iteration 80: loss = 2525.6326, delta_loss = 35.94955 learning_Rate = 0.01000 rmse=1.14130 mae=0.88811\n","\u003cclass '__main__.SocialMF'\u003e iteration 81: loss = 2490.5802, delta_loss = 35.05241 learning_Rate = 0.01000 rmse=1.14099 mae=0.88778\n","\u003cclass '__main__.SocialMF'\u003e iteration 82: loss = 2456.3960, delta_loss = 34.18422 learning_Rate = 0.01000 rmse=1.14070 mae=0.88745\n","\u003cclass '__main__.SocialMF'\u003e iteration 83: loss = 2423.0521, delta_loss = 33.34391 learning_Rate = 0.01000 rmse=1.14042 mae=0.88714\n","\u003cclass '__main__.SocialMF'\u003e iteration 84: loss = 2390.5217, delta_loss = 32.53042 learning_Rate = 0.01000 rmse=1.14016 mae=0.88685\n","\u003cclass '__main__.SocialMF'\u003e iteration 85: loss = 2358.7789, delta_loss = 31.74276 learning_Rate = 0.01000 rmse=1.13991 mae=0.88656\n","\u003cclass '__main__.SocialMF'\u003e iteration 86: loss = 2327.7990, delta_loss = 30.97994 learning_Rate = 0.01000 rmse=1.13967 mae=0.88629\n","\u003cclass '__main__.SocialMF'\u003e iteration 87: loss = 2297.5579, delta_loss = 30.24104 learning_Rate = 0.01000 rmse=1.13945 mae=0.88602\n","\u003cclass '__main__.SocialMF'\u003e iteration 88: loss = 2268.0328, delta_loss = 29.52516 learning_Rate = 0.01000 rmse=1.13924 mae=0.88578\n","\u003cclass '__main__.SocialMF'\u003e iteration 89: loss = 2239.2014, delta_loss = 28.83141 learning_Rate = 0.01000 rmse=1.13905 mae=0.88554\n","\u003cclass '__main__.SocialMF'\u003e iteration 90: loss = 2211.0424, delta_loss = 28.15898 learning_Rate = 0.01000 rmse=1.13887 mae=0.88531\n","\u003cclass '__main__.SocialMF'\u003e iteration 91: loss = 2183.5353, delta_loss = 27.50705 learning_Rate = 0.01000 rmse=1.13870 mae=0.88509\n","\u003cclass '__main__.SocialMF'\u003e iteration 92: loss = 2156.6605, delta_loss = 26.87486 learning_Rate = 0.01000 rmse=1.13853 mae=0.88487\n","\u003cclass '__main__.SocialMF'\u003e iteration 93: loss = 2130.3988, delta_loss = 26.26166 learning_Rate = 0.01000 rmse=1.13837 mae=0.88465\n","\u003cclass '__main__.SocialMF'\u003e iteration 94: loss = 2104.7321, delta_loss = 25.66676 learning_Rate = 0.01000 rmse=1.13822 mae=0.88446\n","\u003cclass '__main__.SocialMF'\u003e iteration 95: loss = 2079.6426, delta_loss = 25.08947 learning_Rate = 0.01000 rmse=1.13809 mae=0.88427\n","\u003cclass '__main__.SocialMF'\u003e iteration 96: loss = 2055.1135, delta_loss = 24.52914 learning_Rate = 0.01000 rmse=1.13796 mae=0.88409\n","\u003cclass '__main__.SocialMF'\u003e iteration 97: loss = 2031.1283, delta_loss = 23.98516 learning_Rate = 0.01000 rmse=1.13785 mae=0.88393\n","\u003cclass '__main__.SocialMF'\u003e iteration 98: loss = 2007.6714, delta_loss = 23.45693 learning_Rate = 0.01000 rmse=1.13775 mae=0.88378\n","\u003cclass '__main__.SocialMF'\u003e iteration 99: loss = 1984.7275, delta_loss = 22.94387 learning_Rate = 0.01000 rmse=1.13767 mae=0.88364\n","\u003cclass '__main__.SocialMF'\u003e iteration 100: loss = 1962.2821, delta_loss = 22.44545 learning_Rate = 0.01000 rmse=1.13759 mae=0.88351\n","the 4th cross validation training\n","\u003cclass '__main__.SocialMF'\u003e iteration 1: loss = 37943.5924, delta_loss = -37943.59241 learning_Rate = 0.01000 rmse=2.27490 mae=1.96416\n","\u003cclass '__main__.SocialMF'\u003e iteration 2: loss = 30353.3708, delta_loss = 7590.22158 learning_Rate = 0.01000 rmse=2.01488 mae=1.70318\n","\u003cclass '__main__.SocialMF'\u003e iteration 3: loss = 25734.4625, delta_loss = 4618.90829 learning_Rate = 0.01000 rmse=1.83858 mae=1.52791\n","\u003cclass '__main__.SocialMF'\u003e iteration 4: loss = 22607.1730, delta_loss = 3127.28955 learning_Rate = 0.01000 rmse=1.71383 mae=1.40757\n","\u003cclass '__main__.SocialMF'\u003e iteration 5: loss = 20325.5603, delta_loss = 2281.61266 learning_Rate = 0.01000 rmse=1.62172 mae=1.32091\n","\u003cclass '__main__.SocialMF'\u003e iteration 6: loss = 18560.5312, delta_loss = 1765.02915 learning_Rate = 0.01000 rmse=1.55088 mae=1.25563\n","\u003cclass '__main__.SocialMF'\u003e iteration 7: loss = 17135.7869, delta_loss = 1424.74431 learning_Rate = 0.01000 rmse=1.49501 mae=1.20496\n","\u003cclass '__main__.SocialMF'\u003e iteration 8: loss = 15949.8411, delta_loss = 1185.94573 learning_Rate = 0.01000 rmse=1.45014 mae=1.16476\n","\u003cclass '__main__.SocialMF'\u003e iteration 9: loss = 14940.1152, delta_loss = 1009.72596 learning_Rate = 0.01000 rmse=1.41326 mae=1.13160\n","\u003cclass '__main__.SocialMF'\u003e iteration 10: loss = 14065.5583, delta_loss = 874.55687 learning_Rate = 0.01000 rmse=1.38263 mae=1.10406\n","\u003cclass '__main__.SocialMF'\u003e iteration 11: loss = 13297.7894, delta_loss = 767.76892 learning_Rate = 0.01000 rmse=1.35674 mae=1.08078\n","\u003cclass '__main__.SocialMF'\u003e iteration 12: loss = 12616.3490, delta_loss = 681.44041 learning_Rate = 0.01000 rmse=1.33457 mae=1.06096\n","\u003cclass '__main__.SocialMF'\u003e iteration 13: loss = 12006.0028, delta_loss = 610.34616 learning_Rate = 0.01000 rmse=1.31540 mae=1.04393\n","\u003cclass '__main__.SocialMF'\u003e iteration 14: loss = 11455.1137, delta_loss = 550.88911 learning_Rate = 0.01000 rmse=1.29878 mae=1.02911\n","\u003cclass '__main__.SocialMF'\u003e iteration 15: loss = 10954.6033, delta_loss = 500.51035 learning_Rate = 0.01000 rmse=1.28432 mae=1.01617\n","\u003cclass '__main__.SocialMF'\u003e iteration 16: loss = 10497.2614, delta_loss = 457.34194 learning_Rate = 0.01000 rmse=1.27164 mae=1.00490\n","\u003cclass '__main__.SocialMF'\u003e iteration 17: loss = 10077.2706, delta_loss = 419.99078 learning_Rate = 0.01000 rmse=1.26050 mae=0.99504\n","\u003cclass '__main__.SocialMF'\u003e iteration 18: loss = 9689.8723, delta_loss = 387.39833 learning_Rate = 0.01000 rmse=1.25059 mae=0.98630\n","\u003cclass '__main__.SocialMF'\u003e iteration 19: loss = 9331.1256, delta_loss = 358.74666 learning_Rate = 0.01000 rmse=1.24164 mae=0.97836\n","\u003cclass '__main__.SocialMF'\u003e iteration 20: loss = 8997.7316, delta_loss = 333.39405 learning_Rate = 0.01000 rmse=1.23356 mae=0.97110\n","\u003cclass '__main__.SocialMF'\u003e iteration 21: loss = 8686.9015, delta_loss = 310.83010 learning_Rate = 0.01000 rmse=1.22626 mae=0.96453\n","\u003cclass '__main__.SocialMF'\u003e iteration 22: loss = 8396.2578, delta_loss = 290.64371 learning_Rate = 0.01000 rmse=1.21958 mae=0.95852\n","\u003cclass '__main__.SocialMF'\u003e iteration 23: loss = 8123.7578, delta_loss = 272.50000 learning_Rate = 0.01000 rmse=1.21349 mae=0.95302\n","\u003cclass '__main__.SocialMF'\u003e iteration 24: loss = 7867.6344, delta_loss = 256.12336 learning_Rate = 0.01000 rmse=1.20793 mae=0.94799\n","\u003cclass '__main__.SocialMF'\u003e iteration 25: loss = 7626.3496, delta_loss = 241.28483 learning_Rate = 0.01000 rmse=1.20281 mae=0.94333\n","\u003cclass '__main__.SocialMF'\u003e iteration 26: loss = 7398.5571, delta_loss = 227.79254 learning_Rate = 0.01000 rmse=1.19807 mae=0.93900\n","\u003cclass '__main__.SocialMF'\u003e iteration 27: loss = 7183.0726, delta_loss = 215.48444 learning_Rate = 0.01000 rmse=1.19371 mae=0.93499\n","\u003cclass '__main__.SocialMF'\u003e iteration 28: loss = 6978.8499, delta_loss = 204.22266 learning_Rate = 0.01000 rmse=1.18964 mae=0.93130\n","\u003cclass '__main__.SocialMF'\u003e iteration 29: loss = 6784.9608, delta_loss = 193.88910 learning_Rate = 0.01000 rmse=1.18586 mae=0.92785\n","\u003cclass '__main__.SocialMF'\u003e iteration 30: loss = 6600.5789, delta_loss = 184.38194 learning_Rate = 0.01000 rmse=1.18232 mae=0.92460\n","\u003cclass '__main__.SocialMF'\u003e iteration 31: loss = 6424.9660, delta_loss = 175.61294 learning_Rate = 0.01000 rmse=1.17899 mae=0.92154\n","\u003cclass '__main__.SocialMF'\u003e iteration 32: loss = 6257.4608, delta_loss = 167.50517 learning_Rate = 0.01000 rmse=1.17587 mae=0.91865\n","\u003cclass '__main__.SocialMF'\u003e iteration 33: loss = 6097.4695, delta_loss = 159.99125 learning_Rate = 0.01000 rmse=1.17295 mae=0.91594\n","\u003cclass '__main__.SocialMF'\u003e iteration 34: loss = 5944.4576, delta_loss = 153.01194 learning_Rate = 0.01000 rmse=1.17021 mae=0.91341\n","\u003cclass '__main__.SocialMF'\u003e iteration 35: loss = 5797.9427, delta_loss = 146.51490 learning_Rate = 0.01000 rmse=1.16764 mae=0.91102\n","\u003cclass '__main__.SocialMF'\u003e iteration 36: loss = 5657.4889, delta_loss = 140.45379 learning_Rate = 0.01000 rmse=1.16520 mae=0.90876\n","\u003cclass '__main__.SocialMF'\u003e iteration 37: loss = 5522.7015, delta_loss = 134.78739 learning_Rate = 0.01000 rmse=1.16289 mae=0.90663\n","\u003cclass '__main__.SocialMF'\u003e iteration 38: loss = 5393.2225, delta_loss = 129.47904 learning_Rate = 0.01000 rmse=1.16069 mae=0.90459\n","\u003cclass '__main__.SocialMF'\u003e iteration 39: loss = 5268.7265, delta_loss = 124.49598 learning_Rate = 0.01000 rmse=1.15861 mae=0.90265\n","\u003cclass '__main__.SocialMF'\u003e iteration 40: loss = 5148.9175, delta_loss = 119.80897 learning_Rate = 0.01000 rmse=1.15664 mae=0.90081\n","\u003cclass '__main__.SocialMF'\u003e iteration 41: loss = 5033.5257, delta_loss = 115.39183 learning_Rate = 0.01000 rmse=1.15478 mae=0.89906\n","\u003cclass '__main__.SocialMF'\u003e iteration 42: loss = 4922.3046, delta_loss = 111.22113 learning_Rate = 0.01000 rmse=1.15300 mae=0.89738\n","\u003cclass '__main__.SocialMF'\u003e iteration 43: loss = 4815.0287, delta_loss = 107.27591 learning_Rate = 0.01000 rmse=1.15132 mae=0.89578\n","\u003cclass '__main__.SocialMF'\u003e iteration 44: loss = 4711.4913, delta_loss = 103.53738 learning_Rate = 0.01000 rmse=1.14973 mae=0.89425\n","\u003cclass '__main__.SocialMF'\u003e iteration 45: loss = 4611.5025, delta_loss = 99.98875 learning_Rate = 0.01000 rmse=1.14820 mae=0.89280\n","\u003cclass '__main__.SocialMF'\u003e iteration 46: loss = 4514.8876, delta_loss = 96.61496 learning_Rate = 0.01000 rmse=1.14676 mae=0.89143\n","\u003cclass '__main__.SocialMF'\u003e iteration 47: loss = 4421.4850, delta_loss = 93.40257 learning_Rate = 0.01000 rmse=1.14541 mae=0.89014\n","\u003cclass '__main__.SocialMF'\u003e iteration 48: loss = 4331.1455, delta_loss = 90.33953 learning_Rate = 0.01000 rmse=1.14413 mae=0.88891\n","\u003cclass '__main__.SocialMF'\u003e iteration 49: loss = 4243.7304, delta_loss = 87.41507 learning_Rate = 0.01000 rmse=1.14291 mae=0.88774\n","\u003cclass '__main__.SocialMF'\u003e iteration 50: loss = 4159.1108, delta_loss = 84.61956 learning_Rate = 0.01000 rmse=1.14176 mae=0.88665\n","\u003cclass '__main__.SocialMF'\u003e iteration 51: loss = 4077.1665, delta_loss = 81.94436 learning_Rate = 0.01000 rmse=1.14067 mae=0.88561\n","\u003cclass '__main__.SocialMF'\u003e iteration 52: loss = 3997.7848, delta_loss = 79.38173 learning_Rate = 0.01000 rmse=1.13964 mae=0.88462\n","\u003cclass '__main__.SocialMF'\u003e iteration 53: loss = 3920.8601, delta_loss = 76.92470 learning_Rate = 0.01000 rmse=1.13865 mae=0.88366\n","\u003cclass '__main__.SocialMF'\u003e iteration 54: loss = 3846.2930, delta_loss = 74.56702 learning_Rate = 0.01000 rmse=1.13771 mae=0.88275\n","\u003cclass '__main__.SocialMF'\u003e iteration 55: loss = 3773.9900, delta_loss = 72.30303 learning_Rate = 0.01000 rmse=1.13682 mae=0.88188\n","\u003cclass '__main__.SocialMF'\u003e iteration 56: loss = 3703.8624, delta_loss = 70.12758 learning_Rate = 0.01000 rmse=1.13598 mae=0.88105\n","\u003cclass '__main__.SocialMF'\u003e iteration 57: loss = 3635.8264, delta_loss = 68.03601 learning_Rate = 0.01000 rmse=1.13517 mae=0.88025\n","\u003cclass '__main__.SocialMF'\u003e iteration 58: loss = 3569.8024, delta_loss = 66.02405 learning_Rate = 0.01000 rmse=1.13442 mae=0.87949\n","\u003cclass '__main__.SocialMF'\u003e iteration 59: loss = 3505.7146, delta_loss = 64.08778 learning_Rate = 0.01000 rmse=1.13371 mae=0.87876\n","\u003cclass '__main__.SocialMF'\u003e iteration 60: loss = 3443.4910, delta_loss = 62.22358 learning_Rate = 0.01000 rmse=1.13303 mae=0.87807\n","\u003cclass '__main__.SocialMF'\u003e iteration 61: loss = 3383.0629, delta_loss = 60.42809 learning_Rate = 0.01000 rmse=1.13240 mae=0.87741\n","\u003cclass '__main__.SocialMF'\u003e iteration 62: loss = 3324.3647, delta_loss = 58.69819 learning_Rate = 0.01000 rmse=1.13181 mae=0.87680\n","\u003cclass '__main__.SocialMF'\u003e iteration 63: loss = 3267.3337, delta_loss = 57.03096 learning_Rate = 0.01000 rmse=1.13125 mae=0.87621\n","\u003cclass '__main__.SocialMF'\u003e iteration 64: loss = 3211.9101, delta_loss = 55.42366 learning_Rate = 0.01000 rmse=1.13074 mae=0.87566\n","\u003cclass '__main__.SocialMF'\u003e iteration 65: loss = 3158.0364, delta_loss = 53.87369 learning_Rate = 0.01000 rmse=1.13028 mae=0.87516\n","\u003cclass '__main__.SocialMF'\u003e iteration 66: loss = 3105.6578, delta_loss = 52.37862 learning_Rate = 0.01000 rmse=1.12983 mae=0.87468\n","\u003cclass '__main__.SocialMF'\u003e iteration 67: loss = 3054.7217, delta_loss = 50.93612 learning_Rate = 0.01000 rmse=1.12942 mae=0.87424\n","\u003cclass '__main__.SocialMF'\u003e iteration 68: loss = 3005.1777, delta_loss = 49.54400 learning_Rate = 0.01000 rmse=1.12904 mae=0.87381\n","\u003cclass '__main__.SocialMF'\u003e iteration 69: loss = 2956.9775, delta_loss = 48.20015 learning_Rate = 0.01000 rmse=1.12867 mae=0.87340\n","\u003cclass '__main__.SocialMF'\u003e iteration 70: loss = 2910.0749, delta_loss = 46.90258 learning_Rate = 0.01000 rmse=1.12834 mae=0.87302\n","\u003cclass '__main__.SocialMF'\u003e iteration 71: loss = 2864.4255, delta_loss = 45.64939 learning_Rate = 0.01000 rmse=1.12803 mae=0.87266\n","\u003cclass '__main__.SocialMF'\u003e iteration 72: loss = 2819.9868, delta_loss = 44.43875 learning_Rate = 0.01000 rmse=1.12774 mae=0.87232\n","\u003cclass '__main__.SocialMF'\u003e iteration 73: loss = 2776.7178, delta_loss = 43.26893 learning_Rate = 0.01000 rmse=1.12747 mae=0.87201\n","\u003cclass '__main__.SocialMF'\u003e iteration 74: loss = 2734.5796, delta_loss = 42.13827 learning_Rate = 0.01000 rmse=1.12723 mae=0.87170\n","\u003cclass '__main__.SocialMF'\u003e iteration 75: loss = 2693.5344, delta_loss = 41.04518 learning_Rate = 0.01000 rmse=1.12701 mae=0.87143\n","\u003cclass '__main__.SocialMF'\u003e iteration 76: loss = 2653.5463, delta_loss = 39.98814 learning_Rate = 0.01000 rmse=1.12682 mae=0.87118\n","\u003cclass '__main__.SocialMF'\u003e iteration 77: loss = 2614.5805, delta_loss = 38.96571 learning_Rate = 0.01000 rmse=1.12664 mae=0.87093\n","\u003cclass '__main__.SocialMF'\u003e iteration 78: loss = 2576.6040, delta_loss = 37.97651 learning_Rate = 0.01000 rmse=1.12648 mae=0.87070\n","\u003cclass '__main__.SocialMF'\u003e iteration 79: loss = 2539.5848, delta_loss = 37.01921 learning_Rate = 0.01000 rmse=1.12633 mae=0.87049\n","\u003cclass '__main__.SocialMF'\u003e iteration 80: loss = 2503.4923, delta_loss = 36.09257 learning_Rate = 0.01000 rmse=1.12621 mae=0.87028\n","\u003cclass '__main__.SocialMF'\u003e iteration 81: loss = 2468.2969, delta_loss = 35.19537 learning_Rate = 0.01000 rmse=1.12610 mae=0.87010\n","\u003cclass '__main__.SocialMF'\u003e iteration 82: loss = 2433.9704, delta_loss = 34.32647 learning_Rate = 0.01000 rmse=1.12602 mae=0.86993\n","\u003cclass '__main__.SocialMF'\u003e iteration 83: loss = 2400.4856, delta_loss = 33.48478 learning_Rate = 0.01000 rmse=1.12595 mae=0.86977\n","\u003cclass '__main__.SocialMF'\u003e iteration 84: loss = 2367.8164, delta_loss = 32.66927 learning_Rate = 0.01000 rmse=1.12589 mae=0.86963\n","\u003cclass '__main__.SocialMF'\u003e iteration 85: loss = 2335.9374, delta_loss = 31.87892 learning_Rate = 0.01000 rmse=1.12584 mae=0.86949\n","\u003cclass '__main__.SocialMF'\u003e iteration 86: loss = 2304.8246, delta_loss = 31.11280 learning_Rate = 0.01000 rmse=1.12581 mae=0.86937\n","\u003cclass '__main__.SocialMF'\u003e iteration 87: loss = 2274.4546, delta_loss = 30.37001 learning_Rate = 0.01000 rmse=1.12580 mae=0.86924\n","\u003cclass '__main__.SocialMF'\u003e iteration 88: loss = 2244.8050, delta_loss = 29.64968 learning_Rate = 0.01000 rmse=1.12580 mae=0.86914\n","\u003cclass '__main__.SocialMF'\u003e iteration 89: loss = 2215.8540, delta_loss = 28.95099 learning_Rate = 0.01000 rmse=1.12581 mae=0.86904\n","\u003cclass '__main__.SocialMF'\u003e iteration 90: loss = 2187.5808, delta_loss = 28.27316 learning_Rate = 0.01000 rmse=1.12584 mae=0.86896\n","\u003cclass '__main__.SocialMF'\u003e iteration 91: loss = 2159.9654, delta_loss = 27.61543 learning_Rate = 0.01000 rmse=1.12588 mae=0.86888\n","\u003cclass '__main__.SocialMF'\u003e iteration 92: loss = 2132.9883, delta_loss = 26.97710 learning_Rate = 0.01000 rmse=1.12593 mae=0.86881\n","\u003cclass '__main__.SocialMF'\u003e iteration 93: loss = 2106.6308, delta_loss = 26.35748 learning_Rate = 0.01000 rmse=1.12598 mae=0.86876\n","\u003cclass '__main__.SocialMF'\u003e iteration 94: loss = 2080.8749, delta_loss = 25.75592 learning_Rate = 0.01000 rmse=1.12605 mae=0.86871\n","\u003cclass '__main__.SocialMF'\u003e iteration 95: loss = 2055.7031, delta_loss = 25.17179 learning_Rate = 0.01000 rmse=1.12613 mae=0.86867\n","\u003cclass '__main__.SocialMF'\u003e iteration 96: loss = 2031.0986, delta_loss = 24.60450 learning_Rate = 0.01000 rmse=1.12621 mae=0.86863\n","\u003cclass '__main__.SocialMF'\u003e iteration 97: loss = 2007.0451, delta_loss = 24.05347 learning_Rate = 0.01000 rmse=1.12630 mae=0.86861\n","\u003cclass '__main__.SocialMF'\u003e iteration 98: loss = 1983.5270, delta_loss = 23.51816 learning_Rate = 0.01000 rmse=1.12640 mae=0.86858\n","\u003cclass '__main__.SocialMF'\u003e iteration 99: loss = 1960.5289, delta_loss = 22.99803 learning_Rate = 0.01000 rmse=1.12651 mae=0.86856\n","\u003cclass '__main__.SocialMF'\u003e iteration 100: loss = 1938.0363, delta_loss = 22.49260 learning_Rate = 0.01000 rmse=1.12663 mae=0.86856\n","the rmses are [1.1390400510263918, 1.1412820283341585, 1.105443304219144, 1.137592492460851, 1.1266268172542173]\n","the maes are [0.8822343768048981, 0.8756590073529413, 0.8713004926108385, 0.8835071698979026, 0.8685560004576157]\n","the average of rmses is 1.1299969386589526 \n","the average of maes is 0.8762514094248394 \n"]}],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")\n","import numpy as np\n","#from mf import MF\n","#from reader.trust import TrustGetter\n","\n","\n","class SocialMF(MF):\n","    \"\"\"\n","    docstring for SocialMF\n","\n","    Jamali M, Ester M. A matrix factorization technique with trust propagation for recommendation in social networks[C]//Proceedings of the fourth ACM conference on Recommender systems. ACM, 2010: 135-142.\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(SocialMF, self).__init__()\n","        # self.config.lr=0.0001\n","        self.config.alpha = 1  # 0.8 rmse=0.87605\n","        self.tg = TrustGetter()  # loading trust data\n","        # self.init_model()\n","\n","    def train_model(self, k):\n","        super(SocialMF, self).train_model(k)\n","        iteration = 0\n","        while iteration \u003c self.config.maxIter:\n","            self.loss = 0\n","            for index, line in enumerate(self.rg.trainSet()):\n","                user, item, rating = line\n","                u = self.rg.user[user]\n","                i = self.rg.item[item]\n","                error = rating - self.predict(user, item)\n","                self.loss += error ** 2\n","                p, q = self.P[u], self.Q[i]\n","\n","                total_weight = 0.0\n","                social_term = np.zeros(self.config.factor)\n","                followees = self.tg.get_followees(user)  # get user u's focus lsit\n","                for followee in followees:\n","                    weight = followees[followee]\n","                    if self.rg.containsUser(followee):\n","                        uk = self.P[self.rg.user[followee]]\n","                        social_term += weight * uk\n","                        total_weight += weight\n","\n","                if total_weight != 0:\n","                    social_term = p - social_term / total_weight\n","\n","                social_term_a = np.zeros(self.config.factor)\n","                total_count = 0\n","                followers = self.tg.get_followers(user)\n","                for follower in followers:\n","                    if self.rg.containsUser(follower):\n","                        total_count += 1\n","                        uv = self.P[self.rg.user[follower]]\n","                        social_term_m = np.zeros(self.config.factor)\n","                        total_weight = 0.0\n","                        followees = self.tg.get_followees(follower)\n","                        for followee in followees:\n","                            weight = followees[followee]\n","                            if self.rg.containsUser(followee):\n","                                uw = self.P[self.rg.user[followee]]\n","                                social_term_m += weight * uw\n","                                total_weight += weight\n","                        if total_weight != 0:\n","                            social_term_a += uv - social_term_m / total_weight\n","                if total_count != 0:\n","                    social_term_a /= total_count\n","\n","                # update latent vectors\n","                self.P[u] += self.config.lr * (\n","                        error * q - self.config.alpha * social_term + self.config.alpha * social_term_a - self.config.lambdaP * p)  #\n","                self.Q[i] += self.config.lr * (error * p - self.config.lambdaQ * q)\n","\n","                self.loss += self.config.alpha * social_term.dot(social_term).sum()\n","\n","            self.loss += self.config.lambdaP * (self.P * self.P).sum() + self.config.lambdaQ * (self.Q * self.Q).sum()\n","\n","            iteration += 1\n","            if self.isConverged(iteration):\n","                break\n","\n","\n","if __name__ == '__main__':\n","    rmses = []\n","    maes = []\n","    tcsr = SocialMF()\n","    # print(bmf.rg.trainSet_u[1])\n","    for i in range(tcsr.config.k_fold_num):\n","        print('the %dth cross validation training' % i)\n","        tcsr.train_model(i)\n","        rmse, mae = tcsr.predict_model()\n","        rmses.append(rmse)\n","        maes.append(mae)\n","    rmse_avg = sum(rmses) / 5\n","    mae_avg = sum(maes) / 5\n","    print(\"the rmses are %s\" % rmses)\n","    print(\"the maes are %s\" % maes)\n","    print(\"the average of rmses is %s \" % rmse_avg)\n","    print(\"the average of maes is %s \" % mae_avg)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2250663,"status":"ok","timestamp":1621252663616,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"9Tj9Dv-UxcNu","outputId":"92dc6127-f45e-40ad-907b-47c35baee525"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'dataset_name': 'CiaoDVD', 'k_fold_num': 5, 'rating_path': '/content/drive/MyDrive/data/ft_ratings.txt', 'rating_cv_path': '../data/cv/', 'trust_path': '/content/drive/MyDrive/data/ft_trust_SimRank.txt', 'sep': ' ', 'random_state': 0, 'size': 0.6, 'min_val': 0.5, 'max_val': 4.0, 'coldUserRating': 5, 'factor': 10, 'threshold': 0.0001, 'lr': 0.01, 'maxIter': 100, 'lambdaP': 0.001, 'lambdaQ': 0.001, 'gamma': 0, 'isEarlyStopping': False, 'result_path': '../results/', 'model_path': 'model/', 'result_log_path': 'log/'}\n","the 0th cross validation training\n","\u003cclass '__main__.RSTE'\u003e iteration 1: loss = 38741.0519, delta_loss = -38741.05188 learning_Rate = 0.01000 rmse=2.42631 mae=2.11286\n","\u003cclass '__main__.RSTE'\u003e iteration 2: loss = 33339.3918, delta_loss = 5401.66010 learning_Rate = 0.01000 rmse=2.22120 mae=1.90069\n","\u003cclass '__main__.RSTE'\u003e iteration 3: loss = 29422.6877, delta_loss = 3916.70411 learning_Rate = 0.01000 rmse=2.06471 mae=1.73999\n","\u003cclass '__main__.RSTE'\u003e iteration 4: loss = 26538.5206, delta_loss = 2884.16709 learning_Rate = 0.01000 rmse=1.94341 mae=1.61889\n","\u003cclass '__main__.RSTE'\u003e iteration 5: loss = 24339.3035, delta_loss = 2199.21704 learning_Rate = 0.01000 rmse=1.84691 mae=1.52484\n","\u003cclass '__main__.RSTE'\u003e iteration 6: loss = 22592.3021, delta_loss = 1747.00141 learning_Rate = 0.01000 rmse=1.76794 mae=1.44957\n","\u003cclass '__main__.RSTE'\u003e iteration 7: loss = 21156.8366, delta_loss = 1435.46557 learning_Rate = 0.01000 rmse=1.70263 mae=1.38824\n","\u003cclass '__main__.RSTE'\u003e iteration 8: loss = 19947.3486, delta_loss = 1209.48798 learning_Rate = 0.01000 rmse=1.64758 mae=1.33704\n","\u003cclass '__main__.RSTE'\u003e iteration 9: loss = 18908.3993, delta_loss = 1038.94929 learning_Rate = 0.01000 rmse=1.60047 mae=1.29358\n","\u003cclass '__main__.RSTE'\u003e iteration 10: loss = 18001.8141, delta_loss = 906.58518 learning_Rate = 0.01000 rmse=1.55983 mae=1.25632\n","\u003cclass '__main__.RSTE'\u003e iteration 11: loss = 17200.2582, delta_loss = 801.55591 learning_Rate = 0.01000 rmse=1.52433 mae=1.22385\n","\u003cclass '__main__.RSTE'\u003e iteration 12: loss = 16483.6778, delta_loss = 716.58041 learning_Rate = 0.01000 rmse=1.49317 mae=1.19565\n","\u003cclass '__main__.RSTE'\u003e iteration 13: loss = 15837.0828, delta_loss = 646.59502 learning_Rate = 0.01000 rmse=1.46554 mae=1.17066\n","\u003cclass '__main__.RSTE'\u003e iteration 14: loss = 15249.0657, delta_loss = 588.01710 learning_Rate = 0.01000 rmse=1.44095 mae=1.14837\n","\u003cclass '__main__.RSTE'\u003e iteration 15: loss = 14710.7850, delta_loss = 538.28066 learning_Rate = 0.01000 rmse=1.41907 mae=1.12854\n","\u003cclass '__main__.RSTE'\u003e iteration 16: loss = 14215.2614, delta_loss = 495.52366 learning_Rate = 0.01000 rmse=1.39942 mae=1.11066\n","\u003cclass '__main__.RSTE'\u003e iteration 17: loss = 13756.8874, delta_loss = 458.37391 learning_Rate = 0.01000 rmse=1.38183 mae=1.09469\n","\u003cclass '__main__.RSTE'\u003e iteration 18: loss = 13331.0851, delta_loss = 425.80236 learning_Rate = 0.01000 rmse=1.36591 mae=1.08030\n","\u003cclass '__main__.RSTE'\u003e iteration 19: loss = 12934.0620, delta_loss = 397.02304 learning_Rate = 0.01000 rmse=1.35144 mae=1.06738\n","\u003cclass '__main__.RSTE'\u003e iteration 20: loss = 12562.6375, delta_loss = 371.42450 learning_Rate = 0.01000 rmse=1.33833 mae=1.05578\n","\u003cclass '__main__.RSTE'\u003e iteration 21: loss = 12214.1147, delta_loss = 348.52287 learning_Rate = 0.01000 rmse=1.32631 mae=1.04520\n","\u003cclass '__main__.RSTE'\u003e iteration 22: loss = 11886.1855, delta_loss = 327.92916 learning_Rate = 0.01000 rmse=1.31531 mae=1.03548\n","\u003cclass '__main__.RSTE'\u003e iteration 23: loss = 11576.8592, delta_loss = 309.32627 learning_Rate = 0.01000 rmse=1.30522 mae=1.02657\n","\u003cclass '__main__.RSTE'\u003e iteration 24: loss = 11284.4067, delta_loss = 292.45259 learning_Rate = 0.01000 rmse=1.29591 mae=1.01834\n","\u003cclass '__main__.RSTE'\u003e iteration 25: loss = 11007.3167, delta_loss = 277.08999 learning_Rate = 0.01000 rmse=1.28732 mae=1.01075\n","\u003cclass '__main__.RSTE'\u003e iteration 26: loss = 10744.2617, delta_loss = 263.05498 learning_Rate = 0.01000 rmse=1.27940 mae=1.00370\n","\u003cclass '__main__.RSTE'\u003e iteration 27: loss = 10494.0697, delta_loss = 250.19195 learning_Rate = 0.01000 rmse=1.27209 mae=0.99716\n","\u003cclass '__main__.RSTE'\u003e iteration 28: loss = 10255.7017, delta_loss = 238.36808 learning_Rate = 0.01000 rmse=1.26533 mae=0.99113\n","\u003cclass '__main__.RSTE'\u003e iteration 29: loss = 10028.2324, delta_loss = 227.46930 learning_Rate = 0.01000 rmse=1.25905 mae=0.98555\n","\u003cclass '__main__.RSTE'\u003e iteration 30: loss = 9810.8352, delta_loss = 217.39712 learning_Rate = 0.01000 rmse=1.25323 mae=0.98038\n","\u003cclass '__main__.RSTE'\u003e iteration 31: loss = 9602.7691, delta_loss = 208.06611 learning_Rate = 0.01000 rmse=1.24780 mae=0.97555\n","\u003cclass '__main__.RSTE'\u003e iteration 32: loss = 9403.3673, delta_loss = 199.40180 learning_Rate = 0.01000 rmse=1.24274 mae=0.97105\n","\u003cclass '__main__.RSTE'\u003e iteration 33: loss = 9212.0282, delta_loss = 191.33909 learning_Rate = 0.01000 rmse=1.23804 mae=0.96687\n","\u003cclass '__main__.RSTE'\u003e iteration 34: loss = 9028.2074, delta_loss = 183.82079 learning_Rate = 0.01000 rmse=1.23365 mae=0.96298\n","\u003cclass '__main__.RSTE'\u003e iteration 35: loss = 8851.4109, delta_loss = 176.79654 learning_Rate = 0.01000 rmse=1.22956 mae=0.95933\n","\u003cclass '__main__.RSTE'\u003e iteration 36: loss = 8681.1891, delta_loss = 170.22180 learning_Rate = 0.01000 rmse=1.22572 mae=0.95592\n","\u003cclass '__main__.RSTE'\u003e iteration 37: loss = 8517.1320, delta_loss = 164.05710 learning_Rate = 0.01000 rmse=1.22209 mae=0.95271\n","\u003cclass '__main__.RSTE'\u003e iteration 38: loss = 8358.8647, delta_loss = 158.26733 learning_Rate = 0.01000 rmse=1.21866 mae=0.94965\n","\u003cclass '__main__.RSTE'\u003e iteration 39: loss = 8206.0435, delta_loss = 152.82119 learning_Rate = 0.01000 rmse=1.21540 mae=0.94675\n","\u003cclass '__main__.RSTE'\u003e iteration 40: loss = 8058.3528, delta_loss = 147.69068 learning_Rate = 0.01000 rmse=1.21232 mae=0.94399\n","\u003cclass '__main__.RSTE'\u003e iteration 41: loss = 7915.5021, delta_loss = 142.85070 learning_Rate = 0.01000 rmse=1.20943 mae=0.94140\n","\u003cclass '__main__.RSTE'\u003e iteration 42: loss = 7777.2234, delta_loss = 138.27868 learning_Rate = 0.01000 rmse=1.20668 mae=0.93893\n","\u003cclass '__main__.RSTE'\u003e iteration 43: loss = 7643.2691, delta_loss = 133.95429 learning_Rate = 0.01000 rmse=1.20407 mae=0.93656\n","\u003cclass '__main__.RSTE'\u003e iteration 44: loss = 7513.4100, delta_loss = 129.85915 learning_Rate = 0.01000 rmse=1.20160 mae=0.93431\n","\u003cclass '__main__.RSTE'\u003e iteration 45: loss = 7387.4334, delta_loss = 125.97661 learning_Rate = 0.01000 rmse=1.19925 mae=0.93217\n","\u003cclass '__main__.RSTE'\u003e iteration 46: loss = 7265.1418, delta_loss = 122.29158 learning_Rate = 0.01000 rmse=1.19702 mae=0.93014\n","\u003cclass '__main__.RSTE'\u003e iteration 47: loss = 7146.3515, delta_loss = 118.79030 learning_Rate = 0.01000 rmse=1.19491 mae=0.92822\n","\u003cclass '__main__.RSTE'\u003e iteration 48: loss = 7030.8913, delta_loss = 115.46023 learning_Rate = 0.01000 rmse=1.19290 mae=0.92639\n","\u003cclass '__main__.RSTE'\u003e iteration 49: loss = 6918.6014, delta_loss = 112.28991 learning_Rate = 0.01000 rmse=1.19099 mae=0.92465\n","\u003cclass '__main__.RSTE'\u003e iteration 50: loss = 6809.3325, delta_loss = 109.26884 learning_Rate = 0.01000 rmse=1.18916 mae=0.92299\n","\u003cclass '__main__.RSTE'\u003e iteration 51: loss = 6702.9452, delta_loss = 106.38737 learning_Rate = 0.01000 rmse=1.18742 mae=0.92141\n","\u003cclass '__main__.RSTE'\u003e iteration 52: loss = 6599.3085, delta_loss = 103.63665 learning_Rate = 0.01000 rmse=1.18577 mae=0.91989\n","\u003cclass '__main__.RSTE'\u003e iteration 53: loss = 6498.3000, delta_loss = 101.00849 learning_Rate = 0.01000 rmse=1.18419 mae=0.91842\n","\u003cclass '__main__.RSTE'\u003e iteration 54: loss = 6399.8047, delta_loss = 98.49535 learning_Rate = 0.01000 rmse=1.18268 mae=0.91700\n","\u003cclass '__main__.RSTE'\u003e iteration 55: loss = 6303.7144, delta_loss = 96.09023 learning_Rate = 0.01000 rmse=1.18122 mae=0.91563\n","\u003cclass '__main__.RSTE'\u003e iteration 56: loss = 6209.9278, delta_loss = 93.78667 learning_Rate = 0.01000 rmse=1.17982 mae=0.91430\n","\u003cclass '__main__.RSTE'\u003e iteration 57: loss = 6118.3491, delta_loss = 91.57863 learning_Rate = 0.01000 rmse=1.17847 mae=0.91303\n","\u003cclass '__main__.RSTE'\u003e iteration 58: loss = 6028.8886, delta_loss = 89.46054 learning_Rate = 0.01000 rmse=1.17720 mae=0.91182\n","\u003cclass '__main__.RSTE'\u003e iteration 59: loss = 5941.4614, delta_loss = 87.42718 learning_Rate = 0.01000 rmse=1.17596 mae=0.91064\n","\u003cclass '__main__.RSTE'\u003e iteration 60: loss = 5855.9877, delta_loss = 85.47368 learning_Rate = 0.01000 rmse=1.17479 mae=0.90951\n","\u003cclass '__main__.RSTE'\u003e iteration 61: loss = 5772.3922, delta_loss = 83.59550 learning_Rate = 0.01000 rmse=1.17366 mae=0.90843\n","\u003cclass '__main__.RSTE'\u003e iteration 62: loss = 5690.6038, delta_loss = 81.78838 learning_Rate = 0.01000 rmse=1.17258 mae=0.90738\n","\u003cclass '__main__.RSTE'\u003e iteration 63: loss = 5610.5555, delta_loss = 80.04836 learning_Rate = 0.01000 rmse=1.17154 mae=0.90638\n","\u003cclass '__main__.RSTE'\u003e iteration 64: loss = 5532.1838, delta_loss = 78.37169 learning_Rate = 0.01000 rmse=1.17056 mae=0.90542\n","\u003cclass '__main__.RSTE'\u003e iteration 65: loss = 5455.4289, delta_loss = 76.75487 learning_Rate = 0.01000 rmse=1.16961 mae=0.90450\n","\u003cclass '__main__.RSTE'\u003e iteration 66: loss = 5380.2343, delta_loss = 75.19462 learning_Rate = 0.01000 rmse=1.16869 mae=0.90360\n","\u003cclass '__main__.RSTE'\u003e iteration 67: loss = 5306.5465, delta_loss = 73.68784 learning_Rate = 0.01000 rmse=1.16781 mae=0.90274\n","\u003cclass '__main__.RSTE'\u003e iteration 68: loss = 5234.3149, delta_loss = 72.23162 learning_Rate = 0.01000 rmse=1.16697 mae=0.90191\n","\u003cclass '__main__.RSTE'\u003e iteration 69: loss = 5163.4916, delta_loss = 70.82324 learning_Rate = 0.01000 rmse=1.16616 mae=0.90113\n","\u003cclass '__main__.RSTE'\u003e iteration 70: loss = 5094.0315, delta_loss = 69.46011 learning_Rate = 0.01000 rmse=1.16538 mae=0.90036\n","\u003cclass '__main__.RSTE'\u003e iteration 71: loss = 5025.8917, delta_loss = 68.13983 learning_Rate = 0.01000 rmse=1.16462 mae=0.89962\n","\u003cclass '__main__.RSTE'\u003e iteration 72: loss = 4959.0316, delta_loss = 66.86012 learning_Rate = 0.01000 rmse=1.16389 mae=0.89890\n","\u003cclass '__main__.RSTE'\u003e iteration 73: loss = 4893.4127, delta_loss = 65.61883 learning_Rate = 0.01000 rmse=1.16319 mae=0.89822\n","\u003cclass '__main__.RSTE'\u003e iteration 74: loss = 4828.9988, delta_loss = 64.41395 learning_Rate = 0.01000 rmse=1.16253 mae=0.89757\n","\u003cclass '__main__.RSTE'\u003e iteration 75: loss = 4765.7552, delta_loss = 63.24360 learning_Rate = 0.01000 rmse=1.16188 mae=0.89693\n","\u003cclass '__main__.RSTE'\u003e iteration 76: loss = 4703.6492, delta_loss = 62.10600 learning_Rate = 0.01000 rmse=1.16126 mae=0.89632\n","\u003cclass '__main__.RSTE'\u003e iteration 77: loss = 4642.6497, delta_loss = 60.99948 learning_Rate = 0.01000 rmse=1.16066 mae=0.89574\n","\u003cclass '__main__.RSTE'\u003e iteration 78: loss = 4582.7272, delta_loss = 59.92248 learning_Rate = 0.01000 rmse=1.16010 mae=0.89518\n","\u003cclass '__main__.RSTE'\u003e iteration 79: loss = 4523.8537, delta_loss = 58.87353 learning_Rate = 0.01000 rmse=1.15957 mae=0.89466\n","\u003cclass '__main__.RSTE'\u003e iteration 80: loss = 4466.0024, delta_loss = 57.85128 learning_Rate = 0.01000 rmse=1.15905 mae=0.89415\n","\u003cclass '__main__.RSTE'\u003e iteration 81: loss = 4409.1480, delta_loss = 56.85443 learning_Rate = 0.01000 rmse=1.15856 mae=0.89366\n","\u003cclass '__main__.RSTE'\u003e iteration 82: loss = 4353.2662, delta_loss = 55.88180 learning_Rate = 0.01000 rmse=1.15809 mae=0.89320\n","\u003cclass '__main__.RSTE'\u003e iteration 83: loss = 4298.3339, delta_loss = 54.93227 learning_Rate = 0.01000 rmse=1.15763 mae=0.89274\n","\u003cclass '__main__.RSTE'\u003e iteration 84: loss = 4244.3291, delta_loss = 54.00481 learning_Rate = 0.01000 rmse=1.15720 mae=0.89230\n","\u003cclass '__main__.RSTE'\u003e iteration 85: loss = 4191.2307, delta_loss = 53.09844 learning_Rate = 0.01000 rmse=1.15679 mae=0.89188\n","\u003cclass '__main__.RSTE'\u003e iteration 86: loss = 4139.0184, delta_loss = 52.21227 learning_Rate = 0.01000 rmse=1.15639 mae=0.89147\n","\u003cclass '__main__.RSTE'\u003e iteration 87: loss = 4087.6729, delta_loss = 51.34547 learning_Rate = 0.01000 rmse=1.15602 mae=0.89108\n","\u003cclass '__main__.RSTE'\u003e iteration 88: loss = 4037.1757, delta_loss = 50.49725 learning_Rate = 0.01000 rmse=1.15568 mae=0.89072\n","\u003cclass '__main__.RSTE'\u003e iteration 89: loss = 3987.5088, delta_loss = 49.66692 learning_Rate = 0.01000 rmse=1.15535 mae=0.89036\n","\u003cclass '__main__.RSTE'\u003e iteration 90: loss = 3938.6550, delta_loss = 48.85379 learning_Rate = 0.01000 rmse=1.15504 mae=0.89003\n","\u003cclass '__main__.RSTE'\u003e iteration 91: loss = 3890.5977, delta_loss = 48.05725 learning_Rate = 0.01000 rmse=1.15474 mae=0.88970\n","\u003cclass '__main__.RSTE'\u003e iteration 92: loss = 3843.3210, delta_loss = 47.27673 learning_Rate = 0.01000 rmse=1.15446 mae=0.88939\n","\u003cclass '__main__.RSTE'\u003e iteration 93: loss = 3796.8093, delta_loss = 46.51169 learning_Rate = 0.01000 rmse=1.15420 mae=0.88911\n","\u003cclass '__main__.RSTE'\u003e iteration 94: loss = 3751.0477, delta_loss = 45.76165 learning_Rate = 0.01000 rmse=1.15395 mae=0.88884\n","\u003cclass '__main__.RSTE'\u003e iteration 95: loss = 3706.0215, delta_loss = 45.02614 learning_Rate = 0.01000 rmse=1.15373 mae=0.88857\n","\u003cclass '__main__.RSTE'\u003e iteration 96: loss = 3661.7168, delta_loss = 44.30474 learning_Rate = 0.01000 rmse=1.15351 mae=0.88832\n","\u003cclass '__main__.RSTE'\u003e iteration 97: loss = 3618.1197, delta_loss = 43.59706 learning_Rate = 0.01000 rmse=1.15330 mae=0.88807\n","\u003cclass '__main__.RSTE'\u003e iteration 98: loss = 3575.2170, delta_loss = 42.90271 learning_Rate = 0.01000 rmse=1.15311 mae=0.88784\n","\u003cclass '__main__.RSTE'\u003e iteration 99: loss = 3532.9957, delta_loss = 42.22135 learning_Rate = 0.01000 rmse=1.15294 mae=0.88763\n","\u003cclass '__main__.RSTE'\u003e iteration 100: loss = 3491.4430, delta_loss = 41.55266 learning_Rate = 0.01000 rmse=1.15279 mae=0.88744\n","the 1th cross validation training\n","\u003cclass '__main__.RSTE'\u003e iteration 1: loss = 38619.4678, delta_loss = -38619.46782 learning_Rate = 0.01000 rmse=2.43673 mae=2.11698\n","\u003cclass '__main__.RSTE'\u003e iteration 2: loss = 33147.1625, delta_loss = 5472.30532 learning_Rate = 0.01000 rmse=2.23100 mae=1.90503\n","\u003cclass '__main__.RSTE'\u003e iteration 3: loss = 29237.7919, delta_loss = 3909.37063 learning_Rate = 0.01000 rmse=2.07488 mae=1.74742\n","\u003cclass '__main__.RSTE'\u003e iteration 4: loss = 26375.7735, delta_loss = 2862.01840 learning_Rate = 0.01000 rmse=1.95377 mae=1.62708\n","\u003cclass '__main__.RSTE'\u003e iteration 5: loss = 24198.1402, delta_loss = 2177.63324 learning_Rate = 0.01000 rmse=1.85760 mae=1.53225\n","\u003cclass '__main__.RSTE'\u003e iteration 6: loss = 22470.6754, delta_loss = 1727.46479 learning_Rate = 0.01000 rmse=1.77923 mae=1.45612\n","\u003cclass '__main__.RSTE'\u003e iteration 7: loss = 21052.7092, delta_loss = 1417.96625 learning_Rate = 0.01000 rmse=1.71395 mae=1.39376\n","\u003cclass '__main__.RSTE'\u003e iteration 8: loss = 19858.6707, delta_loss = 1194.03844 learning_Rate = 0.01000 rmse=1.65900 mae=1.34230\n","\u003cclass '__main__.RSTE'\u003e iteration 9: loss = 18833.2770, delta_loss = 1025.39374 learning_Rate = 0.01000 rmse=1.61199 mae=1.29866\n","\u003cclass '__main__.RSTE'\u003e iteration 10: loss = 17938.6211, delta_loss = 894.65587 learning_Rate = 0.01000 rmse=1.57136 mae=1.26140\n","\u003cclass '__main__.RSTE'\u003e iteration 11: loss = 17147.6238, delta_loss = 790.99733 learning_Rate = 0.01000 rmse=1.53587 mae=1.22897\n","\u003cclass '__main__.RSTE'\u003e iteration 12: loss = 16440.4211, delta_loss = 707.20269 learning_Rate = 0.01000 rmse=1.50454 mae=1.20063\n","\u003cclass '__main__.RSTE'\u003e iteration 13: loss = 15802.1506, delta_loss = 638.27052 learning_Rate = 0.01000 rmse=1.47668 mae=1.17547\n","\u003cclass '__main__.RSTE'\u003e iteration 14: loss = 15221.4926, delta_loss = 580.65802 learning_Rate = 0.01000 rmse=1.45180 mae=1.15304\n","\u003cclass '__main__.RSTE'\u003e iteration 15: loss = 14689.6744, delta_loss = 531.81817 learning_Rate = 0.01000 rmse=1.42951 mae=1.13293\n","\u003cclass '__main__.RSTE'\u003e iteration 16: loss = 14199.7798, delta_loss = 489.89458 learning_Rate = 0.01000 rmse=1.40950 mae=1.11492\n","\u003cclass '__main__.RSTE'\u003e iteration 17: loss = 13746.2655, delta_loss = 453.51428 learning_Rate = 0.01000 rmse=1.39141 mae=1.09861\n","\u003cclass '__main__.RSTE'\u003e iteration 18: loss = 13324.6199, delta_loss = 421.64564 learning_Rate = 0.01000 rmse=1.37506 mae=1.08380\n","\u003cclass '__main__.RSTE'\u003e iteration 19: loss = 12931.1192, delta_loss = 393.50069 learning_Rate = 0.01000 rmse=1.36022 mae=1.07040\n","\u003cclass '__main__.RSTE'\u003e iteration 20: loss = 12562.6515, delta_loss = 368.46772 learning_Rate = 0.01000 rmse=1.34670 mae=1.05824\n","\u003cclass '__main__.RSTE'\u003e iteration 21: loss = 12216.5871, delta_loss = 346.06441 learning_Rate = 0.01000 rmse=1.33443 mae=1.04725\n","\u003cclass '__main__.RSTE'\u003e iteration 22: loss = 11890.6822, delta_loss = 325.90486 learning_Rate = 0.01000 rmse=1.32318 mae=1.03719\n","\u003cclass '__main__.RSTE'\u003e iteration 23: loss = 11583.0060, delta_loss = 307.67626 learning_Rate = 0.01000 rmse=1.31285 mae=1.02796\n","\u003cclass '__main__.RSTE'\u003e iteration 24: loss = 11291.8839, delta_loss = 291.12202 learning_Rate = 0.01000 rmse=1.30334 mae=1.01942\n","\u003cclass '__main__.RSTE'\u003e iteration 25: loss = 11015.8546, delta_loss = 276.02939 learning_Rate = 0.01000 rmse=1.29462 mae=1.01155\n","\u003cclass '__main__.RSTE'\u003e iteration 26: loss = 10753.6342, delta_loss = 262.22031 learning_Rate = 0.01000 rmse=1.28657 mae=1.00427\n","\u003cclass '__main__.RSTE'\u003e iteration 27: loss = 10504.0897, delta_loss = 249.54450 learning_Rate = 0.01000 rmse=1.27910 mae=0.99750\n","\u003cclass '__main__.RSTE'\u003e iteration 28: loss = 10266.2156, delta_loss = 237.87413 learning_Rate = 0.01000 rmse=1.27219 mae=0.99119\n","\u003cclass '__main__.RSTE'\u003e iteration 29: loss = 10039.1158, delta_loss = 227.09977 learning_Rate = 0.01000 rmse=1.26575 mae=0.98530\n","\u003cclass '__main__.RSTE'\u003e iteration 30: loss = 9821.9887, delta_loss = 217.12713 learning_Rate = 0.01000 rmse=1.25978 mae=0.97979\n","\u003cclass '__main__.RSTE'\u003e iteration 31: loss = 9614.1142, delta_loss = 207.87450 learning_Rate = 0.01000 rmse=1.25422 mae=0.97464\n","\u003cclass '__main__.RSTE'\u003e iteration 32: loss = 9414.8435, delta_loss = 199.27076 learning_Rate = 0.01000 rmse=1.24904 mae=0.96984\n","\u003cclass '__main__.RSTE'\u003e iteration 33: loss = 9223.5898, delta_loss = 191.25366 learning_Rate = 0.01000 rmse=1.24421 mae=0.96535\n","\u003cclass '__main__.RSTE'\u003e iteration 34: loss = 9039.8213, delta_loss = 183.76850 learning_Rate = 0.01000 rmse=1.23970 mae=0.96115\n","\u003cclass '__main__.RSTE'\u003e iteration 35: loss = 8863.0542, delta_loss = 176.76706 learning_Rate = 0.01000 rmse=1.23547 mae=0.95716\n","\u003cclass '__main__.RSTE'\u003e iteration 36: loss = 8692.8476, delta_loss = 170.20661 learning_Rate = 0.01000 rmse=1.23149 mae=0.95339\n","\u003cclass '__main__.RSTE'\u003e iteration 37: loss = 8528.7984, delta_loss = 164.04920 learning_Rate = 0.01000 rmse=1.22777 mae=0.94984\n","\u003cclass '__main__.RSTE'\u003e iteration 38: loss = 8370.5374, delta_loss = 158.26101 learning_Rate = 0.01000 rmse=1.22427 mae=0.94649\n","\u003cclass '__main__.RSTE'\u003e iteration 39: loss = 8217.7256, delta_loss = 152.81182 learning_Rate = 0.01000 rmse=1.22099 mae=0.94336\n","\u003cclass '__main__.RSTE'\u003e iteration 40: loss = 8070.0511, delta_loss = 147.67451 learning_Rate = 0.01000 rmse=1.21789 mae=0.94040\n","\u003cclass '__main__.RSTE'\u003e iteration 41: loss = 7927.2264, delta_loss = 142.82472 learning_Rate = 0.01000 rmse=1.21496 mae=0.93760\n","\u003cclass '__main__.RSTE'\u003e iteration 42: loss = 7788.9859, delta_loss = 138.24051 learning_Rate = 0.01000 rmse=1.21218 mae=0.93494\n","\u003cclass '__main__.RSTE'\u003e iteration 43: loss = 7655.0838, delta_loss = 133.90206 learning_Rate = 0.01000 rmse=1.20955 mae=0.93242\n","\u003cclass '__main__.RSTE'\u003e iteration 44: loss = 7525.2924, delta_loss = 129.79140 learning_Rate = 0.01000 rmse=1.20706 mae=0.93003\n","\u003cclass '__main__.RSTE'\u003e iteration 45: loss = 7399.4001, delta_loss = 125.89226 learning_Rate = 0.01000 rmse=1.20470 mae=0.92775\n","\u003cclass '__main__.RSTE'\u003e iteration 46: loss = 7277.2103, delta_loss = 122.18983 learning_Rate = 0.01000 rmse=1.20246 mae=0.92561\n","\u003cclass '__main__.RSTE'\u003e iteration 47: loss = 7158.5397, delta_loss = 118.67061 learning_Rate = 0.01000 rmse=1.20034 mae=0.92357\n","\u003cclass '__main__.RSTE'\u003e iteration 48: loss = 7043.2174, delta_loss = 115.32228 learning_Rate = 0.01000 rmse=1.19831 mae=0.92161\n","\u003cclass '__main__.RSTE'\u003e iteration 49: loss = 6931.0838, delta_loss = 112.13356 learning_Rate = 0.01000 rmse=1.19637 mae=0.91972\n","\u003cclass '__main__.RSTE'\u003e iteration 50: loss = 6821.9897, delta_loss = 109.09413 learning_Rate = 0.01000 rmse=1.19452 mae=0.91791\n","\u003cclass '__main__.RSTE'\u003e iteration 51: loss = 6715.7952, delta_loss = 106.19448 learning_Rate = 0.01000 rmse=1.19274 mae=0.91617\n","\u003cclass '__main__.RSTE'\u003e iteration 52: loss = 6612.3693, delta_loss = 103.42588 learning_Rate = 0.01000 rmse=1.19106 mae=0.91452\n","\u003cclass '__main__.RSTE'\u003e iteration 53: loss = 6511.5891, delta_loss = 100.78028 learning_Rate = 0.01000 rmse=1.18945 mae=0.91293\n","\u003cclass '__main__.RSTE'\u003e iteration 54: loss = 6413.3388, delta_loss = 98.25024 learning_Rate = 0.01000 rmse=1.18791 mae=0.91141\n","\u003cclass '__main__.RSTE'\u003e iteration 55: loss = 6317.5100, delta_loss = 95.82886 learning_Rate = 0.01000 rmse=1.18644 mae=0.90994\n","\u003cclass '__main__.RSTE'\u003e iteration 56: loss = 6224.0002, delta_loss = 93.50978 learning_Rate = 0.01000 rmse=1.18503 mae=0.90852\n","\u003cclass '__main__.RSTE'\u003e iteration 57: loss = 6132.7131, delta_loss = 91.28706 learning_Rate = 0.01000 rmse=1.18368 mae=0.90716\n","\u003cclass '__main__.RSTE'\u003e iteration 58: loss = 6043.5580, delta_loss = 89.15518 learning_Rate = 0.01000 rmse=1.18239 mae=0.90586\n","\u003cclass '__main__.RSTE'\u003e iteration 59: loss = 5956.4489, delta_loss = 87.10902 learning_Rate = 0.01000 rmse=1.18116 mae=0.90460\n","\u003cclass '__main__.RSTE'\u003e iteration 60: loss = 5871.3051, delta_loss = 85.14379 learning_Rate = 0.01000 rmse=1.17998 mae=0.90341\n","\u003cclass '__main__.RSTE'\u003e iteration 61: loss = 5788.0502, delta_loss = 83.25499 learning_Rate = 0.01000 rmse=1.17886 mae=0.90228\n","\u003cclass '__main__.RSTE'\u003e iteration 62: loss = 5706.6117, delta_loss = 81.43844 learning_Rate = 0.01000 rmse=1.17777 mae=0.90118\n","\u003cclass '__main__.RSTE'\u003e iteration 63: loss = 5626.9215, delta_loss = 79.69021 learning_Rate = 0.01000 rmse=1.17672 mae=0.90014\n","\u003cclass '__main__.RSTE'\u003e iteration 64: loss = 5548.9149, delta_loss = 78.00662 learning_Rate = 0.01000 rmse=1.17572 mae=0.89915\n","\u003cclass '__main__.RSTE'\u003e iteration 65: loss = 5472.5307, delta_loss = 76.38420 learning_Rate = 0.01000 rmse=1.17477 mae=0.89821\n","\u003cclass '__main__.RSTE'\u003e iteration 66: loss = 5397.7110, delta_loss = 74.81969 learning_Rate = 0.01000 rmse=1.17385 mae=0.89731\n","\u003cclass '__main__.RSTE'\u003e iteration 67: loss = 5324.4010, delta_loss = 73.31002 learning_Rate = 0.01000 rmse=1.17297 mae=0.89645\n","\u003cclass '__main__.RSTE'\u003e iteration 68: loss = 5252.5487, delta_loss = 71.85231 learning_Rate = 0.01000 rmse=1.17212 mae=0.89561\n","\u003cclass '__main__.RSTE'\u003e iteration 69: loss = 5182.1048, delta_loss = 70.44384 learning_Rate = 0.01000 rmse=1.17132 mae=0.89482\n","\u003cclass '__main__.RSTE'\u003e iteration 70: loss = 5113.0228, delta_loss = 69.08203 learning_Rate = 0.01000 rmse=1.17055 mae=0.89406\n","\u003cclass '__main__.RSTE'\u003e iteration 71: loss = 5045.2583, delta_loss = 67.76445 learning_Rate = 0.01000 rmse=1.16981 mae=0.89331\n","\u003cclass '__main__.RSTE'\u003e iteration 72: loss = 4978.7695, delta_loss = 66.48883 learning_Rate = 0.01000 rmse=1.16910 mae=0.89262\n","\u003cclass '__main__.RSTE'\u003e iteration 73: loss = 4913.5165, delta_loss = 65.25299 learning_Rate = 0.01000 rmse=1.16841 mae=0.89194\n","\u003cclass '__main__.RSTE'\u003e iteration 74: loss = 4849.4616, delta_loss = 64.05489 learning_Rate = 0.01000 rmse=1.16776 mae=0.89130\n","\u003cclass '__main__.RSTE'\u003e iteration 75: loss = 4786.5690, delta_loss = 62.89261 learning_Rate = 0.01000 rmse=1.16713 mae=0.89067\n","\u003cclass '__main__.RSTE'\u003e iteration 76: loss = 4724.8047, delta_loss = 61.76432 learning_Rate = 0.01000 rmse=1.16653 mae=0.89007\n","\u003cclass '__main__.RSTE'\u003e iteration 77: loss = 4664.1364, delta_loss = 60.66830 learning_Rate = 0.01000 rmse=1.16595 mae=0.88949\n","\u003cclass '__main__.RSTE'\u003e iteration 78: loss = 4604.5335, delta_loss = 59.60293 learning_Rate = 0.01000 rmse=1.16540 mae=0.88895\n","\u003cclass '__main__.RSTE'\u003e iteration 79: loss = 4545.9668, delta_loss = 58.56668 learning_Rate = 0.01000 rmse=1.16488 mae=0.88843\n","\u003cclass '__main__.RSTE'\u003e iteration 80: loss = 4488.4087, delta_loss = 57.55811 learning_Rate = 0.01000 rmse=1.16437 mae=0.88792\n","\u003cclass '__main__.RSTE'\u003e iteration 81: loss = 4431.8328, delta_loss = 56.57586 learning_Rate = 0.01000 rmse=1.16389 mae=0.88743\n","\u003cclass '__main__.RSTE'\u003e iteration 82: loss = 4376.2142, delta_loss = 55.61866 learning_Rate = 0.01000 rmse=1.16342 mae=0.88695\n","\u003cclass '__main__.RSTE'\u003e iteration 83: loss = 4321.5289, delta_loss = 54.68529 learning_Rate = 0.01000 rmse=1.16298 mae=0.88649\n","\u003cclass '__main__.RSTE'\u003e iteration 84: loss = 4267.7542, delta_loss = 53.77463 learning_Rate = 0.01000 rmse=1.16255 mae=0.88606\n","\u003cclass '__main__.RSTE'\u003e iteration 85: loss = 4214.8686, delta_loss = 52.88562 learning_Rate = 0.01000 rmse=1.16213 mae=0.88563\n","\u003cclass '__main__.RSTE'\u003e iteration 86: loss = 4162.8513, delta_loss = 52.01727 learning_Rate = 0.01000 rmse=1.16174 mae=0.88523\n","\u003cclass '__main__.RSTE'\u003e iteration 87: loss = 4111.6827, delta_loss = 51.16865 learning_Rate = 0.01000 rmse=1.16135 mae=0.88485\n","\u003cclass '__main__.RSTE'\u003e iteration 88: loss = 4061.3438, delta_loss = 50.33888 learning_Rate = 0.01000 rmse=1.16099 mae=0.88448\n","\u003cclass '__main__.RSTE'\u003e iteration 89: loss = 4011.8167, delta_loss = 49.52716 learning_Rate = 0.01000 rmse=1.16064 mae=0.88413\n","\u003cclass '__main__.RSTE'\u003e iteration 90: loss = 3963.0839, delta_loss = 48.73271 learning_Rate = 0.01000 rmse=1.16031 mae=0.88378\n","\u003cclass '__main__.RSTE'\u003e iteration 91: loss = 3915.1291, delta_loss = 47.95484 learning_Rate = 0.01000 rmse=1.16000 mae=0.88345\n","\u003cclass '__main__.RSTE'\u003e iteration 92: loss = 3867.9362, delta_loss = 47.19288 learning_Rate = 0.01000 rmse=1.15970 mae=0.88313\n","\u003cclass '__main__.RSTE'\u003e iteration 93: loss = 3821.4900, delta_loss = 46.44621 learning_Rate = 0.01000 rmse=1.15942 mae=0.88282\n","\u003cclass '__main__.RSTE'\u003e iteration 94: loss = 3775.7758, delta_loss = 45.71426 learning_Rate = 0.01000 rmse=1.15914 mae=0.88252\n","\u003cclass '__main__.RSTE'\u003e iteration 95: loss = 3730.7793, delta_loss = 44.99650 learning_Rate = 0.01000 rmse=1.15889 mae=0.88224\n","\u003cclass '__main__.RSTE'\u003e iteration 96: loss = 3686.4868, delta_loss = 44.29243 learning_Rate = 0.01000 rmse=1.15865 mae=0.88196\n","\u003cclass '__main__.RSTE'\u003e iteration 97: loss = 3642.8852, delta_loss = 43.60159 learning_Rate = 0.01000 rmse=1.15842 mae=0.88170\n","\u003cclass '__main__.RSTE'\u003e iteration 98: loss = 3599.9617, delta_loss = 42.92355 learning_Rate = 0.01000 rmse=1.15820 mae=0.88146\n","\u003cclass '__main__.RSTE'\u003e iteration 99: loss = 3557.7038, delta_loss = 42.25790 learning_Rate = 0.01000 rmse=1.15800 mae=0.88123\n","\u003cclass '__main__.RSTE'\u003e iteration 100: loss = 3516.0995, delta_loss = 41.60429 learning_Rate = 0.01000 rmse=1.15782 mae=0.88102\n","the 2th cross validation training\n","\u003cclass '__main__.RSTE'\u003e iteration 1: loss = 38751.6540, delta_loss = -38751.65398 learning_Rate = 0.01000 rmse=2.43910 mae=2.13534\n","\u003cclass '__main__.RSTE'\u003e iteration 2: loss = 33284.5030, delta_loss = 5467.15098 learning_Rate = 0.01000 rmse=2.23127 mae=1.92198\n","\u003cclass '__main__.RSTE'\u003e iteration 3: loss = 29351.1195, delta_loss = 3933.38355 learning_Rate = 0.01000 rmse=2.07000 mae=1.75648\n","\u003cclass '__main__.RSTE'\u003e iteration 4: loss = 26465.5967, delta_loss = 2885.52270 learning_Rate = 0.01000 rmse=1.94427 mae=1.63025\n","\u003cclass '__main__.RSTE'\u003e iteration 5: loss = 24271.4740, delta_loss = 2194.12276 learning_Rate = 0.01000 rmse=1.84407 mae=1.53218\n","\u003cclass '__main__.RSTE'\u003e iteration 6: loss = 22532.4652, delta_loss = 1739.00879 learning_Rate = 0.01000 rmse=1.76283 mae=1.45430\n","\u003cclass '__main__.RSTE'\u003e iteration 7: loss = 21105.5516, delta_loss = 1426.91361 learning_Rate = 0.01000 rmse=1.69567 mae=1.39098\n","\u003cclass '__main__.RSTE'\u003e iteration 8: loss = 19904.0430, delta_loss = 1201.50858 learning_Rate = 0.01000 rmse=1.63903 mae=1.33828\n","\u003cclass '__main__.RSTE'\u003e iteration 9: loss = 18872.2120, delta_loss = 1031.83100 learning_Rate = 0.01000 rmse=1.59087 mae=1.29382\n","\u003cclass '__main__.RSTE'\u003e iteration 10: loss = 17971.9375, delta_loss = 900.27455 learning_Rate = 0.01000 rmse=1.54938 mae=1.25593\n","\u003cclass '__main__.RSTE'\u003e iteration 11: loss = 17175.9997, delta_loss = 795.93777 learning_Rate = 0.01000 rmse=1.51324 mae=1.22310\n","\u003cclass '__main__.RSTE'\u003e iteration 12: loss = 16464.4293, delta_loss = 711.57044 learning_Rate = 0.01000 rmse=1.48141 mae=1.19443\n","\u003cclass '__main__.RSTE'\u003e iteration 13: loss = 15822.2824, delta_loss = 642.14682 learning_Rate = 0.01000 rmse=1.45308 mae=1.16904\n","\u003cclass '__main__.RSTE'\u003e iteration 14: loss = 15238.1773, delta_loss = 584.10511 learning_Rate = 0.01000 rmse=1.42776 mae=1.14652\n","\u003cclass '__main__.RSTE'\u003e iteration 15: loss = 14703.2939, delta_loss = 534.88338 learning_Rate = 0.01000 rmse=1.40501 mae=1.12639\n","\u003cclass '__main__.RSTE'\u003e iteration 16: loss = 14210.6800, delta_loss = 492.61396 learning_Rate = 0.01000 rmse=1.38458 mae=1.10836\n","\u003cclass '__main__.RSTE'\u003e iteration 17: loss = 13754.7643, delta_loss = 455.91571 learning_Rate = 0.01000 rmse=1.36617 mae=1.09218\n","\u003cclass '__main__.RSTE'\u003e iteration 18: loss = 13331.0127, delta_loss = 423.75159 learning_Rate = 0.01000 rmse=1.34956 mae=1.07757\n","\u003cclass '__main__.RSTE'\u003e iteration 19: loss = 12935.6823, delta_loss = 395.33038 learning_Rate = 0.01000 rmse=1.33445 mae=1.06426\n","\u003cclass '__main__.RSTE'\u003e iteration 20: loss = 12565.6436, delta_loss = 370.03875 learning_Rate = 0.01000 rmse=1.32069 mae=1.05208\n","\u003cclass '__main__.RSTE'\u003e iteration 21: loss = 12218.2498, delta_loss = 347.39380 learning_Rate = 0.01000 rmse=1.30812 mae=1.04098\n","\u003cclass '__main__.RSTE'\u003e iteration 22: loss = 11891.2401, delta_loss = 327.00969 learning_Rate = 0.01000 rmse=1.29669 mae=1.03094\n","\u003cclass '__main__.RSTE'\u003e iteration 23: loss = 11582.6662, delta_loss = 308.57386 learning_Rate = 0.01000 rmse=1.28620 mae=1.02170\n","\u003cclass '__main__.RSTE'\u003e iteration 24: loss = 11290.8362, delta_loss = 291.82996 learning_Rate = 0.01000 rmse=1.27654 mae=1.01319\n","\u003cclass '__main__.RSTE'\u003e iteration 25: loss = 11014.2709, delta_loss = 276.56534 learning_Rate = 0.01000 rmse=1.26768 mae=1.00538\n","\u003cclass '__main__.RSTE'\u003e iteration 26: loss = 10751.6692, delta_loss = 262.60175 learning_Rate = 0.01000 rmse=1.25952 mae=0.99819\n","\u003cclass '__main__.RSTE'\u003e iteration 27: loss = 10501.8807, delta_loss = 249.78849 learning_Rate = 0.01000 rmse=1.25197 mae=0.99153\n","\u003cclass '__main__.RSTE'\u003e iteration 28: loss = 10263.8836, delta_loss = 237.99706 learning_Rate = 0.01000 rmse=1.24494 mae=0.98529\n","\u003cclass '__main__.RSTE'\u003e iteration 29: loss = 10036.7665, delta_loss = 227.11714 learning_Rate = 0.01000 rmse=1.23842 mae=0.97944\n","\u003cclass '__main__.RSTE'\u003e iteration 30: loss = 9819.7131, delta_loss = 217.05341 learning_Rate = 0.01000 rmse=1.23235 mae=0.97402\n","\u003cclass '__main__.RSTE'\u003e iteration 31: loss = 9611.9900, delta_loss = 207.72304 learning_Rate = 0.01000 rmse=1.22667 mae=0.96896\n","\u003cclass '__main__.RSTE'\u003e iteration 32: loss = 9412.9363, delta_loss = 199.05373 learning_Rate = 0.01000 rmse=1.22138 mae=0.96423\n","\u003cclass '__main__.RSTE'\u003e iteration 33: loss = 9221.9542, delta_loss = 190.98205 learning_Rate = 0.01000 rmse=1.21645 mae=0.95981\n","\u003cclass '__main__.RSTE'\u003e iteration 34: loss = 9038.5021, delta_loss = 183.45215 learning_Rate = 0.01000 rmse=1.21184 mae=0.95567\n","\u003cclass '__main__.RSTE'\u003e iteration 35: loss = 8862.0874, delta_loss = 176.41470 learning_Rate = 0.01000 rmse=1.20752 mae=0.95177\n","\u003cclass '__main__.RSTE'\u003e iteration 36: loss = 8692.2614, delta_loss = 169.82594 learning_Rate = 0.01000 rmse=1.20345 mae=0.94807\n","\u003cclass '__main__.RSTE'\u003e iteration 37: loss = 8528.6145, delta_loss = 163.64697 learning_Rate = 0.01000 rmse=1.19962 mae=0.94456\n","\u003cclass '__main__.RSTE'\u003e iteration 38: loss = 8370.7713, delta_loss = 157.84312 learning_Rate = 0.01000 rmse=1.19603 mae=0.94128\n","\u003cclass '__main__.RSTE'\u003e iteration 39: loss = 8218.3880, delta_loss = 152.38337 learning_Rate = 0.01000 rmse=1.19264 mae=0.93819\n","\u003cclass '__main__.RSTE'\u003e iteration 40: loss = 8071.1480, delta_loss = 147.23993 learning_Rate = 0.01000 rmse=1.18945 mae=0.93529\n","\u003cclass '__main__.RSTE'\u003e iteration 41: loss = 7928.7602, delta_loss = 142.38783 learning_Rate = 0.01000 rmse=1.18642 mae=0.93254\n","\u003cclass '__main__.RSTE'\u003e iteration 42: loss = 7790.9556, delta_loss = 137.80458 learning_Rate = 0.01000 rmse=1.18356 mae=0.92993\n","\u003cclass '__main__.RSTE'\u003e iteration 43: loss = 7657.4857, delta_loss = 133.46990 learning_Rate = 0.01000 rmse=1.18084 mae=0.92745\n","\u003cclass '__main__.RSTE'\u003e iteration 44: loss = 7528.1203, delta_loss = 129.36543 learning_Rate = 0.01000 rmse=1.17827 mae=0.92509\n","\u003cclass '__main__.RSTE'\u003e iteration 45: loss = 7402.6458, delta_loss = 125.47452 learning_Rate = 0.01000 rmse=1.17582 mae=0.92282\n","\u003cclass '__main__.RSTE'\u003e iteration 46: loss = 7280.8637, delta_loss = 121.78206 learning_Rate = 0.01000 rmse=1.17348 mae=0.92066\n","\u003cclass '__main__.RSTE'\u003e iteration 47: loss = 7162.5894, delta_loss = 118.27430 learning_Rate = 0.01000 rmse=1.17124 mae=0.91859\n","\u003cclass '__main__.RSTE'\u003e iteration 48: loss = 7047.6508, delta_loss = 114.93866 learning_Rate = 0.01000 rmse=1.16911 mae=0.91662\n","\u003cclass '__main__.RSTE'\u003e iteration 49: loss = 6935.8871, delta_loss = 111.76367 learning_Rate = 0.01000 rmse=1.16707 mae=0.91475\n","\u003cclass '__main__.RSTE'\u003e iteration 50: loss = 6827.1483, delta_loss = 108.73883 learning_Rate = 0.01000 rmse=1.16512 mae=0.91295\n","\u003cclass '__main__.RSTE'\u003e iteration 51: loss = 6721.2938, delta_loss = 105.85446 learning_Rate = 0.01000 rmse=1.16325 mae=0.91123\n","\u003cclass '__main__.RSTE'\u003e iteration 52: loss = 6618.1921, delta_loss = 103.10170 learning_Rate = 0.01000 rmse=1.16146 mae=0.90958\n","\u003cclass '__main__.RSTE'\u003e iteration 53: loss = 6517.7197, delta_loss = 100.47236 learning_Rate = 0.01000 rmse=1.15974 mae=0.90799\n","\u003cclass '__main__.RSTE'\u003e iteration 54: loss = 6419.7609, delta_loss = 97.95888 learning_Rate = 0.01000 rmse=1.15809 mae=0.90648\n","\u003cclass '__main__.RSTE'\u003e iteration 55: loss = 6324.2066, delta_loss = 95.55427 learning_Rate = 0.01000 rmse=1.15651 mae=0.90503\n","\u003cclass '__main__.RSTE'\u003e iteration 56: loss = 6230.9545, delta_loss = 93.25205 learning_Rate = 0.01000 rmse=1.15499 mae=0.90361\n","\u003cclass '__main__.RSTE'\u003e iteration 57: loss = 6139.9083, delta_loss = 91.04621 learning_Rate = 0.01000 rmse=1.15352 mae=0.90226\n","\u003cclass '__main__.RSTE'\u003e iteration 58: loss = 6050.9772, delta_loss = 88.93115 learning_Rate = 0.01000 rmse=1.15212 mae=0.90095\n","\u003cclass '__main__.RSTE'\u003e iteration 59: loss = 5964.0755, delta_loss = 86.90166 learning_Rate = 0.01000 rmse=1.15078 mae=0.89971\n","\u003cclass '__main__.RSTE'\u003e iteration 60: loss = 5879.1226, delta_loss = 84.95288 learning_Rate = 0.01000 rmse=1.14950 mae=0.89851\n","\u003cclass '__main__.RSTE'\u003e iteration 61: loss = 5796.0424, delta_loss = 83.08026 learning_Rate = 0.01000 rmse=1.14826 mae=0.89736\n","\u003cclass '__main__.RSTE'\u003e iteration 62: loss = 5714.7628, delta_loss = 81.27957 learning_Rate = 0.01000 rmse=1.14707 mae=0.89624\n","\u003cclass '__main__.RSTE'\u003e iteration 63: loss = 5635.2160, delta_loss = 79.54682 learning_Rate = 0.01000 rmse=1.14594 mae=0.89517\n","\u003cclass '__main__.RSTE'\u003e iteration 64: loss = 5557.3377, delta_loss = 77.87829 learning_Rate = 0.01000 rmse=1.14483 mae=0.89413\n","\u003cclass '__main__.RSTE'\u003e iteration 65: loss = 5481.0672, delta_loss = 76.27047 learning_Rate = 0.01000 rmse=1.14377 mae=0.89314\n","\u003cclass '__main__.RSTE'\u003e iteration 66: loss = 5406.3471, delta_loss = 74.72009 learning_Rate = 0.01000 rmse=1.14276 mae=0.89219\n","\u003cclass '__main__.RSTE'\u003e iteration 67: loss = 5333.1231, delta_loss = 73.22404 learning_Rate = 0.01000 rmse=1.14179 mae=0.89126\n","\u003cclass '__main__.RSTE'\u003e iteration 68: loss = 5261.3437, delta_loss = 71.77942 learning_Rate = 0.01000 rmse=1.14086 mae=0.89037\n","\u003cclass '__main__.RSTE'\u003e iteration 69: loss = 5190.9602, delta_loss = 70.38351 learning_Rate = 0.01000 rmse=1.13996 mae=0.88952\n","\u003cclass '__main__.RSTE'\u003e iteration 70: loss = 5121.9264, delta_loss = 69.03371 learning_Rate = 0.01000 rmse=1.13910 mae=0.88869\n","\u003cclass '__main__.RSTE'\u003e iteration 71: loss = 5054.1988, delta_loss = 67.72761 learning_Rate = 0.01000 rmse=1.13827 mae=0.88790\n","\u003cclass '__main__.RSTE'\u003e iteration 72: loss = 4987.7359, delta_loss = 66.46292 learning_Rate = 0.01000 rmse=1.13748 mae=0.88714\n","\u003cclass '__main__.RSTE'\u003e iteration 73: loss = 4922.4984, delta_loss = 65.23748 learning_Rate = 0.01000 rmse=1.13673 mae=0.88641\n","\u003cclass '__main__.RSTE'\u003e iteration 74: loss = 4858.4492, delta_loss = 64.04926 learning_Rate = 0.01000 rmse=1.13600 mae=0.88571\n","\u003cclass '__main__.RSTE'\u003e iteration 75: loss = 4795.5528, delta_loss = 62.89635 learning_Rate = 0.01000 rmse=1.13530 mae=0.88503\n","\u003cclass '__main__.RSTE'\u003e iteration 76: loss = 4733.7759, delta_loss = 61.77695 learning_Rate = 0.01000 rmse=1.13464 mae=0.88439\n","\u003cclass '__main__.RSTE'\u003e iteration 77: loss = 4673.0865, delta_loss = 60.68934 learning_Rate = 0.01000 rmse=1.13401 mae=0.88378\n","\u003cclass '__main__.RSTE'\u003e iteration 78: loss = 4613.4546, delta_loss = 59.63194 learning_Rate = 0.01000 rmse=1.13341 mae=0.88320\n","\u003cclass '__main__.RSTE'\u003e iteration 79: loss = 4554.8514, delta_loss = 58.60324 learning_Rate = 0.01000 rmse=1.13283 mae=0.88264\n","\u003cclass '__main__.RSTE'\u003e iteration 80: loss = 4497.2496, delta_loss = 57.60180 learning_Rate = 0.01000 rmse=1.13228 mae=0.88211\n","\u003cclass '__main__.RSTE'\u003e iteration 81: loss = 4440.6232, delta_loss = 56.62630 learning_Rate = 0.01000 rmse=1.13174 mae=0.88159\n","\u003cclass '__main__.RSTE'\u003e iteration 82: loss = 4384.9478, delta_loss = 55.67548 learning_Rate = 0.01000 rmse=1.13123 mae=0.88109\n","\u003cclass '__main__.RSTE'\u003e iteration 83: loss = 4330.1996, delta_loss = 54.74816 learning_Rate = 0.01000 rmse=1.13075 mae=0.88061\n","\u003cclass '__main__.RSTE'\u003e iteration 84: loss = 4276.3564, delta_loss = 53.84322 learning_Rate = 0.01000 rmse=1.13027 mae=0.88014\n","\u003cclass '__main__.RSTE'\u003e iteration 85: loss = 4223.3968, delta_loss = 52.95963 learning_Rate = 0.01000 rmse=1.12981 mae=0.87970\n","\u003cclass '__main__.RSTE'\u003e iteration 86: loss = 4171.3004, delta_loss = 52.09641 learning_Rate = 0.01000 rmse=1.12939 mae=0.87927\n","\u003cclass '__main__.RSTE'\u003e iteration 87: loss = 4120.0477, delta_loss = 51.25264 learning_Rate = 0.01000 rmse=1.12898 mae=0.87886\n","\u003cclass '__main__.RSTE'\u003e iteration 88: loss = 4069.6203, delta_loss = 50.42746 learning_Rate = 0.01000 rmse=1.12859 mae=0.87846\n","\u003cclass '__main__.RSTE'\u003e iteration 89: loss = 4020.0002, delta_loss = 49.62008 learning_Rate = 0.01000 rmse=1.12822 mae=0.87807\n","\u003cclass '__main__.RSTE'\u003e iteration 90: loss = 3971.1704, delta_loss = 48.82973 learning_Rate = 0.01000 rmse=1.12787 mae=0.87770\n","\u003cclass '__main__.RSTE'\u003e iteration 91: loss = 3923.1147, delta_loss = 48.05573 learning_Rate = 0.01000 rmse=1.12752 mae=0.87733\n","\u003cclass '__main__.RSTE'\u003e iteration 92: loss = 3875.8173, delta_loss = 47.29742 learning_Rate = 0.01000 rmse=1.12718 mae=0.87698\n","\u003cclass '__main__.RSTE'\u003e iteration 93: loss = 3829.2631, delta_loss = 46.55418 learning_Rate = 0.01000 rmse=1.12687 mae=0.87664\n","\u003cclass '__main__.RSTE'\u003e iteration 94: loss = 3783.4377, delta_loss = 45.82545 learning_Rate = 0.01000 rmse=1.12656 mae=0.87632\n","\u003cclass '__main__.RSTE'\u003e iteration 95: loss = 3738.3270, delta_loss = 45.11070 learning_Rate = 0.01000 rmse=1.12628 mae=0.87602\n","\u003cclass '__main__.RSTE'\u003e iteration 96: loss = 3693.9175, delta_loss = 44.40943 learning_Rate = 0.01000 rmse=1.12601 mae=0.87572\n","\u003cclass '__main__.RSTE'\u003e iteration 97: loss = 3650.1963, delta_loss = 43.72119 learning_Rate = 0.01000 rmse=1.12575 mae=0.87544\n","\u003cclass '__main__.RSTE'\u003e iteration 98: loss = 3607.1508, delta_loss = 43.04556 learning_Rate = 0.01000 rmse=1.12551 mae=0.87517\n","\u003cclass '__main__.RSTE'\u003e iteration 99: loss = 3564.7687, delta_loss = 42.38213 learning_Rate = 0.01000 rmse=1.12528 mae=0.87492\n","\u003cclass '__main__.RSTE'\u003e iteration 100: loss = 3523.0381, delta_loss = 41.73053 learning_Rate = 0.01000 rmse=1.12505 mae=0.87466\n","the 3th cross validation training\n","\u003cclass '__main__.RSTE'\u003e iteration 1: loss = 38775.2684, delta_loss = -38775.26841 learning_Rate = 0.01000 rmse=2.43726 mae=2.12469\n","\u003cclass '__main__.RSTE'\u003e iteration 2: loss = 33262.9122, delta_loss = 5512.35624 learning_Rate = 0.01000 rmse=2.23255 mae=1.91662\n","\u003cclass '__main__.RSTE'\u003e iteration 3: loss = 29314.1376, delta_loss = 3948.77454 learning_Rate = 0.01000 rmse=2.07664 mae=1.75866\n","\u003cclass '__main__.RSTE'\u003e iteration 4: loss = 26426.5582, delta_loss = 2887.57947 learning_Rate = 0.01000 rmse=1.95584 mae=1.63798\n","\u003cclass '__main__.RSTE'\u003e iteration 5: loss = 24234.9002, delta_loss = 2191.65795 learning_Rate = 0.01000 rmse=1.85978 mae=1.54329\n","\u003cclass '__main__.RSTE'\u003e iteration 6: loss = 22498.8841, delta_loss = 1736.01612 learning_Rate = 0.01000 rmse=1.78094 mae=1.46724\n","\u003cclass '__main__.RSTE'\u003e iteration 7: loss = 21074.1160, delta_loss = 1424.76806 learning_Rate = 0.01000 rmse=1.71499 mae=1.40390\n","\u003cclass '__main__.RSTE'\u003e iteration 8: loss = 19873.7091, delta_loss = 1200.40697 learning_Rate = 0.01000 rmse=1.65935 mae=1.35055\n","\u003cclass '__main__.RSTE'\u003e iteration 9: loss = 18842.1454, delta_loss = 1031.56371 learning_Rate = 0.01000 rmse=1.61169 mae=1.30558\n","\u003cclass '__main__.RSTE'\u003e iteration 10: loss = 17941.5734, delta_loss = 900.57195 learning_Rate = 0.01000 rmse=1.57046 mae=1.26722\n","\u003cclass '__main__.RSTE'\u003e iteration 11: loss = 17144.9889, delta_loss = 796.58446 learning_Rate = 0.01000 rmse=1.53438 mae=1.23404\n","\u003cclass '__main__.RSTE'\u003e iteration 12: loss = 16432.5711, delta_loss = 712.41787 learning_Rate = 0.01000 rmse=1.50253 mae=1.20520\n","\u003cclass '__main__.RSTE'\u003e iteration 13: loss = 15789.4740, delta_loss = 643.09709 learning_Rate = 0.01000 rmse=1.47430 mae=1.17991\n","\u003cclass '__main__.RSTE'\u003e iteration 14: loss = 15204.3798, delta_loss = 585.09422 learning_Rate = 0.01000 rmse=1.44931 mae=1.15770\n","\u003cclass '__main__.RSTE'\u003e iteration 15: loss = 14668.5096, delta_loss = 535.87014 learning_Rate = 0.01000 rmse=1.42689 mae=1.13779\n","\u003cclass '__main__.RSTE'\u003e iteration 16: loss = 14174.9366, delta_loss = 493.57301 learning_Rate = 0.01000 rmse=1.40666 mae=1.11993\n","\u003cclass '__main__.RSTE'\u003e iteration 17: loss = 13718.1038, delta_loss = 456.83281 learning_Rate = 0.01000 rmse=1.38844 mae=1.10377\n","\u003cclass '__main__.RSTE'\u003e iteration 18: loss = 13293.4838, delta_loss = 424.62000 learning_Rate = 0.01000 rmse=1.37194 mae=1.08904\n","\u003cclass '__main__.RSTE'\u003e iteration 19: loss = 12897.3357, delta_loss = 396.14809 learning_Rate = 0.01000 rmse=1.35698 mae=1.07569\n","\u003cclass '__main__.RSTE'\u003e iteration 20: loss = 12526.5295, delta_loss = 370.80626 learning_Rate = 0.01000 rmse=1.34335 mae=1.06347\n","\u003cclass '__main__.RSTE'\u003e iteration 21: loss = 12178.4169, delta_loss = 348.11259 learning_Rate = 0.01000 rmse=1.33089 mae=1.05223\n","\u003cclass '__main__.RSTE'\u003e iteration 22: loss = 11850.7357, delta_loss = 327.68121 learning_Rate = 0.01000 rmse=1.31951 mae=1.04199\n","\u003cclass '__main__.RSTE'\u003e iteration 23: loss = 11541.5367, delta_loss = 309.19899 learning_Rate = 0.01000 rmse=1.30908 mae=1.03260\n","\u003cclass '__main__.RSTE'\u003e iteration 24: loss = 11249.1279, delta_loss = 292.40878 learning_Rate = 0.01000 rmse=1.29949 mae=1.02396\n","\u003cclass '__main__.RSTE'\u003e iteration 25: loss = 10972.0308, delta_loss = 277.09709 learning_Rate = 0.01000 rmse=1.29064 mae=1.01599\n","\u003cclass '__main__.RSTE'\u003e iteration 26: loss = 10708.9458, delta_loss = 263.08506 learning_Rate = 0.01000 rmse=1.28247 mae=1.00863\n","\u003cclass '__main__.RSTE'\u003e iteration 27: loss = 10458.7242, delta_loss = 250.22151 learning_Rate = 0.01000 rmse=1.27490 mae=1.00185\n","\u003cclass '__main__.RSTE'\u003e iteration 28: loss = 10220.3465, delta_loss = 238.37774 learning_Rate = 0.01000 rmse=1.26792 mae=0.99560\n","\u003cclass '__main__.RSTE'\u003e iteration 29: loss = 9992.9031, delta_loss = 227.44343 learning_Rate = 0.01000 rmse=1.26142 mae=0.98978\n","\u003cclass '__main__.RSTE'\u003e iteration 30: loss = 9775.5796, delta_loss = 217.32343 learning_Rate = 0.01000 rmse=1.25534 mae=0.98431\n","\u003cclass '__main__.RSTE'\u003e iteration 31: loss = 9567.6444, delta_loss = 207.93523 learning_Rate = 0.01000 rmse=1.24968 mae=0.97920\n","\u003cclass '__main__.RSTE'\u003e iteration 32: loss = 9368.4375, delta_loss = 199.20693 learning_Rate = 0.01000 rmse=1.24439 mae=0.97443\n","\u003cclass '__main__.RSTE'\u003e iteration 33: loss = 9177.3619, delta_loss = 191.07555 learning_Rate = 0.01000 rmse=1.23945 mae=0.96997\n","\u003cclass '__main__.RSTE'\u003e iteration 34: loss = 8993.8762, delta_loss = 183.48574 learning_Rate = 0.01000 rmse=1.23480 mae=0.96576\n","\u003cclass '__main__.RSTE'\u003e iteration 35: loss = 8817.4876, delta_loss = 176.38862 learning_Rate = 0.01000 rmse=1.23043 mae=0.96178\n","\u003cclass '__main__.RSTE'\u003e iteration 36: loss = 8647.7467, delta_loss = 169.74088 learning_Rate = 0.01000 rmse=1.22633 mae=0.95801\n","\u003cclass '__main__.RSTE'\u003e iteration 37: loss = 8484.2427, delta_loss = 163.50402 learning_Rate = 0.01000 rmse=1.22244 mae=0.95443\n","\u003cclass '__main__.RSTE'\u003e iteration 38: loss = 8326.5989, delta_loss = 157.64371 learning_Rate = 0.01000 rmse=1.21878 mae=0.95103\n","\u003cclass '__main__.RSTE'\u003e iteration 39: loss = 8174.4697, delta_loss = 152.12923 learning_Rate = 0.01000 rmse=1.21531 mae=0.94781\n","\u003cclass '__main__.RSTE'\u003e iteration 40: loss = 8027.5367, delta_loss = 146.93302 learning_Rate = 0.01000 rmse=1.21204 mae=0.94474\n","\u003cclass '__main__.RSTE'\u003e iteration 41: loss = 7885.5064, delta_loss = 142.03029 learning_Rate = 0.01000 rmse=1.20896 mae=0.94184\n","\u003cclass '__main__.RSTE'\u003e iteration 42: loss = 7748.1077, delta_loss = 137.39869 learning_Rate = 0.01000 rmse=1.20603 mae=0.93908\n","\u003cclass '__main__.RSTE'\u003e iteration 43: loss = 7615.0897, delta_loss = 133.01803 learning_Rate = 0.01000 rmse=1.20326 mae=0.93646\n","\u003cclass '__main__.RSTE'\u003e iteration 44: loss = 7486.2197, delta_loss = 128.86998 learning_Rate = 0.01000 rmse=1.20065 mae=0.93397\n","\u003cclass '__main__.RSTE'\u003e iteration 45: loss = 7361.2818, delta_loss = 124.93794 learning_Rate = 0.01000 rmse=1.19819 mae=0.93162\n","\u003cclass '__main__.RSTE'\u003e iteration 46: loss = 7240.0750, delta_loss = 121.20677 learning_Rate = 0.01000 rmse=1.19584 mae=0.92939\n","\u003cclass '__main__.RSTE'\u003e iteration 47: loss = 7122.4123, delta_loss = 117.66269 learning_Rate = 0.01000 rmse=1.19361 mae=0.92729\n","\u003cclass '__main__.RSTE'\u003e iteration 48: loss = 7008.1192, delta_loss = 114.29310 learning_Rate = 0.01000 rmse=1.19150 mae=0.92529\n","\u003cclass '__main__.RSTE'\u003e iteration 49: loss = 6897.0328, delta_loss = 111.08645 learning_Rate = 0.01000 rmse=1.18947 mae=0.92337\n","\u003cclass '__main__.RSTE'\u003e iteration 50: loss = 6789.0006, delta_loss = 108.03217 learning_Rate = 0.01000 rmse=1.18754 mae=0.92153\n","\u003cclass '__main__.RSTE'\u003e iteration 51: loss = 6683.8800, delta_loss = 105.12055 learning_Rate = 0.01000 rmse=1.18571 mae=0.91979\n","\u003cclass '__main__.RSTE'\u003e iteration 52: loss = 6581.5374, delta_loss = 102.34262 learning_Rate = 0.01000 rmse=1.18397 mae=0.91814\n","\u003cclass '__main__.RSTE'\u003e iteration 53: loss = 6481.8473, delta_loss = 99.69015 learning_Rate = 0.01000 rmse=1.18230 mae=0.91656\n","\u003cclass '__main__.RSTE'\u003e iteration 54: loss = 6384.6918, delta_loss = 97.15550 learning_Rate = 0.01000 rmse=1.18071 mae=0.91504\n","\u003cclass '__main__.RSTE'\u003e iteration 55: loss = 6289.9601, delta_loss = 94.73163 learning_Rate = 0.01000 rmse=1.17919 mae=0.91359\n","\u003cclass '__main__.RSTE'\u003e iteration 56: loss = 6197.5481, delta_loss = 92.41201 learning_Rate = 0.01000 rmse=1.17774 mae=0.91222\n","\u003cclass '__main__.RSTE'\u003e iteration 57: loss = 6107.3576, delta_loss = 90.19056 learning_Rate = 0.01000 rmse=1.17636 mae=0.91091\n","\u003cclass '__main__.RSTE'\u003e iteration 58: loss = 6019.2959, delta_loss = 88.06164 learning_Rate = 0.01000 rmse=1.17504 mae=0.90965\n","\u003cclass '__main__.RSTE'\u003e iteration 59: loss = 5933.2759, delta_loss = 86.02001 learning_Rate = 0.01000 rmse=1.17377 mae=0.90844\n","\u003cclass '__main__.RSTE'\u003e iteration 60: loss = 5849.2152, delta_loss = 84.06076 learning_Rate = 0.01000 rmse=1.17258 mae=0.90731\n","\u003cclass '__main__.RSTE'\u003e iteration 61: loss = 5767.0358, delta_loss = 82.17934 learning_Rate = 0.01000 rmse=1.17142 mae=0.90620\n","\u003cclass '__main__.RSTE'\u003e iteration 62: loss = 5686.6644, delta_loss = 80.37145 learning_Rate = 0.01000 rmse=1.17031 mae=0.90514\n","\u003cclass '__main__.RSTE'\u003e iteration 63: loss = 5608.0313, delta_loss = 78.63310 learning_Rate = 0.01000 rmse=1.16924 mae=0.90411\n","\u003cclass '__main__.RSTE'\u003e iteration 64: loss = 5531.0708, delta_loss = 76.96053 learning_Rate = 0.01000 rmse=1.16822 mae=0.90313\n","\u003cclass '__main__.RSTE'\u003e iteration 65: loss = 5455.7205, delta_loss = 75.35023 learning_Rate = 0.01000 rmse=1.16724 mae=0.90219\n","\u003cclass '__main__.RSTE'\u003e iteration 66: loss = 5381.9216, delta_loss = 73.79888 learning_Rate = 0.01000 rmse=1.16630 mae=0.90130\n","\u003cclass '__main__.RSTE'\u003e iteration 67: loss = 5309.6183, delta_loss = 72.30338 learning_Rate = 0.01000 rmse=1.16540 mae=0.90044\n","\u003cclass '__main__.RSTE'\u003e iteration 68: loss = 5238.7575, delta_loss = 70.86079 learning_Rate = 0.01000 rmse=1.16454 mae=0.89961\n","\u003cclass '__main__.RSTE'\u003e iteration 69: loss = 5169.2891, delta_loss = 69.46836 learning_Rate = 0.01000 rmse=1.16371 mae=0.89881\n","\u003cclass '__main__.RSTE'\u003e iteration 70: loss = 5101.1656, delta_loss = 68.12349 learning_Rate = 0.01000 rmse=1.16291 mae=0.89804\n","\u003cclass '__main__.RSTE'\u003e iteration 71: loss = 5034.3419, delta_loss = 66.82371 learning_Rate = 0.01000 rmse=1.16214 mae=0.89729\n","\u003cclass '__main__.RSTE'\u003e iteration 72: loss = 4968.7752, delta_loss = 65.56671 learning_Rate = 0.01000 rmse=1.16140 mae=0.89657\n","\u003cclass '__main__.RSTE'\u003e iteration 73: loss = 4904.4249, delta_loss = 64.35030 learning_Rate = 0.01000 rmse=1.16069 mae=0.89587\n","\u003cclass '__main__.RSTE'\u003e iteration 74: loss = 4841.2525, delta_loss = 63.17241 learning_Rate = 0.01000 rmse=1.15999 mae=0.89518\n","\u003cclass '__main__.RSTE'\u003e iteration 75: loss = 4779.2214, delta_loss = 62.03109 learning_Rate = 0.01000 rmse=1.15932 mae=0.89451\n","\u003cclass '__main__.RSTE'\u003e iteration 76: loss = 4718.2969, delta_loss = 60.92448 learning_Rate = 0.01000 rmse=1.15868 mae=0.89387\n","\u003cclass '__main__.RSTE'\u003e iteration 77: loss = 4658.4461, delta_loss = 59.85084 learning_Rate = 0.01000 rmse=1.15808 mae=0.89325\n","\u003cclass '__main__.RSTE'\u003e iteration 78: loss = 4599.6376, delta_loss = 58.80850 learning_Rate = 0.01000 rmse=1.15748 mae=0.89264\n","\u003cclass '__main__.RSTE'\u003e iteration 79: loss = 4541.8417, delta_loss = 57.79592 learning_Rate = 0.01000 rmse=1.15693 mae=0.89208\n","\u003cclass '__main__.RSTE'\u003e iteration 80: loss = 4485.0301, delta_loss = 56.81160 learning_Rate = 0.01000 rmse=1.15640 mae=0.89153\n","\u003cclass '__main__.RSTE'\u003e iteration 81: loss = 4429.1759, delta_loss = 55.85414 learning_Rate = 0.01000 rmse=1.15589 mae=0.89100\n","\u003cclass '__main__.RSTE'\u003e iteration 82: loss = 4374.2537, delta_loss = 54.92224 learning_Rate = 0.01000 rmse=1.15541 mae=0.89049\n","\u003cclass '__main__.RSTE'\u003e iteration 83: loss = 4320.2390, delta_loss = 54.01463 learning_Rate = 0.01000 rmse=1.15495 mae=0.89000\n","\u003cclass '__main__.RSTE'\u003e iteration 84: loss = 4267.1089, delta_loss = 53.13015 learning_Rate = 0.01000 rmse=1.15450 mae=0.88953\n","\u003cclass '__main__.RSTE'\u003e iteration 85: loss = 4214.8412, delta_loss = 52.26767 learning_Rate = 0.01000 rmse=1.15409 mae=0.88908\n","\u003cclass '__main__.RSTE'\u003e iteration 86: loss = 4163.4151, delta_loss = 51.42615 learning_Rate = 0.01000 rmse=1.15369 mae=0.88865\n","\u003cclass '__main__.RSTE'\u003e iteration 87: loss = 4112.8105, delta_loss = 50.60461 learning_Rate = 0.01000 rmse=1.15331 mae=0.88825\n","\u003cclass '__main__.RSTE'\u003e iteration 88: loss = 4063.0084, delta_loss = 49.80211 learning_Rate = 0.01000 rmse=1.15295 mae=0.88787\n","\u003cclass '__main__.RSTE'\u003e iteration 89: loss = 4013.9906, delta_loss = 49.01778 learning_Rate = 0.01000 rmse=1.15262 mae=0.88750\n","\u003cclass '__main__.RSTE'\u003e iteration 90: loss = 3965.7398, delta_loss = 48.25080 learning_Rate = 0.01000 rmse=1.15228 mae=0.88714\n","\u003cclass '__main__.RSTE'\u003e iteration 91: loss = 3918.2394, delta_loss = 47.50039 learning_Rate = 0.01000 rmse=1.15196 mae=0.88679\n","\u003cclass '__main__.RSTE'\u003e iteration 92: loss = 3871.4736, delta_loss = 46.76583 learning_Rate = 0.01000 rmse=1.15166 mae=0.88646\n","\u003cclass '__main__.RSTE'\u003e iteration 93: loss = 3825.4271, delta_loss = 46.04645 learning_Rate = 0.01000 rmse=1.15137 mae=0.88613\n","\u003cclass '__main__.RSTE'\u003e iteration 94: loss = 3780.0855, delta_loss = 45.34160 learning_Rate = 0.01000 rmse=1.15109 mae=0.88581\n","\u003cclass '__main__.RSTE'\u003e iteration 95: loss = 3735.4348, delta_loss = 44.65069 learning_Rate = 0.01000 rmse=1.15082 mae=0.88550\n","\u003cclass '__main__.RSTE'\u003e iteration 96: loss = 3691.4616, delta_loss = 43.97317 learning_Rate = 0.01000 rmse=1.15056 mae=0.88520\n","\u003cclass '__main__.RSTE'\u003e iteration 97: loss = 3648.1531, delta_loss = 43.30853 learning_Rate = 0.01000 rmse=1.15031 mae=0.88492\n","\u003cclass '__main__.RSTE'\u003e iteration 98: loss = 3605.4969, delta_loss = 42.65626 learning_Rate = 0.01000 rmse=1.15008 mae=0.88465\n","\u003cclass '__main__.RSTE'\u003e iteration 99: loss = 3563.4809, delta_loss = 42.01593 learning_Rate = 0.01000 rmse=1.14987 mae=0.88440\n","\u003cclass '__main__.RSTE'\u003e iteration 100: loss = 3522.0938, delta_loss = 41.38712 learning_Rate = 0.01000 rmse=1.14966 mae=0.88416\n","the 4th cross validation training\n","\u003cclass '__main__.RSTE'\u003e iteration 1: loss = 38845.3755, delta_loss = -38845.37550 learning_Rate = 0.01000 rmse=2.42265 mae=2.10767\n","\u003cclass '__main__.RSTE'\u003e iteration 2: loss = 33371.5280, delta_loss = 5473.84755 learning_Rate = 0.01000 rmse=2.21546 mae=1.89530\n","\u003cclass '__main__.RSTE'\u003e iteration 3: loss = 29447.9682, delta_loss = 3923.55980 learning_Rate = 0.01000 rmse=2.05745 mae=1.73333\n","\u003cclass '__main__.RSTE'\u003e iteration 4: loss = 26566.2558, delta_loss = 2881.71234 learning_Rate = 0.01000 rmse=1.93511 mae=1.60864\n","\u003cclass '__main__.RSTE'\u003e iteration 5: loss = 24368.1806, delta_loss = 2198.07516 learning_Rate = 0.01000 rmse=1.83761 mae=1.51117\n","\u003cclass '__main__.RSTE'\u003e iteration 6: loss = 22621.0557, delta_loss = 1747.12496 learning_Rate = 0.01000 rmse=1.75843 mae=1.43384\n","\u003cclass '__main__.RSTE'\u003e iteration 7: loss = 21184.5621, delta_loss = 1436.49361 learning_Rate = 0.01000 rmse=1.69278 mae=1.37118\n","\u003cclass '__main__.RSTE'\u003e iteration 8: loss = 19973.2260, delta_loss = 1211.33610 learning_Rate = 0.01000 rmse=1.63735 mae=1.31941\n","\u003cclass '__main__.RSTE'\u003e iteration 9: loss = 18931.8281, delta_loss = 1041.39786 learning_Rate = 0.01000 rmse=1.58972 mae=1.27564\n","\u003cclass '__main__.RSTE'\u003e iteration 10: loss = 18022.5273, delta_loss = 909.30084 learning_Rate = 0.01000 rmse=1.54847 mae=1.23817\n","\u003cclass '__main__.RSTE'\u003e iteration 11: loss = 17218.3012, delta_loss = 804.22611 learning_Rate = 0.01000 rmse=1.51244 mae=1.20581\n","\u003cclass '__main__.RSTE'\u003e iteration 12: loss = 16499.3129, delta_loss = 718.98824 learning_Rate = 0.01000 rmse=1.48075 mae=1.17772\n","\u003cclass '__main__.RSTE'\u003e iteration 13: loss = 15850.6826, delta_loss = 648.63029 learning_Rate = 0.01000 rmse=1.45265 mae=1.15299\n","\u003cclass '__main__.RSTE'\u003e iteration 14: loss = 15261.0274, delta_loss = 589.65522 learning_Rate = 0.01000 rmse=1.42762 mae=1.13108\n","\u003cclass '__main__.RSTE'\u003e iteration 15: loss = 14721.4747, delta_loss = 539.55273 learning_Rate = 0.01000 rmse=1.40513 mae=1.11145\n","\u003cclass '__main__.RSTE'\u003e iteration 16: loss = 14224.9851, delta_loss = 496.48961 learning_Rate = 0.01000 rmse=1.38490 mae=1.09378\n","\u003cclass '__main__.RSTE'\u003e iteration 17: loss = 13765.8823, delta_loss = 459.10281 learning_Rate = 0.01000 rmse=1.36667 mae=1.07796\n","\u003cclass '__main__.RSTE'\u003e iteration 18: loss = 13339.5222, delta_loss = 426.36011 learning_Rate = 0.01000 rmse=1.35009 mae=1.06356\n","\u003cclass '__main__.RSTE'\u003e iteration 19: loss = 12942.0563, delta_loss = 397.46585 learning_Rate = 0.01000 rmse=1.33504 mae=1.05044\n","\u003cclass '__main__.RSTE'\u003e iteration 20: loss = 12570.2598, delta_loss = 371.79650 learning_Rate = 0.01000 rmse=1.32135 mae=1.03850\n","\u003cclass '__main__.RSTE'\u003e iteration 21: loss = 12221.4036, delta_loss = 348.85619 learning_Rate = 0.01000 rmse=1.30885 mae=1.02756\n","\u003cclass '__main__.RSTE'\u003e iteration 22: loss = 11893.1583, delta_loss = 328.24530 learning_Rate = 0.01000 rmse=1.29747 mae=1.01757\n","\u003cclass '__main__.RSTE'\u003e iteration 23: loss = 11583.5202, delta_loss = 309.63810 learning_Rate = 0.01000 rmse=1.28702 mae=1.00841\n","\u003cclass '__main__.RSTE'\u003e iteration 24: loss = 11290.7539, delta_loss = 292.76635 learning_Rate = 0.01000 rmse=1.27743 mae=1.00005\n","\u003cclass '__main__.RSTE'\u003e iteration 25: loss = 11013.3467, delta_loss = 277.40717 learning_Rate = 0.01000 rmse=1.26861 mae=0.99236\n","\u003cclass '__main__.RSTE'\u003e iteration 26: loss = 10749.9728, delta_loss = 263.37387 learning_Rate = 0.01000 rmse=1.26045 mae=0.98523\n","\u003cclass '__main__.RSTE'\u003e iteration 27: loss = 10499.4639, delta_loss = 250.50891 learning_Rate = 0.01000 rmse=1.25291 mae=0.97863\n","\u003cclass '__main__.RSTE'\u003e iteration 28: loss = 10260.7855, delta_loss = 238.67846 learning_Rate = 0.01000 rmse=1.24595 mae=0.97250\n","\u003cclass '__main__.RSTE'\u003e iteration 29: loss = 10033.0173, delta_loss = 227.76812 learning_Rate = 0.01000 rmse=1.23953 mae=0.96685\n","\u003cclass '__main__.RSTE'\u003e iteration 30: loss = 9815.3378, delta_loss = 217.67956 learning_Rate = 0.01000 rmse=1.23358 mae=0.96162\n","\u003cclass '__main__.RSTE'\u003e iteration 31: loss = 9607.0100, delta_loss = 208.32778 learning_Rate = 0.01000 rmse=1.22805 mae=0.95673\n","\u003cclass '__main__.RSTE'\u003e iteration 32: loss = 9407.3711, delta_loss = 199.63894 learning_Rate = 0.01000 rmse=1.22290 mae=0.95215\n","\u003cclass '__main__.RSTE'\u003e iteration 33: loss = 9215.8224, delta_loss = 191.54862 learning_Rate = 0.01000 rmse=1.21808 mae=0.94787\n","\u003cclass '__main__.RSTE'\u003e iteration 34: loss = 9031.8221, delta_loss = 184.00035 learning_Rate = 0.01000 rmse=1.21358 mae=0.94386\n","\u003cclass '__main__.RSTE'\u003e iteration 35: loss = 8854.8777, delta_loss = 176.94443 learning_Rate = 0.01000 rmse=1.20936 mae=0.94009\n","\u003cclass '__main__.RSTE'\u003e iteration 36: loss = 8684.5407, delta_loss = 170.33697 learning_Rate = 0.01000 rmse=1.20543 mae=0.93656\n","\u003cclass '__main__.RSTE'\u003e iteration 37: loss = 8520.4016, delta_loss = 164.13905 learning_Rate = 0.01000 rmse=1.20174 mae=0.93323\n","\u003cclass '__main__.RSTE'\u003e iteration 38: loss = 8362.0856, delta_loss = 158.31604 learning_Rate = 0.01000 rmse=1.19826 mae=0.93009\n","\u003cclass '__main__.RSTE'\u003e iteration 39: loss = 8209.2485, delta_loss = 152.83708 learning_Rate = 0.01000 rmse=1.19499 mae=0.92713\n","\u003cclass '__main__.RSTE'\u003e iteration 40: loss = 8061.5740, delta_loss = 147.67449 learning_Rate = 0.01000 rmse=1.19190 mae=0.92432\n","\u003cclass '__main__.RSTE'\u003e iteration 41: loss = 7918.7705, delta_loss = 142.80349 learning_Rate = 0.01000 rmse=1.18899 mae=0.92167\n","\u003cclass '__main__.RSTE'\u003e iteration 42: loss = 7780.5688, delta_loss = 138.20173 learning_Rate = 0.01000 rmse=1.18623 mae=0.91914\n","\u003cclass '__main__.RSTE'\u003e iteration 43: loss = 7646.7197, delta_loss = 133.84907 learning_Rate = 0.01000 rmse=1.18363 mae=0.91675\n","\u003cclass '__main__.RSTE'\u003e iteration 44: loss = 7516.9925, delta_loss = 129.72728 learning_Rate = 0.01000 rmse=1.18114 mae=0.91445\n","\u003cclass '__main__.RSTE'\u003e iteration 45: loss = 7391.1726, delta_loss = 125.81984 learning_Rate = 0.01000 rmse=1.17878 mae=0.91224\n","\u003cclass '__main__.RSTE'\u003e iteration 46: loss = 7269.0609, delta_loss = 122.11173 learning_Rate = 0.01000 rmse=1.17651 mae=0.91013\n","\u003cclass '__main__.RSTE'\u003e iteration 47: loss = 7150.4716, delta_loss = 118.58925 learning_Rate = 0.01000 rmse=1.17435 mae=0.90810\n","\u003cclass '__main__.RSTE'\u003e iteration 48: loss = 7035.2317, delta_loss = 115.23991 learning_Rate = 0.01000 rmse=1.17230 mae=0.90618\n","\u003cclass '__main__.RSTE'\u003e iteration 49: loss = 6923.1794, delta_loss = 112.05228 learning_Rate = 0.01000 rmse=1.17035 mae=0.90435\n","\u003cclass '__main__.RSTE'\u003e iteration 50: loss = 6814.1636, delta_loss = 109.01588 learning_Rate = 0.01000 rmse=1.16848 mae=0.90261\n","\u003cclass '__main__.RSTE'\u003e iteration 51: loss = 6708.0425, delta_loss = 106.12105 learning_Rate = 0.01000 rmse=1.16670 mae=0.90092\n","\u003cclass '__main__.RSTE'\u003e iteration 52: loss = 6604.6836, delta_loss = 103.35893 learning_Rate = 0.01000 rmse=1.16499 mae=0.89931\n","\u003cclass '__main__.RSTE'\u003e iteration 53: loss = 6503.9623, delta_loss = 100.72132 learning_Rate = 0.01000 rmse=1.16337 mae=0.89776\n","\u003cclass '__main__.RSTE'\u003e iteration 54: loss = 6405.7616, delta_loss = 98.20064 learning_Rate = 0.01000 rmse=1.16183 mae=0.89627\n","\u003cclass '__main__.RSTE'\u003e iteration 55: loss = 6309.9718, delta_loss = 95.78988 learning_Rate = 0.01000 rmse=1.16037 mae=0.89485\n","\u003cclass '__main__.RSTE'\u003e iteration 56: loss = 6216.4892, delta_loss = 93.48252 learning_Rate = 0.01000 rmse=1.15896 mae=0.89348\n","\u003cclass '__main__.RSTE'\u003e iteration 57: loss = 6125.2167, delta_loss = 91.27249 learning_Rate = 0.01000 rmse=1.15762 mae=0.89217\n","\u003cclass '__main__.RSTE'\u003e iteration 58: loss = 6036.0626, delta_loss = 89.15416 learning_Rate = 0.01000 rmse=1.15635 mae=0.89093\n","\u003cclass '__main__.RSTE'\u003e iteration 59: loss = 5948.9403, delta_loss = 87.12224 learning_Rate = 0.01000 rmse=1.15513 mae=0.88975\n","\u003cclass '__main__.RSTE'\u003e iteration 60: loss = 5863.7685, delta_loss = 85.17182 learning_Rate = 0.01000 rmse=1.15396 mae=0.88861\n","\u003cclass '__main__.RSTE'\u003e iteration 61: loss = 5780.4702, delta_loss = 83.29829 learning_Rate = 0.01000 rmse=1.15285 mae=0.88752\n","\u003cclass '__main__.RSTE'\u003e iteration 62: loss = 5698.9729, delta_loss = 81.49731 learning_Rate = 0.01000 rmse=1.15176 mae=0.88645\n","\u003cclass '__main__.RSTE'\u003e iteration 63: loss = 5619.2081, delta_loss = 79.76483 learning_Rate = 0.01000 rmse=1.15073 mae=0.88543\n","\u003cclass '__main__.RSTE'\u003e iteration 64: loss = 5541.1111, delta_loss = 78.09704 learning_Rate = 0.01000 rmse=1.14973 mae=0.88446\n","\u003cclass '__main__.RSTE'\u003e iteration 65: loss = 5464.6207, delta_loss = 76.49035 learning_Rate = 0.01000 rmse=1.14877 mae=0.88352\n","\u003cclass '__main__.RSTE'\u003e iteration 66: loss = 5389.6793, delta_loss = 74.94139 learning_Rate = 0.01000 rmse=1.14784 mae=0.88261\n","\u003cclass '__main__.RSTE'\u003e iteration 67: loss = 5316.2323, delta_loss = 73.44697 learning_Rate = 0.01000 rmse=1.14695 mae=0.88173\n","\u003cclass '__main__.RSTE'\u003e iteration 68: loss = 5244.2282, delta_loss = 72.00410 learning_Rate = 0.01000 rmse=1.14609 mae=0.88089\n","\u003cclass '__main__.RSTE'\u003e iteration 69: loss = 5173.6183, delta_loss = 70.60995 learning_Rate = 0.01000 rmse=1.14527 mae=0.88008\n","\u003cclass '__main__.RSTE'\u003e iteration 70: loss = 5104.3564, delta_loss = 69.26185 learning_Rate = 0.01000 rmse=1.14449 mae=0.87931\n","\u003cclass '__main__.RSTE'\u003e iteration 71: loss = 5036.3992, delta_loss = 67.95729 learning_Rate = 0.01000 rmse=1.14375 mae=0.87857\n","\u003cclass '__main__.RSTE'\u003e iteration 72: loss = 4969.7053, delta_loss = 66.69390 learning_Rate = 0.01000 rmse=1.14305 mae=0.87787\n","\u003cclass '__main__.RSTE'\u003e iteration 73: loss = 4904.2358, delta_loss = 65.46944 learning_Rate = 0.01000 rmse=1.14237 mae=0.87719\n","\u003cclass '__main__.RSTE'\u003e iteration 74: loss = 4839.9540, delta_loss = 64.28181 learning_Rate = 0.01000 rmse=1.14172 mae=0.87654\n","\u003cclass '__main__.RSTE'\u003e iteration 75: loss = 4776.8250, delta_loss = 63.12902 learning_Rate = 0.01000 rmse=1.14110 mae=0.87592\n","\u003cclass '__main__.RSTE'\u003e iteration 76: loss = 4714.8158, delta_loss = 62.00921 learning_Rate = 0.01000 rmse=1.14050 mae=0.87533\n","\u003cclass '__main__.RSTE'\u003e iteration 77: loss = 4653.8952, delta_loss = 60.92061 learning_Rate = 0.01000 rmse=1.13992 mae=0.87475\n","\u003cclass '__main__.RSTE'\u003e iteration 78: loss = 4594.0336, delta_loss = 59.86158 learning_Rate = 0.01000 rmse=1.13938 mae=0.87420\n","\u003cclass '__main__.RSTE'\u003e iteration 79: loss = 4535.2030, delta_loss = 58.83057 learning_Rate = 0.01000 rmse=1.13885 mae=0.87368\n","\u003cclass '__main__.RSTE'\u003e iteration 80: loss = 4477.3769, delta_loss = 57.82614 learning_Rate = 0.01000 rmse=1.13834 mae=0.87316\n","\u003cclass '__main__.RSTE'\u003e iteration 81: loss = 4420.5300, delta_loss = 56.84691 learning_Rate = 0.01000 rmse=1.13785 mae=0.87266\n","\u003cclass '__main__.RSTE'\u003e iteration 82: loss = 4364.6383, delta_loss = 55.89162 learning_Rate = 0.01000 rmse=1.13738 mae=0.87218\n","\u003cclass '__main__.RSTE'\u003e iteration 83: loss = 4309.6793, delta_loss = 54.95908 learning_Rate = 0.01000 rmse=1.13693 mae=0.87173\n","\u003cclass '__main__.RSTE'\u003e iteration 84: loss = 4255.6311, delta_loss = 54.04818 learning_Rate = 0.01000 rmse=1.13650 mae=0.87129\n","\u003cclass '__main__.RSTE'\u003e iteration 85: loss = 4202.4732, delta_loss = 53.15791 learning_Rate = 0.01000 rmse=1.13610 mae=0.87087\n","\u003cclass '__main__.RSTE'\u003e iteration 86: loss = 4150.1859, delta_loss = 52.28728 learning_Rate = 0.01000 rmse=1.13571 mae=0.87046\n","\u003cclass '__main__.RSTE'\u003e iteration 87: loss = 4098.7505, delta_loss = 51.43543 learning_Rate = 0.01000 rmse=1.13534 mae=0.87007\n","\u003cclass '__main__.RSTE'\u003e iteration 88: loss = 4048.1489, delta_loss = 50.60151 learning_Rate = 0.01000 rmse=1.13499 mae=0.86969\n","\u003cclass '__main__.RSTE'\u003e iteration 89: loss = 3998.3642, delta_loss = 49.78477 learning_Rate = 0.01000 rmse=1.13465 mae=0.86934\n","\u003cclass '__main__.RSTE'\u003e iteration 90: loss = 3949.3797, delta_loss = 48.98449 learning_Rate = 0.01000 rmse=1.13433 mae=0.86899\n","\u003cclass '__main__.RSTE'\u003e iteration 91: loss = 3901.1797, delta_loss = 48.20002 learning_Rate = 0.01000 rmse=1.13404 mae=0.86866\n","\u003cclass '__main__.RSTE'\u003e iteration 92: loss = 3853.7489, delta_loss = 47.43076 learning_Rate = 0.01000 rmse=1.13375 mae=0.86835\n","\u003cclass '__main__.RSTE'\u003e iteration 93: loss = 3807.0728, delta_loss = 46.67615 learning_Rate = 0.01000 rmse=1.13347 mae=0.86804\n","\u003cclass '__main__.RSTE'\u003e iteration 94: loss = 3761.1371, delta_loss = 45.93568 learning_Rate = 0.01000 rmse=1.13322 mae=0.86775\n","\u003cclass '__main__.RSTE'\u003e iteration 95: loss = 3715.9282, delta_loss = 45.20886 learning_Rate = 0.01000 rmse=1.13299 mae=0.86748\n","\u003cclass '__main__.RSTE'\u003e iteration 96: loss = 3671.4330, delta_loss = 44.49526 learning_Rate = 0.01000 rmse=1.13277 mae=0.86723\n","\u003cclass '__main__.RSTE'\u003e iteration 97: loss = 3627.6385, delta_loss = 43.79448 learning_Rate = 0.01000 rmse=1.13256 mae=0.86700\n","\u003cclass '__main__.RSTE'\u003e iteration 98: loss = 3584.5323, delta_loss = 43.10615 learning_Rate = 0.01000 rmse=1.13237 mae=0.86679\n","\u003cclass '__main__.RSTE'\u003e iteration 99: loss = 3542.1024, delta_loss = 42.42992 learning_Rate = 0.01000 rmse=1.13221 mae=0.86659\n","\u003cclass '__main__.RSTE'\u003e iteration 100: loss = 3500.3369, delta_loss = 41.76547 learning_Rate = 0.01000 rmse=1.13206 mae=0.86641\n","the rmses are [1.1527885705500809, 1.1578158303020287, 1.125052842485495, 1.1496630456373171, 1.1320585958575047]\n","the maes are [0.8874398752454645, 0.8810201056985276, 0.8746645663879026, 0.884156016978319, 0.8664107081569601]\n","the average of rmses is 1.1434757769664852 \n","the average of maes is 0.8787382544934348 \n"]}],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")  # add current path into environment variable\n","import numpy as np\n","#from mf import MF\n","#from reader.trust import TrustGetter\n","\n","\n","# from utility.similarity import pearson_sp\n","\n","\n","class RSTE(MF):\n","    \"\"\"\n","    docstring for RSTE\n","\n","    Ma H, King I, Lyu M R. Learning to recommend with social trust ensemble[C]//Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. ACM, 2009: 203-210.\n","\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(RSTE, self).__init__()\n","        # self.maxIter=700\n","        self.config.alpha = 0.5\n","        # self.config.lambdaH=0.01\n","        self.tg = TrustGetter()\n","        # self.init_model()\n","\n","    def init_model(self, k):\n","        super(RSTE, self).init_model(k)\n","\n","    # from collections import defaultdict\n","    # self.Sim = defaultdict(dict)\n","    # print('constructing similarity matrix...')\n","    # for user in self.rg.user:\n","    # \tfor k in self.tg.get_followees(user):\n","    # \t\tif user in self.Sim and k in self.Sim[user]:\n","    # \t\t\tpass\n","    # \t\telse:\n","    # \t\t\tself.Sim[user][k]=self.get_sim(user,k)\n","\n","    def train_model(self, k):\n","        super(RSTE, self).train_model(k)\n","        iteration = 0\n","        while iteration \u003c self.config.maxIter:\n","            self.loss = 0\n","            for index, line in enumerate(self.rg.trainSet()):\n","                user, item, rating = line\n","\n","                error = rating - self.predict(user, item)\n","                self.loss += error ** 2\n","                social_term, _ = self.get_social_term_Q(user, item)\n","\n","                u = self.rg.user[user]\n","                i = self.rg.item[item]\n","                p, q = self.P[u], self.Q[i]\n","\n","                # update latent vectors\n","\n","                self.P[u] += self.config.lr * (self.config.alpha * error * q + \\\n","                                               (1 - self.config.alpha) * self.get_social_term_P(user,\n","                                                                                                item) - self.config.lambdaP * p)\n","\n","                self.Q[i] += self.config.lr * (error * (self.config.alpha * p + (1 - self.config.alpha) * social_term) \\\n","                                               - self.config.lambdaQ * q)\n","\n","            self.loss += self.config.lambdaP * (self.P * self.P).sum() + self.config.lambdaQ * (self.Q * self.Q).sum()\n","\n","            iteration += 1\n","            if self.isConverged(iteration):\n","                break\n","\n","    def get_social_term_Q(self, user, item):\n","        if self.rg.containsUser(user) and self.rg.containsItem(item):\n","            i = self.rg.item[item]\n","            u = self.rg.user[user]\n","            social_term_loss = 0\n","            social_term = np.zeros(self.config.factor)\n","            followees = self.tg.get_followees(user)\n","            weights = []\n","            indexes = []\n","            for followee in followees:\n","                if self.rg.containsUser(followee):  # followee is in rating set\n","                    indexes.append(self.rg.user[followee])\n","                    weights.append(followees[followee])\n","            weights = np.array(weights)\n","            qw = weights.sum()\n","            indexes = np.array(indexes)\n","            if qw != 0:\n","                social_term = weights.dot(self.P[indexes])\n","                social_term /= qw\n","                social_term_loss += weights.dot((self.P[indexes].dot(self.Q[i]))) / qw\n","            return social_term, social_term_loss\n","\n","    def get_social_term_P(self, user, item):\n","        i = self.rg.item[item]\n","        # social_term_loss = 0\n","        social_term = np.zeros(self.config.factor)\n","\n","        followers = self.tg.get_followers(user)\n","        weights = []\n","        indexes = []\n","        errs = []\n","        for follower in followers:\n","            if self.rg.containsUser(follower) and self.rg.containsItem(item) and self.rg.containsUserItem(follower,\n","                                                                                                          item):  # followee is in rating set\n","                indexes.append(self.rg.user[follower])\n","                weights.append(followers[follower])\n","                errs.append(self.rg.trainSet_u[follower][item] - self.predict(follower, item))\n","        weights = np.array(weights)\n","        indexes = np.array(indexes)\n","        errs = np.array(errs)\n","        qw = weights.sum()\n","        if qw != 0:\n","            for es in errs * weights:\n","                social_term += es * self.Q[i]\n","            social_term /= qw\n","        # social_term_loss += weights.dot((self.P[indexes].dot(self.Q[i])))\n","        return social_term\n","\n","    def predict(self, u, i):\n","        if self.rg.containsUser(u) and self.rg.containsItem(i):\n","            _, social_term_loss = self.get_social_term_Q(u, i)\n","            i = self.rg.item[i]\n","            u = self.rg.user[u]\n","\n","            if social_term_loss != 0:\n","                return self.config.alpha * self.P[u].dot(self.Q[i]) + (1 - self.config.alpha) * social_term_loss\n","            else:\n","                return self.P[u].dot(self.Q[i])\n","        else:\n","            return self.rg.globalMean\n","\n","        # def get_sim(self,u,k):\n","        # \treturn (pearson_sp(self.rg.get_row(u), self.rg.get_row(k))+1.0)/2.0\n","\n","\n","if __name__ == '__main__':\n","    rmses = []\n","    maes = []\n","    tcsr = RSTE()\n","    # print(bmf.rg.trainSet_u[1])\n","    for i in range(tcsr.config.k_fold_num):\n","        print('the %dth cross validation training' % i)\n","        tcsr.train_model(i)\n","        rmse, mae = tcsr.predict_model()\n","        rmses.append(rmse)\n","        maes.append(mae)\n","    rmse_avg = sum(rmses) / 5\n","    mae_avg = sum(maes) / 5\n","    print(\"the rmses are %s\" % rmses)\n","    print(\"the maes are %s\" % maes)\n","    print(\"the average of rmses is %s \" % rmse_avg)\n","    print(\"the average of maes is %s \" % mae_avg)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1117533,"status":"ok","timestamp":1621254411489,"user":{"displayName":"Liakos Liakouras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6NT3RUPWrqjgd4sDMwDCfnAVGQSIp4lYCoOv0=s64","userId":"13672684891848947720"},"user_tz":-180},"id":"p43kX8dMfNkf","outputId":"54ef03c6-cb1a-41ee-e360-17e1458967c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'dataset_name': 'CiaoDVD', 'k_fold_num': 5, 'rating_path': '/content/drive/MyDrive/data/ft_ratings.txt', 'rating_cv_path': '../data/cv/', 'trust_path': '/content/drive/MyDrive/data/ft_trust_SimRank.txt', 'sep': ' ', 'random_state': 0, 'size': 0.6, 'min_val': 0.5, 'max_val': 4.0, 'coldUserRating': 5, 'factor': 10, 'threshold': 0.0001, 'lr': 0.01, 'maxIter': 100, 'lambdaP': 0.001, 'lambdaQ': 0.001, 'gamma': 0, 'isEarlyStopping': False, 'result_path': '../results/', 'model_path': 'model/', 'result_log_path': 'log/'}\n","the 0th cross validation training\n","constructing user-user similarity matrix...\n","\u003cclass '__main__.SocialReg'\u003e iteration 1: loss = 18397.0782, delta_loss = -18397.07817 learning_Rate = 0.01000 rmse=2.23368 mae=1.91649\n","\u003cclass '__main__.SocialReg'\u003e iteration 2: loss = 14605.1917, delta_loss = 3791.88650 learning_Rate = 0.01000 rmse=1.96837 mae=1.65151\n","\u003cclass '__main__.SocialReg'\u003e iteration 3: loss = 12363.3580, delta_loss = 2241.83372 learning_Rate = 0.01000 rmse=1.79622 mae=1.48492\n","\u003cclass '__main__.SocialReg'\u003e iteration 4: loss = 10878.9622, delta_loss = 1484.39577 learning_Rate = 0.01000 rmse=1.67661 mae=1.37252\n","\u003cclass '__main__.SocialReg'\u003e iteration 5: loss = 9802.1584, delta_loss = 1076.80374 learning_Rate = 0.01000 rmse=1.58898 mae=1.29169\n","\u003cclass '__main__.SocialReg'\u003e iteration 6: loss = 8966.9795, delta_loss = 835.17891 learning_Rate = 0.01000 rmse=1.52222 mae=1.23107\n","\u003cclass '__main__.SocialReg'\u003e iteration 7: loss = 8289.4849, delta_loss = 677.49462 learning_Rate = 0.01000 rmse=1.46947 mae=1.18368\n","\u003cclass '__main__.SocialReg'\u003e iteration 8: loss = 7722.8690, delta_loss = 566.61593 learning_Rate = 0.01000 rmse=1.42727 mae=1.14586\n","\u003cclass '__main__.SocialReg'\u003e iteration 9: loss = 7238.6306, delta_loss = 484.23840 learning_Rate = 0.01000 rmse=1.39268 mae=1.11500\n","\u003cclass '__main__.SocialReg'\u003e iteration 10: loss = 6818.0883, delta_loss = 420.54231 learning_Rate = 0.01000 rmse=1.36414 mae=1.08956\n","\u003cclass '__main__.SocialReg'\u003e iteration 11: loss = 6448.2480, delta_loss = 369.84031 learning_Rate = 0.01000 rmse=1.34025 mae=1.06825\n","\u003cclass '__main__.SocialReg'\u003e iteration 12: loss = 6119.6507, delta_loss = 328.59723 learning_Rate = 0.01000 rmse=1.31992 mae=1.05012\n","\u003cclass '__main__.SocialReg'\u003e iteration 13: loss = 5825.1736, delta_loss = 294.47709 learning_Rate = 0.01000 rmse=1.30240 mae=1.03452\n","\u003cclass '__main__.SocialReg'\u003e iteration 14: loss = 5559.3145, delta_loss = 265.85914 learning_Rate = 0.01000 rmse=1.28725 mae=1.02107\n","\u003cclass '__main__.SocialReg'\u003e iteration 15: loss = 5317.7381, delta_loss = 241.57641 learning_Rate = 0.01000 rmse=1.27402 mae=1.00929\n","\u003cclass '__main__.SocialReg'\u003e iteration 16: loss = 5096.9735, delta_loss = 220.76458 learning_Rate = 0.01000 rmse=1.26241 mae=0.99893\n","\u003cclass '__main__.SocialReg'\u003e iteration 17: loss = 4894.2042, delta_loss = 202.76926 learning_Rate = 0.01000 rmse=1.25213 mae=0.98983\n","\u003cclass '__main__.SocialReg'\u003e iteration 18: loss = 4707.1182, delta_loss = 187.08607 learning_Rate = 0.01000 rmse=1.24301 mae=0.98178\n","\u003cclass '__main__.SocialReg'\u003e iteration 19: loss = 4533.7977, delta_loss = 173.32045 learning_Rate = 0.01000 rmse=1.23484 mae=0.97452\n","\u003cclass '__main__.SocialReg'\u003e iteration 20: loss = 4372.6379, delta_loss = 161.15981 learning_Rate = 0.01000 rmse=1.22749 mae=0.96800\n","\u003cclass '__main__.SocialReg'\u003e iteration 21: loss = 4222.2841, delta_loss = 150.35378 learning_Rate = 0.01000 rmse=1.22086 mae=0.96208\n","\u003cclass '__main__.SocialReg'\u003e iteration 22: loss = 4081.5843, delta_loss = 140.69983 learning_Rate = 0.01000 rmse=1.21484 mae=0.95673\n","\u003cclass '__main__.SocialReg'\u003e iteration 23: loss = 3949.5516, delta_loss = 132.03270 learning_Rate = 0.01000 rmse=1.20936 mae=0.95184\n","\u003cclass '__main__.SocialReg'\u003e iteration 24: loss = 3825.3352, delta_loss = 124.21641 learning_Rate = 0.01000 rmse=1.20430 mae=0.94731\n","\u003cclass '__main__.SocialReg'\u003e iteration 25: loss = 3708.1969, delta_loss = 117.13824 learning_Rate = 0.01000 rmse=1.19965 mae=0.94312\n","\u003cclass '__main__.SocialReg'\u003e iteration 26: loss = 3597.4929, delta_loss = 110.70403 learning_Rate = 0.01000 rmse=1.19538 mae=0.93925\n","\u003cclass '__main__.SocialReg'\u003e iteration 27: loss = 3492.6583, delta_loss = 104.83461 learning_Rate = 0.01000 rmse=1.19145 mae=0.93569\n","\u003cclass '__main__.SocialReg'\u003e iteration 28: loss = 3393.1954, delta_loss = 99.46294 learning_Rate = 0.01000 rmse=1.18781 mae=0.93237\n","\u003cclass '__main__.SocialReg'\u003e iteration 29: loss = 3298.6635, delta_loss = 94.53190 learning_Rate = 0.01000 rmse=1.18444 mae=0.92929\n","\u003cclass '__main__.SocialReg'\u003e iteration 30: loss = 3208.6710, delta_loss = 89.99248 learning_Rate = 0.01000 rmse=1.18129 mae=0.92641\n","\u003cclass '__main__.SocialReg'\u003e iteration 31: loss = 3122.8686, delta_loss = 85.80242 learning_Rate = 0.01000 rmse=1.17836 mae=0.92373\n","\u003cclass '__main__.SocialReg'\u003e iteration 32: loss = 3040.9435, delta_loss = 81.92505 learning_Rate = 0.01000 rmse=1.17559 mae=0.92120\n","\u003cclass '__main__.SocialReg'\u003e iteration 33: loss = 2962.6151, delta_loss = 78.32839 learning_Rate = 0.01000 rmse=1.17299 mae=0.91882\n","\u003cclass '__main__.SocialReg'\u003e iteration 34: loss = 2887.6308, delta_loss = 74.98437 learning_Rate = 0.01000 rmse=1.17055 mae=0.91658\n","\u003cclass '__main__.SocialReg'\u003e iteration 35: loss = 2815.7624, delta_loss = 71.86831 learning_Rate = 0.01000 rmse=1.16825 mae=0.91447\n","\u003cclass '__main__.SocialReg'\u003e iteration 36: loss = 2746.8041, delta_loss = 68.95836 learning_Rate = 0.01000 rmse=1.16608 mae=0.91246\n","\u003cclass '__main__.SocialReg'\u003e iteration 37: loss = 2680.5690, delta_loss = 66.23512 learning_Rate = 0.01000 rmse=1.16404 mae=0.91056\n","\u003cclass '__main__.SocialReg'\u003e iteration 38: loss = 2616.8876, delta_loss = 63.68133 learning_Rate = 0.01000 rmse=1.16212 mae=0.90878\n","\u003cclass '__main__.SocialReg'\u003e iteration 39: loss = 2555.6061, delta_loss = 61.28157 learning_Rate = 0.01000 rmse=1.16031 mae=0.90708\n","\u003cclass '__main__.SocialReg'\u003e iteration 40: loss = 2496.5840, delta_loss = 59.02206 learning_Rate = 0.01000 rmse=1.15859 mae=0.90549\n","\u003cclass '__main__.SocialReg'\u003e iteration 41: loss = 2439.6936, delta_loss = 56.89042 learning_Rate = 0.01000 rmse=1.15697 mae=0.90398\n","\u003cclass '__main__.SocialReg'\u003e iteration 42: loss = 2384.8180, delta_loss = 54.87558 learning_Rate = 0.01000 rmse=1.15542 mae=0.90253\n","\u003cclass '__main__.SocialReg'\u003e iteration 43: loss = 2331.8504, delta_loss = 52.96759 learning_Rate = 0.01000 rmse=1.15395 mae=0.90114\n","\u003cclass '__main__.SocialReg'\u003e iteration 44: loss = 2280.6929, delta_loss = 51.15750 learning_Rate = 0.01000 rmse=1.15255 mae=0.89981\n","\u003cclass '__main__.SocialReg'\u003e iteration 45: loss = 2231.2556, delta_loss = 49.43729 learning_Rate = 0.01000 rmse=1.15125 mae=0.89856\n","\u003cclass '__main__.SocialReg'\u003e iteration 46: loss = 2183.4558, delta_loss = 47.79978 learning_Rate = 0.01000 rmse=1.15000 mae=0.89736\n","\u003cclass '__main__.SocialReg'\u003e iteration 47: loss = 2137.2173, delta_loss = 46.23850 learning_Rate = 0.01000 rmse=1.14884 mae=0.89624\n","\u003cclass '__main__.SocialReg'\u003e iteration 48: loss = 2092.4697, delta_loss = 44.74766 learning_Rate = 0.01000 rmse=1.14775 mae=0.89518\n","\u003cclass '__main__.SocialReg'\u003e iteration 49: loss = 2049.1476, delta_loss = 43.32210 learning_Rate = 0.01000 rmse=1.14672 mae=0.89418\n","\u003cclass '__main__.SocialReg'\u003e iteration 50: loss = 2007.1904, delta_loss = 41.95717 learning_Rate = 0.01000 rmse=1.14575 mae=0.89322\n","\u003cclass '__main__.SocialReg'\u003e iteration 51: loss = 1966.5417, delta_loss = 40.64873 learning_Rate = 0.01000 rmse=1.14484 mae=0.89231\n","\u003cclass '__main__.SocialReg'\u003e iteration 52: loss = 1927.1486, delta_loss = 39.39307 learning_Rate = 0.01000 rmse=1.14397 mae=0.89144\n","\u003cclass '__main__.SocialReg'\u003e iteration 53: loss = 1888.9617, delta_loss = 38.18689 learning_Rate = 0.01000 rmse=1.14314 mae=0.89061\n","\u003cclass '__main__.SocialReg'\u003e iteration 54: loss = 1851.9345, delta_loss = 37.02721 learning_Rate = 0.01000 rmse=1.14236 mae=0.88981\n","\u003cclass '__main__.SocialReg'\u003e iteration 55: loss = 1816.0231, delta_loss = 35.91137 learning_Rate = 0.01000 rmse=1.14162 mae=0.88906\n","\u003cclass '__main__.SocialReg'\u003e iteration 56: loss = 1781.1862, delta_loss = 34.83699 learning_Rate = 0.01000 rmse=1.14093 mae=0.88835\n","\u003cclass '__main__.SocialReg'\u003e iteration 57: loss = 1747.3842, delta_loss = 33.80192 learning_Rate = 0.01000 rmse=1.14028 mae=0.88767\n","\u003cclass '__main__.SocialReg'\u003e iteration 58: loss = 1714.5800, delta_loss = 32.80421 learning_Rate = 0.01000 rmse=1.13967 mae=0.88703\n","\u003cclass '__main__.SocialReg'\u003e iteration 59: loss = 1682.7379, delta_loss = 31.84212 learning_Rate = 0.01000 rmse=1.13910 mae=0.88640\n","\u003cclass '__main__.SocialReg'\u003e iteration 60: loss = 1651.8239, delta_loss = 30.91402 learning_Rate = 0.01000 rmse=1.13855 mae=0.88581\n","\u003cclass '__main__.SocialReg'\u003e iteration 61: loss = 1621.8054, delta_loss = 30.01845 learning_Rate = 0.01000 rmse=1.13803 mae=0.88524\n","\u003cclass '__main__.SocialReg'\u003e iteration 62: loss = 1592.6514, delta_loss = 29.15406 learning_Rate = 0.01000 rmse=1.13755 mae=0.88471\n","\u003cclass '__main__.SocialReg'\u003e iteration 63: loss = 1564.3318, delta_loss = 28.31957 learning_Rate = 0.01000 rmse=1.13710 mae=0.88421\n","\u003cclass '__main__.SocialReg'\u003e iteration 64: loss = 1536.8180, delta_loss = 27.51382 learning_Rate = 0.01000 rmse=1.13668 mae=0.88374\n","\u003cclass '__main__.SocialReg'\u003e iteration 65: loss = 1510.0823, delta_loss = 26.73570 learning_Rate = 0.01000 rmse=1.13630 mae=0.88328\n","\u003cclass '__main__.SocialReg'\u003e iteration 66: loss = 1484.0981, delta_loss = 25.98416 learning_Rate = 0.01000 rmse=1.13594 mae=0.88285\n","\u003cclass '__main__.SocialReg'\u003e iteration 67: loss = 1458.8399, delta_loss = 25.25820 learning_Rate = 0.01000 rmse=1.13559 mae=0.88243\n","\u003cclass '__main__.SocialReg'\u003e iteration 68: loss = 1434.2830, delta_loss = 24.55689 learning_Rate = 0.01000 rmse=1.13528 mae=0.88204\n","\u003cclass '__main__.SocialReg'\u003e iteration 69: loss = 1410.4037, delta_loss = 23.87932 learning_Rate = 0.01000 rmse=1.13495 mae=0.88165\n","\u003cclass '__main__.SocialReg'\u003e iteration 70: loss = 1387.1791, delta_loss = 23.22460 learning_Rate = 0.01000 rmse=1.13464 mae=0.88128\n","\u003cclass '__main__.SocialReg'\u003e iteration 71: loss = 1364.5872, delta_loss = 22.59191 learning_Rate = 0.01000 rmse=1.13434 mae=0.88092\n","\u003cclass '__main__.SocialReg'\u003e iteration 72: loss = 1342.6068, delta_loss = 21.98041 learning_Rate = 0.01000 rmse=1.13408 mae=0.88059\n","\u003cclass '__main__.SocialReg'\u003e iteration 73: loss = 1321.2175, delta_loss = 21.38935 learning_Rate = 0.01000 rmse=1.13382 mae=0.88028\n","\u003cclass '__main__.SocialReg'\u003e iteration 74: loss = 1300.3995, delta_loss = 20.81794 learning_Rate = 0.01000 rmse=1.13359 mae=0.87999\n","\u003cclass '__main__.SocialReg'\u003e iteration 75: loss = 1280.1341, delta_loss = 20.26546 learning_Rate = 0.01000 rmse=1.13338 mae=0.87973\n","\u003cclass '__main__.SocialReg'\u003e iteration 76: loss = 1260.4028, delta_loss = 19.73121 learning_Rate = 0.01000 rmse=1.13317 mae=0.87949\n","\u003cclass '__main__.SocialReg'\u003e iteration 77: loss = 1241.1884, delta_loss = 19.21449 learning_Rate = 0.01000 rmse=1.13299 mae=0.87926\n","\u003cclass '__main__.SocialReg'\u003e iteration 78: loss = 1222.4737, delta_loss = 18.71464 learning_Rate = 0.01000 rmse=1.13281 mae=0.87904\n","\u003cclass '__main__.SocialReg'\u003e iteration 79: loss = 1204.2427, delta_loss = 18.23102 learning_Rate = 0.01000 rmse=1.13265 mae=0.87882\n","\u003cclass '__main__.SocialReg'\u003e iteration 80: loss = 1186.4797, delta_loss = 17.76303 learning_Rate = 0.01000 rmse=1.13249 mae=0.87862\n","\u003cclass '__main__.SocialReg'\u003e iteration 81: loss = 1169.1696, delta_loss = 17.31006 learning_Rate = 0.01000 rmse=1.13235 mae=0.87844\n","\u003cclass '__main__.SocialReg'\u003e iteration 82: loss = 1152.2980, delta_loss = 16.87156 learning_Rate = 0.01000 rmse=1.13223 mae=0.87826\n","\u003cclass '__main__.SocialReg'\u003e iteration 83: loss = 1135.8511, delta_loss = 16.44696 learning_Rate = 0.01000 rmse=1.13212 mae=0.87810\n","\u003cclass '__main__.SocialReg'\u003e iteration 84: loss = 1119.8153, delta_loss = 16.03575 learning_Rate = 0.01000 rmse=1.13202 mae=0.87795\n","\u003cclass '__main__.SocialReg'\u003e iteration 85: loss = 1104.1779, delta_loss = 15.63743 learning_Rate = 0.01000 rmse=1.13194 mae=0.87782\n","\u003cclass '__main__.SocialReg'\u003e iteration 86: loss = 1088.9264, delta_loss = 15.25150 learning_Rate = 0.01000 rmse=1.13188 mae=0.87769\n","\u003cclass '__main__.SocialReg'\u003e iteration 87: loss = 1074.0489, delta_loss = 14.87751 learning_Rate = 0.01000 rmse=1.13182 mae=0.87757\n","\u003cclass '__main__.SocialReg'\u003e iteration 88: loss = 1059.5339, delta_loss = 14.51501 learning_Rate = 0.01000 rmse=1.13178 mae=0.87747\n","\u003cclass '__main__.SocialReg'\u003e iteration 89: loss = 1045.3703, delta_loss = 14.16359 learning_Rate = 0.01000 rmse=1.13176 mae=0.87738\n","\u003cclass '__main__.SocialReg'\u003e iteration 90: loss = 1031.5475, delta_loss = 13.82284 learning_Rate = 0.01000 rmse=1.13174 mae=0.87729\n","\u003cclass '__main__.SocialReg'\u003e iteration 91: loss = 1018.0551, delta_loss = 13.49236 learning_Rate = 0.01000 rmse=1.13174 mae=0.87722\n","\u003cclass '__main__.SocialReg'\u003e iteration 92: loss = 1004.8833, delta_loss = 13.17179 learning_Rate = 0.01000 rmse=1.13174 mae=0.87714\n","\u003cclass '__main__.SocialReg'\u003e iteration 93: loss = 992.0225, delta_loss = 12.86078 learning_Rate = 0.01000 rmse=1.13175 mae=0.87709\n","\u003cclass '__main__.SocialReg'\u003e iteration 94: loss = 979.4635, delta_loss = 12.55899 learning_Rate = 0.01000 rmse=1.13177 mae=0.87704\n","\u003cclass '__main__.SocialReg'\u003e iteration 95: loss = 967.1974, delta_loss = 12.26609 learning_Rate = 0.01000 rmse=1.13180 mae=0.87700\n","\u003cclass '__main__.SocialReg'\u003e iteration 96: loss = 955.2157, delta_loss = 11.98178 learning_Rate = 0.01000 rmse=1.13183 mae=0.87696\n","\u003cclass '__main__.SocialReg'\u003e iteration 97: loss = 943.5099, delta_loss = 11.70575 learning_Rate = 0.01000 rmse=1.13187 mae=0.87693\n","\u003cclass '__main__.SocialReg'\u003e iteration 98: loss = 932.0722, delta_loss = 11.43772 learning_Rate = 0.01000 rmse=1.13192 mae=0.87691\n","\u003cclass '__main__.SocialReg'\u003e iteration 99: loss = 920.8948, delta_loss = 11.17743 learning_Rate = 0.01000 rmse=1.13197 mae=0.87689\n","\u003cclass '__main__.SocialReg'\u003e iteration 100: loss = 909.9702, delta_loss = 10.92460 learning_Rate = 0.01000 rmse=1.13204 mae=0.87687\n","the 1th cross validation training\n","constructing user-user similarity matrix...\n","\u003cclass '__main__.SocialReg'\u003e iteration 1: loss = 18463.1096, delta_loss = -18463.10963 learning_Rate = 0.01000 rmse=2.25799 mae=1.93454\n","\u003cclass '__main__.SocialReg'\u003e iteration 2: loss = 14682.7575, delta_loss = 3780.35217 learning_Rate = 0.01000 rmse=1.99251 mae=1.67011\n","\u003cclass '__main__.SocialReg'\u003e iteration 3: loss = 12441.3563, delta_loss = 2241.40117 learning_Rate = 0.01000 rmse=1.81758 mae=1.50084\n","\u003cclass '__main__.SocialReg'\u003e iteration 4: loss = 10948.5720, delta_loss = 1492.78431 learning_Rate = 0.01000 rmse=1.69574 mae=1.38540\n","\u003cclass '__main__.SocialReg'\u003e iteration 5: loss = 9862.8986, delta_loss = 1085.67337 learning_Rate = 0.01000 rmse=1.60623 mae=1.30231\n","\u003cclass '__main__.SocialReg'\u003e iteration 6: loss = 9020.9906, delta_loss = 841.90799 learning_Rate = 0.01000 rmse=1.53792 mae=1.23993\n","\u003cclass '__main__.SocialReg'\u003e iteration 7: loss = 8339.0447, delta_loss = 681.94589 learning_Rate = 0.01000 rmse=1.48399 mae=1.19139\n","\u003cclass '__main__.SocialReg'\u003e iteration 8: loss = 7769.6508, delta_loss = 569.39390 learning_Rate = 0.01000 rmse=1.44034 mae=1.15244\n","\u003cclass '__main__.SocialReg'\u003e iteration 9: loss = 7283.6287, delta_loss = 486.02216 learning_Rate = 0.01000 rmse=1.40454 mae=1.12057\n","\u003cclass '__main__.SocialReg'\u003e iteration 10: loss = 6861.7708, delta_loss = 421.85783 learning_Rate = 0.01000 rmse=1.37462 mae=1.09401\n","\u003cclass '__main__.SocialReg'\u003e iteration 11: loss = 6490.7470, delta_loss = 371.02387 learning_Rate = 0.01000 rmse=1.34947 mae=1.07156\n","\u003cclass '__main__.SocialReg'\u003e iteration 12: loss = 6160.9145, delta_loss = 329.83248 learning_Rate = 0.01000 rmse=1.32823 mae=1.05260\n","\u003cclass '__main__.SocialReg'\u003e iteration 13: loss = 5865.0689, delta_loss = 295.84558 learning_Rate = 0.01000 rmse=1.31011 mae=1.03644\n","\u003cclass '__main__.SocialReg'\u003e iteration 14: loss = 5597.6873, delta_loss = 267.38164 learning_Rate = 0.01000 rmse=1.29435 mae=1.02239\n","\u003cclass '__main__.SocialReg'\u003e iteration 15: loss = 5354.4465, delta_loss = 243.24080 learning_Rate = 0.01000 rmse=1.28054 mae=1.01015\n","\u003cclass '__main__.SocialReg'\u003e iteration 16: loss = 5131.9033, delta_loss = 222.54320 learning_Rate = 0.01000 rmse=1.26836 mae=0.99927\n","\u003cclass '__main__.SocialReg'\u003e iteration 17: loss = 4927.2743, delta_loss = 204.62892 learning_Rate = 0.01000 rmse=1.25763 mae=0.98964\n","\u003cclass '__main__.SocialReg'\u003e iteration 18: loss = 4738.2807, delta_loss = 188.99365 learning_Rate = 0.01000 rmse=1.24807 mae=0.98101\n","\u003cclass '__main__.SocialReg'\u003e iteration 19: loss = 4563.0349, delta_loss = 175.24575 learning_Rate = 0.01000 rmse=1.23953 mae=0.97319\n","\u003cclass '__main__.SocialReg'\u003e iteration 20: loss = 4399.9581, delta_loss = 163.07681 learning_Rate = 0.01000 rmse=1.23186 mae=0.96613\n","\u003cclass '__main__.SocialReg'\u003e iteration 21: loss = 4247.7172, delta_loss = 152.24097 learning_Rate = 0.01000 rmse=1.22495 mae=0.95978\n","\u003cclass '__main__.SocialReg'\u003e iteration 22: loss = 4105.1771, delta_loss = 142.54005 learning_Rate = 0.01000 rmse=1.21866 mae=0.95399\n","\u003cclass '__main__.SocialReg'\u003e iteration 23: loss = 3971.3644, delta_loss = 133.81268 learning_Rate = 0.01000 rmse=1.21293 mae=0.94865\n","\u003cclass '__main__.SocialReg'\u003e iteration 24: loss = 3845.4382, delta_loss = 125.92627 learning_Rate = 0.01000 rmse=1.20767 mae=0.94372\n","\u003cclass '__main__.SocialReg'\u003e iteration 25: loss = 3726.6672, delta_loss = 118.77094 learning_Rate = 0.01000 rmse=1.20285 mae=0.93914\n","\u003cclass '__main__.SocialReg'\u003e iteration 26: loss = 3614.4124, delta_loss = 112.25488 learning_Rate = 0.01000 rmse=1.19841 mae=0.93492\n","\u003cclass '__main__.SocialReg'\u003e iteration 27: loss = 3508.1116, delta_loss = 106.30080 learning_Rate = 0.01000 rmse=1.19432 mae=0.93101\n","\u003cclass '__main__.SocialReg'\u003e iteration 28: loss = 3407.2683, delta_loss = 100.84320 learning_Rate = 0.01000 rmse=1.19053 mae=0.92738\n","\u003cclass '__main__.SocialReg'\u003e iteration 29: loss = 3311.4422, delta_loss = 95.82615 learning_Rate = 0.01000 rmse=1.18702 mae=0.92399\n","\u003cclass '__main__.SocialReg'\u003e iteration 30: loss = 3220.2406, delta_loss = 91.20160 learning_Rate = 0.01000 rmse=1.18373 mae=0.92081\n","\u003cclass '__main__.SocialReg'\u003e iteration 31: loss = 3133.3126, delta_loss = 86.92803 learning_Rate = 0.01000 rmse=1.18066 mae=0.91783\n","\u003cclass '__main__.SocialReg'\u003e iteration 32: loss = 3050.3432, delta_loss = 82.96933 learning_Rate = 0.01000 rmse=1.17779 mae=0.91505\n","\u003cclass '__main__.SocialReg'\u003e iteration 33: loss = 2971.0493, delta_loss = 79.29396 learning_Rate = 0.01000 rmse=1.17510 mae=0.91244\n","\u003cclass '__main__.SocialReg'\u003e iteration 34: loss = 2895.1751, delta_loss = 75.87420 learning_Rate = 0.01000 rmse=1.17260 mae=0.91001\n","\u003cclass '__main__.SocialReg'\u003e iteration 35: loss = 2822.4895, delta_loss = 72.68559 learning_Rate = 0.01000 rmse=1.17024 mae=0.90770\n","\u003cclass '__main__.SocialReg'\u003e iteration 36: loss = 2752.7830, delta_loss = 69.70646 learning_Rate = 0.01000 rmse=1.16799 mae=0.90551\n","\u003cclass '__main__.SocialReg'\u003e iteration 37: loss = 2685.8655, delta_loss = 66.91752 learning_Rate = 0.01000 rmse=1.16588 mae=0.90346\n","\u003cclass '__main__.SocialReg'\u003e iteration 38: loss = 2621.5639, delta_loss = 64.30156 learning_Rate = 0.01000 rmse=1.16390 mae=0.90154\n","\u003cclass '__main__.SocialReg'\u003e iteration 39: loss = 2559.7207, delta_loss = 61.84320 learning_Rate = 0.01000 rmse=1.16204 mae=0.89973\n","\u003cclass '__main__.SocialReg'\u003e iteration 40: loss = 2500.1921, delta_loss = 59.52862 learning_Rate = 0.01000 rmse=1.16026 mae=0.89803\n","\u003cclass '__main__.SocialReg'\u003e iteration 41: loss = 2442.8467, delta_loss = 57.34542 learning_Rate = 0.01000 rmse=1.15858 mae=0.89642\n","\u003cclass '__main__.SocialReg'\u003e iteration 42: loss = 2387.5643, delta_loss = 55.28243 learning_Rate = 0.01000 rmse=1.15699 mae=0.89489\n","\u003cclass '__main__.SocialReg'\u003e iteration 43: loss = 2334.2347, delta_loss = 53.32962 learning_Rate = 0.01000 rmse=1.15547 mae=0.89343\n","\u003cclass '__main__.SocialReg'\u003e iteration 44: loss = 2282.7567, delta_loss = 51.47795 learning_Rate = 0.01000 rmse=1.15404 mae=0.89206\n","\u003cclass '__main__.SocialReg'\u003e iteration 45: loss = 2233.0374, delta_loss = 49.71929 learning_Rate = 0.01000 rmse=1.15268 mae=0.89075\n","\u003cclass '__main__.SocialReg'\u003e iteration 46: loss = 2184.9911, delta_loss = 48.04631 learning_Rate = 0.01000 rmse=1.15140 mae=0.88952\n","\u003cclass '__main__.SocialReg'\u003e iteration 47: loss = 2138.5387, delta_loss = 46.45244 learning_Rate = 0.01000 rmse=1.15020 mae=0.88837\n","\u003cclass '__main__.SocialReg'\u003e iteration 48: loss = 2093.6069, delta_loss = 44.93179 learning_Rate = 0.01000 rmse=1.14905 mae=0.88727\n","\u003cclass '__main__.SocialReg'\u003e iteration 49: loss = 2050.1278, delta_loss = 43.47904 learning_Rate = 0.01000 rmse=1.14798 mae=0.88623\n","\u003cclass '__main__.SocialReg'\u003e iteration 50: loss = 2008.0384, delta_loss = 42.08947 learning_Rate = 0.01000 rmse=1.14697 mae=0.88526\n","\u003cclass '__main__.SocialReg'\u003e iteration 51: loss = 1967.2796, delta_loss = 40.75880 learning_Rate = 0.01000 rmse=1.14601 mae=0.88433\n","\u003cclass '__main__.SocialReg'\u003e iteration 52: loss = 1927.7963, delta_loss = 39.48324 learning_Rate = 0.01000 rmse=1.14511 mae=0.88346\n","\u003cclass '__main__.SocialReg'\u003e iteration 53: loss = 1889.5370, delta_loss = 38.25936 learning_Rate = 0.01000 rmse=1.14426 mae=0.88264\n","\u003cclass '__main__.SocialReg'\u003e iteration 54: loss = 1852.4529, delta_loss = 37.08410 learning_Rate = 0.01000 rmse=1.14347 mae=0.88187\n","\u003cclass '__main__.SocialReg'\u003e iteration 55: loss = 1816.4982, delta_loss = 35.95469 learning_Rate = 0.01000 rmse=1.14274 mae=0.88116\n","\u003cclass '__main__.SocialReg'\u003e iteration 56: loss = 1781.6295, delta_loss = 34.86864 learning_Rate = 0.01000 rmse=1.14202 mae=0.88046\n","\u003cclass '__main__.SocialReg'\u003e iteration 57: loss = 1747.8059, delta_loss = 33.82368 learning_Rate = 0.01000 rmse=1.14137 mae=0.87982\n","\u003cclass '__main__.SocialReg'\u003e iteration 58: loss = 1714.9881, delta_loss = 32.81776 learning_Rate = 0.01000 rmse=1.14074 mae=0.87921\n","\u003cclass '__main__.SocialReg'\u003e iteration 59: loss = 1683.1391, delta_loss = 31.84898 learning_Rate = 0.01000 rmse=1.14016 mae=0.87865\n","\u003cclass '__main__.SocialReg'\u003e iteration 60: loss = 1652.2235, delta_loss = 30.91560 learning_Rate = 0.01000 rmse=1.13962 mae=0.87812\n","\u003cclass '__main__.SocialReg'\u003e iteration 61: loss = 1622.2075, delta_loss = 30.01600 learning_Rate = 0.01000 rmse=1.13911 mae=0.87762\n","\u003cclass '__main__.SocialReg'\u003e iteration 62: loss = 1593.0588, delta_loss = 29.14867 learning_Rate = 0.01000 rmse=1.13864 mae=0.87716\n","\u003cclass '__main__.SocialReg'\u003e iteration 63: loss = 1564.7466, delta_loss = 28.31220 learning_Rate = 0.01000 rmse=1.13821 mae=0.87673\n","\u003cclass '__main__.SocialReg'\u003e iteration 64: loss = 1537.2414, delta_loss = 27.50525 learning_Rate = 0.01000 rmse=1.13780 mae=0.87632\n","\u003cclass '__main__.SocialReg'\u003e iteration 65: loss = 1510.5148, delta_loss = 26.72656 learning_Rate = 0.01000 rmse=1.13742 mae=0.87593\n","\u003cclass '__main__.SocialReg'\u003e iteration 66: loss = 1484.5399, delta_loss = 25.97495 learning_Rate = 0.01000 rmse=1.13707 mae=0.87557\n","\u003cclass '__main__.SocialReg'\u003e iteration 67: loss = 1459.2906, delta_loss = 25.24926 learning_Rate = 0.01000 rmse=1.13675 mae=0.87523\n","\u003cclass '__main__.SocialReg'\u003e iteration 68: loss = 1434.7422, delta_loss = 24.54842 learning_Rate = 0.01000 rmse=1.13646 mae=0.87492\n","\u003cclass '__main__.SocialReg'\u003e iteration 69: loss = 1410.8708, delta_loss = 23.87141 learning_Rate = 0.01000 rmse=1.13620 mae=0.87463\n","\u003cclass '__main__.SocialReg'\u003e iteration 70: loss = 1387.6536, delta_loss = 23.21723 learning_Rate = 0.01000 rmse=1.13597 mae=0.87437\n","\u003cclass '__main__.SocialReg'\u003e iteration 71: loss = 1365.0686, delta_loss = 22.58495 learning_Rate = 0.01000 rmse=1.13576 mae=0.87413\n","\u003cclass '__main__.SocialReg'\u003e iteration 72: loss = 1343.0949, delta_loss = 21.97368 learning_Rate = 0.01000 rmse=1.13558 mae=0.87392\n","\u003cclass '__main__.SocialReg'\u003e iteration 73: loss = 1321.7124, delta_loss = 21.38257 learning_Rate = 0.01000 rmse=1.13542 mae=0.87372\n","\u003cclass '__main__.SocialReg'\u003e iteration 74: loss = 1300.9016, delta_loss = 20.81082 learning_Rate = 0.01000 rmse=1.13528 mae=0.87356\n","\u003cclass '__main__.SocialReg'\u003e iteration 75: loss = 1280.6439, delta_loss = 20.25765 learning_Rate = 0.01000 rmse=1.13516 mae=0.87341\n","\u003cclass '__main__.SocialReg'\u003e iteration 76: loss = 1260.9216, delta_loss = 19.72233 learning_Rate = 0.01000 rmse=1.13505 mae=0.87327\n","\u003cclass '__main__.SocialReg'\u003e iteration 77: loss = 1241.7174, delta_loss = 19.20418 learning_Rate = 0.01000 rmse=1.13496 mae=0.87315\n","\u003cclass '__main__.SocialReg'\u003e iteration 78: loss = 1223.0149, delta_loss = 18.70252 learning_Rate = 0.01000 rmse=1.13489 mae=0.87304\n","\u003cclass '__main__.SocialReg'\u003e iteration 79: loss = 1204.7981, delta_loss = 18.21674 learning_Rate = 0.01000 rmse=1.13483 mae=0.87294\n","\u003cclass '__main__.SocialReg'\u003e iteration 80: loss = 1187.0519, delta_loss = 17.74624 learning_Rate = 0.01000 rmse=1.13479 mae=0.87286\n","\u003cclass '__main__.SocialReg'\u003e iteration 81: loss = 1169.7615, delta_loss = 17.29045 learning_Rate = 0.01000 rmse=1.13476 mae=0.87279\n","\u003cclass '__main__.SocialReg'\u003e iteration 82: loss = 1152.9126, delta_loss = 16.84884 learning_Rate = 0.01000 rmse=1.13476 mae=0.87273\n","\u003cclass '__main__.SocialReg'\u003e iteration 83: loss = 1136.4917, delta_loss = 16.42089 learning_Rate = 0.01000 rmse=1.13477 mae=0.87268\n","\u003cclass '__main__.SocialReg'\u003e iteration 84: loss = 1120.4856, delta_loss = 16.00611 learning_Rate = 0.01000 rmse=1.13479 mae=0.87265\n","\u003cclass '__main__.SocialReg'\u003e iteration 85: loss = 1104.8816, delta_loss = 15.60405 learning_Rate = 0.01000 rmse=1.13481 mae=0.87261\n","\u003cclass '__main__.SocialReg'\u003e iteration 86: loss = 1089.6673, delta_loss = 15.21426 learning_Rate = 0.01000 rmse=1.13484 mae=0.87258\n","\u003cclass '__main__.SocialReg'\u003e iteration 87: loss = 1074.8310, delta_loss = 14.83631 learning_Rate = 0.01000 rmse=1.13489 mae=0.87256\n","\u003cclass '__main__.SocialReg'\u003e iteration 88: loss = 1060.3612, delta_loss = 14.46981 learning_Rate = 0.01000 rmse=1.13494 mae=0.87254\n","\u003cclass '__main__.SocialReg'\u003e iteration 89: loss = 1046.2468, delta_loss = 14.11436 learning_Rate = 0.01000 rmse=1.13500 mae=0.87254\n","\u003cclass '__main__.SocialReg'\u003e iteration 90: loss = 1032.4772, delta_loss = 13.76960 learning_Rate = 0.01000 rmse=1.13504 mae=0.87252\n","\u003cclass '__main__.SocialReg'\u003e iteration 91: loss = 1019.0420, delta_loss = 13.43518 learning_Rate = 0.01000 rmse=1.13511 mae=0.87252\n","\u003cclass '__main__.SocialReg'\u003e iteration 92: loss = 1005.9313, delta_loss = 13.11075 learning_Rate = 0.01000 rmse=1.13518 mae=0.87252\n","\u003cclass '__main__.SocialReg'\u003e iteration 93: loss = 993.1353, delta_loss = 12.79598 learning_Rate = 0.01000 rmse=1.13527 mae=0.87253\n","\u003cclass '__main__.SocialReg'\u003e iteration 94: loss = 980.6448, delta_loss = 12.49056 learning_Rate = 0.01000 rmse=1.13537 mae=0.87255\n","\u003cclass '__main__.SocialReg'\u003e iteration 95: loss = 968.4506, delta_loss = 12.19420 learning_Rate = 0.01000 rmse=1.13547 mae=0.87257\n","\u003cclass '__main__.SocialReg'\u003e iteration 96: loss = 956.5440, delta_loss = 11.90659 learning_Rate = 0.01000 rmse=1.13558 mae=0.87260\n","\u003cclass '__main__.SocialReg'\u003e iteration 97: loss = 944.9165, delta_loss = 11.62745 learning_Rate = 0.01000 rmse=1.13570 mae=0.87264\n","\u003cclass '__main__.SocialReg'\u003e iteration 98: loss = 933.5600, delta_loss = 11.35653 learning_Rate = 0.01000 rmse=1.13582 mae=0.87268\n","\u003cclass '__main__.SocialReg'\u003e iteration 99: loss = 922.4665, delta_loss = 11.09354 learning_Rate = 0.01000 rmse=1.13596 mae=0.87273\n","\u003cclass '__main__.SocialReg'\u003e iteration 100: loss = 911.6282, delta_loss = 10.83824 learning_Rate = 0.01000 rmse=1.13610 mae=0.87279\n","the 2th cross validation training\n","constructing user-user similarity matrix...\n","\u003cclass '__main__.SocialReg'\u003e iteration 1: loss = 18343.6493, delta_loss = -18343.64933 learning_Rate = 0.01000 rmse=2.23843 mae=1.93092\n","\u003cclass '__main__.SocialReg'\u003e iteration 2: loss = 14602.4643, delta_loss = 3741.18499 learning_Rate = 0.01000 rmse=1.97298 mae=1.66677\n","\u003cclass '__main__.SocialReg'\u003e iteration 3: loss = 12386.4335, delta_loss = 2216.03080 learning_Rate = 0.01000 rmse=1.79575 mae=1.49595\n","\u003cclass '__main__.SocialReg'\u003e iteration 4: loss = 10908.9431, delta_loss = 1477.49045 learning_Rate = 0.01000 rmse=1.67172 mae=1.37881\n","\u003cclass '__main__.SocialReg'\u003e iteration 5: loss = 9832.0565, delta_loss = 1076.88663 learning_Rate = 0.01000 rmse=1.58009 mae=1.29431\n","\u003cclass '__main__.SocialReg'\u003e iteration 6: loss = 8994.9529, delta_loss = 837.10361 learning_Rate = 0.01000 rmse=1.51009 mae=1.23084\n","\u003cclass '__main__.SocialReg'\u003e iteration 7: loss = 8315.7967, delta_loss = 679.15616 learning_Rate = 0.01000 rmse=1.45495 mae=1.18133\n","\u003cclass '__main__.SocialReg'\u003e iteration 8: loss = 7748.3115, delta_loss = 567.48523 learning_Rate = 0.01000 rmse=1.41032 mae=1.14159\n","\u003cclass '__main__.SocialReg'\u003e iteration 9: loss = 7263.8451, delta_loss = 484.46641 learning_Rate = 0.01000 rmse=1.37373 mae=1.10902\n","\u003cclass '__main__.SocialReg'\u003e iteration 10: loss = 6843.4161, delta_loss = 420.42895 learning_Rate = 0.01000 rmse=1.34349 mae=1.08229\n","\u003cclass '__main__.SocialReg'\u003e iteration 11: loss = 6473.7929, delta_loss = 369.62324 learning_Rate = 0.01000 rmse=1.31815 mae=1.05993\n","\u003cclass '__main__.SocialReg'\u003e iteration 12: loss = 6145.3775, delta_loss = 328.41535 learning_Rate = 0.01000 rmse=1.29673 mae=1.04122\n","\u003cclass '__main__.SocialReg'\u003e iteration 13: loss = 5850.9832, delta_loss = 294.39428 learning_Rate = 0.01000 rmse=1.27841 mae=1.02536\n","\u003cclass '__main__.SocialReg'\u003e iteration 14: loss = 5585.0882, delta_loss = 265.89506 learning_Rate = 0.01000 rmse=1.26261 mae=1.01179\n","\u003cclass '__main__.SocialReg'\u003e iteration 15: loss = 5343.3597, delta_loss = 241.72850 learning_Rate = 0.01000 rmse=1.24884 mae=0.99986\n","\u003cclass '__main__.SocialReg'\u003e iteration 16: loss = 5122.3387, delta_loss = 221.02093 learning_Rate = 0.01000 rmse=1.23675 mae=0.98936\n","\u003cclass '__main__.SocialReg'\u003e iteration 17: loss = 4919.2236, delta_loss = 203.11511 learning_Rate = 0.01000 rmse=1.22611 mae=0.98017\n","\u003cclass '__main__.SocialReg'\u003e iteration 18: loss = 4731.7168, delta_loss = 187.50684 learning_Rate = 0.01000 rmse=1.21665 mae=0.97192\n","\u003cclass '__main__.SocialReg'\u003e iteration 19: loss = 4557.9138, delta_loss = 173.80303 learning_Rate = 0.01000 rmse=1.20818 mae=0.96448\n","\u003cclass '__main__.SocialReg'\u003e iteration 20: loss = 4396.2208, delta_loss = 161.69296 learning_Rate = 0.01000 rmse=1.20053 mae=0.95776\n","\u003cclass '__main__.SocialReg'\u003e iteration 21: loss = 4245.2927, delta_loss = 150.92816 learning_Rate = 0.01000 rmse=1.19360 mae=0.95164\n","\u003cclass '__main__.SocialReg'\u003e iteration 22: loss = 4103.9848, delta_loss = 141.30787 learning_Rate = 0.01000 rmse=1.18729 mae=0.94605\n","\u003cclass '__main__.SocialReg'\u003e iteration 23: loss = 3971.3164, delta_loss = 132.66838 learning_Rate = 0.01000 rmse=1.18153 mae=0.94098\n","\u003cclass '__main__.SocialReg'\u003e iteration 24: loss = 3846.4414, delta_loss = 124.87502 learning_Rate = 0.01000 rmse=1.17622 mae=0.93629\n","\u003cclass '__main__.SocialReg'\u003e iteration 25: loss = 3728.6253, delta_loss = 117.81610 learning_Rate = 0.01000 rmse=1.17132 mae=0.93194\n","\u003cclass '__main__.SocialReg'\u003e iteration 26: loss = 3617.2270, delta_loss = 111.39827 learning_Rate = 0.01000 rmse=1.16681 mae=0.92793\n","\u003cclass '__main__.SocialReg'\u003e iteration 27: loss = 3511.6841, delta_loss = 105.54290 learning_Rate = 0.01000 rmse=1.16262 mae=0.92421\n","\u003cclass '__main__.SocialReg'\u003e iteration 28: loss = 3411.5008, delta_loss = 100.18331 learning_Rate = 0.01000 rmse=1.15872 mae=0.92074\n","\u003cclass '__main__.SocialReg'\u003e iteration 29: loss = 3316.2383, delta_loss = 95.26250 learning_Rate = 0.01000 rmse=1.15509 mae=0.91748\n","\u003cclass '__main__.SocialReg'\u003e iteration 30: loss = 3225.5068, delta_loss = 90.73149 learning_Rate = 0.01000 rmse=1.15171 mae=0.91444\n","\u003cclass '__main__.SocialReg'\u003e iteration 31: loss = 3138.9590, delta_loss = 86.54786 learning_Rate = 0.01000 rmse=1.14854 mae=0.91160\n","\u003cclass '__main__.SocialReg'\u003e iteration 32: loss = 3056.2842, delta_loss = 82.67472 learning_Rate = 0.01000 rmse=1.14557 mae=0.90892\n","\u003cclass '__main__.SocialReg'\u003e iteration 33: loss = 2977.2045, delta_loss = 79.07976 learning_Rate = 0.01000 rmse=1.14278 mae=0.90640\n","\u003cclass '__main__.SocialReg'\u003e iteration 34: loss = 2901.4699, delta_loss = 75.73461 learning_Rate = 0.01000 rmse=1.14015 mae=0.90402\n","\u003cclass '__main__.SocialReg'\u003e iteration 35: loss = 2828.8556, delta_loss = 72.61425 learning_Rate = 0.01000 rmse=1.13768 mae=0.90178\n","\u003cclass '__main__.SocialReg'\u003e iteration 36: loss = 2759.1591, delta_loss = 69.69650 learning_Rate = 0.01000 rmse=1.13534 mae=0.89966\n","\u003cclass '__main__.SocialReg'\u003e iteration 37: loss = 2692.1974, delta_loss = 66.96174 learning_Rate = 0.01000 rmse=1.13315 mae=0.89767\n","\u003cclass '__main__.SocialReg'\u003e iteration 38: loss = 2627.8049, delta_loss = 64.39250 learning_Rate = 0.01000 rmse=1.13108 mae=0.89578\n","\u003cclass '__main__.SocialReg'\u003e iteration 39: loss = 2565.8316, delta_loss = 61.97328 learning_Rate = 0.01000 rmse=1.12911 mae=0.89399\n","\u003cclass '__main__.SocialReg'\u003e iteration 40: loss = 2506.1413, delta_loss = 59.69029 learning_Rate = 0.01000 rmse=1.12722 mae=0.89228\n","\u003cclass '__main__.SocialReg'\u003e iteration 41: loss = 2448.6100, delta_loss = 57.53128 learning_Rate = 0.01000 rmse=1.12545 mae=0.89067\n","\u003cclass '__main__.SocialReg'\u003e iteration 42: loss = 2393.1246, delta_loss = 55.48539 learning_Rate = 0.01000 rmse=1.12376 mae=0.88912\n","\u003cclass '__main__.SocialReg'\u003e iteration 43: loss = 2339.5817, delta_loss = 53.54298 learning_Rate = 0.01000 rmse=1.12216 mae=0.88767\n","\u003cclass '__main__.SocialReg'\u003e iteration 44: loss = 2287.8861, delta_loss = 51.69552 learning_Rate = 0.01000 rmse=1.12065 mae=0.88630\n","\u003cclass '__main__.SocialReg'\u003e iteration 45: loss = 2237.9507, delta_loss = 49.93548 learning_Rate = 0.01000 rmse=1.11922 mae=0.88502\n","\u003cclass '__main__.SocialReg'\u003e iteration 46: loss = 2189.6945, delta_loss = 48.25620 learning_Rate = 0.01000 rmse=1.11786 mae=0.88381\n","\u003cclass '__main__.SocialReg'\u003e iteration 47: loss = 2143.0427, delta_loss = 46.65181 learning_Rate = 0.01000 rmse=1.11657 mae=0.88265\n","\u003cclass '__main__.SocialReg'\u003e iteration 48: loss = 2097.9255, delta_loss = 45.11712 learning_Rate = 0.01000 rmse=1.11537 mae=0.88156\n","\u003cclass '__main__.SocialReg'\u003e iteration 49: loss = 2054.2780, delta_loss = 43.64755 learning_Rate = 0.01000 rmse=1.11423 mae=0.88055\n","\u003cclass '__main__.SocialReg'\u003e iteration 50: loss = 2012.0390, delta_loss = 42.23901 learning_Rate = 0.01000 rmse=1.11316 mae=0.87958\n","\u003cclass '__main__.SocialReg'\u003e iteration 51: loss = 1971.1511, delta_loss = 40.88790 learning_Rate = 0.01000 rmse=1.11215 mae=0.87865\n","\u003cclass '__main__.SocialReg'\u003e iteration 52: loss = 1931.5601, delta_loss = 39.59097 learning_Rate = 0.01000 rmse=1.11118 mae=0.87776\n","\u003cclass '__main__.SocialReg'\u003e iteration 53: loss = 1893.2148, delta_loss = 38.34531 learning_Rate = 0.01000 rmse=1.11027 mae=0.87691\n","\u003cclass '__main__.SocialReg'\u003e iteration 54: loss = 1856.0665, delta_loss = 37.14828 learning_Rate = 0.01000 rmse=1.10942 mae=0.87611\n","\u003cclass '__main__.SocialReg'\u003e iteration 55: loss = 1820.0690, delta_loss = 35.99747 learning_Rate = 0.01000 rmse=1.10861 mae=0.87534\n","\u003cclass '__main__.SocialReg'\u003e iteration 56: loss = 1785.1784, delta_loss = 34.89067 learning_Rate = 0.01000 rmse=1.10787 mae=0.87462\n","\u003cclass '__main__.SocialReg'\u003e iteration 57: loss = 1751.3525, delta_loss = 33.82584 learning_Rate = 0.01000 rmse=1.10716 mae=0.87394\n","\u003cclass '__main__.SocialReg'\u003e iteration 58: loss = 1718.5515, delta_loss = 32.80107 learning_Rate = 0.01000 rmse=1.10648 mae=0.87330\n","\u003cclass '__main__.SocialReg'\u003e iteration 59: loss = 1686.7369, delta_loss = 31.81458 learning_Rate = 0.01000 rmse=1.10584 mae=0.87269\n","\u003cclass '__main__.SocialReg'\u003e iteration 60: loss = 1655.8722, delta_loss = 30.86469 learning_Rate = 0.01000 rmse=1.10524 mae=0.87211\n","\u003cclass '__main__.SocialReg'\u003e iteration 61: loss = 1625.9224, delta_loss = 29.94981 learning_Rate = 0.01000 rmse=1.10466 mae=0.87154\n","\u003cclass '__main__.SocialReg'\u003e iteration 62: loss = 1596.8539, delta_loss = 29.06844 learning_Rate = 0.01000 rmse=1.10413 mae=0.87101\n","\u003cclass '__main__.SocialReg'\u003e iteration 63: loss = 1568.6348, delta_loss = 28.21915 learning_Rate = 0.01000 rmse=1.10364 mae=0.87051\n","\u003cclass '__main__.SocialReg'\u003e iteration 64: loss = 1541.2342, delta_loss = 27.40058 learning_Rate = 0.01000 rmse=1.10317 mae=0.87003\n","\u003cclass '__main__.SocialReg'\u003e iteration 65: loss = 1514.6228, delta_loss = 26.61144 learning_Rate = 0.01000 rmse=1.10275 mae=0.86961\n","\u003cclass '__main__.SocialReg'\u003e iteration 66: loss = 1488.7723, delta_loss = 25.85048 learning_Rate = 0.01000 rmse=1.10235 mae=0.86920\n","\u003cclass '__main__.SocialReg'\u003e iteration 67: loss = 1463.6558, delta_loss = 25.11653 learning_Rate = 0.01000 rmse=1.10196 mae=0.86881\n","\u003cclass '__main__.SocialReg'\u003e iteration 68: loss = 1439.2473, delta_loss = 24.40846 learning_Rate = 0.01000 rmse=1.10161 mae=0.86844\n","\u003cclass '__main__.SocialReg'\u003e iteration 69: loss = 1415.5221, delta_loss = 23.72520 learning_Rate = 0.01000 rmse=1.10127 mae=0.86810\n","\u003cclass '__main__.SocialReg'\u003e iteration 70: loss = 1392.4564, delta_loss = 23.06573 learning_Rate = 0.01000 rmse=1.10095 mae=0.86778\n","\u003cclass '__main__.SocialReg'\u003e iteration 71: loss = 1370.0273, delta_loss = 22.42907 learning_Rate = 0.01000 rmse=1.10067 mae=0.86748\n","\u003cclass '__main__.SocialReg'\u003e iteration 72: loss = 1348.2130, delta_loss = 21.81430 learning_Rate = 0.01000 rmse=1.10042 mae=0.86721\n","\u003cclass '__main__.SocialReg'\u003e iteration 73: loss = 1326.9925, delta_loss = 21.22052 learning_Rate = 0.01000 rmse=1.10019 mae=0.86694\n","\u003cclass '__main__.SocialReg'\u003e iteration 74: loss = 1306.3456, delta_loss = 20.64690 learning_Rate = 0.01000 rmse=1.10000 mae=0.86670\n","\u003cclass '__main__.SocialReg'\u003e iteration 75: loss = 1286.2530, delta_loss = 20.09263 learning_Rate = 0.01000 rmse=1.09982 mae=0.86647\n","\u003cclass '__main__.SocialReg'\u003e iteration 76: loss = 1266.6960, delta_loss = 19.55695 learning_Rate = 0.01000 rmse=1.09966 mae=0.86626\n","\u003cclass '__main__.SocialReg'\u003e iteration 77: loss = 1247.6569, delta_loss = 19.03913 learning_Rate = 0.01000 rmse=1.09950 mae=0.86606\n","\u003cclass '__main__.SocialReg'\u003e iteration 78: loss = 1229.1184, delta_loss = 18.53847 learning_Rate = 0.01000 rmse=1.09937 mae=0.86587\n","\u003cclass '__main__.SocialReg'\u003e iteration 79: loss = 1211.0641, delta_loss = 18.05430 learning_Rate = 0.01000 rmse=1.09926 mae=0.86571\n","\u003cclass '__main__.SocialReg'\u003e iteration 80: loss = 1193.4781, delta_loss = 17.58601 learning_Rate = 0.01000 rmse=1.09916 mae=0.86555\n","\u003cclass '__main__.SocialReg'\u003e iteration 81: loss = 1176.3451, delta_loss = 17.13298 learning_Rate = 0.01000 rmse=1.09910 mae=0.86541\n","\u003cclass '__main__.SocialReg'\u003e iteration 82: loss = 1159.6505, delta_loss = 16.69463 learning_Rate = 0.01000 rmse=1.09903 mae=0.86527\n","\u003cclass '__main__.SocialReg'\u003e iteration 83: loss = 1143.3801, delta_loss = 16.27041 learning_Rate = 0.01000 rmse=1.09899 mae=0.86513\n","\u003cclass '__main__.SocialReg'\u003e iteration 84: loss = 1127.5203, delta_loss = 15.85980 learning_Rate = 0.01000 rmse=1.09896 mae=0.86501\n","\u003cclass '__main__.SocialReg'\u003e iteration 85: loss = 1112.0580, delta_loss = 15.46228 learning_Rate = 0.01000 rmse=1.09894 mae=0.86489\n","\u003cclass '__main__.SocialReg'\u003e iteration 86: loss = 1096.9807, delta_loss = 15.07738 learning_Rate = 0.01000 rmse=1.09894 mae=0.86478\n","\u003cclass '__main__.SocialReg'\u003e iteration 87: loss = 1082.2760, delta_loss = 14.70462 learning_Rate = 0.01000 rmse=1.09893 mae=0.86468\n","\u003cclass '__main__.SocialReg'\u003e iteration 88: loss = 1067.9325, delta_loss = 14.34357 learning_Rate = 0.01000 rmse=1.09893 mae=0.86459\n","\u003cclass '__main__.SocialReg'\u003e iteration 89: loss = 1053.9387, delta_loss = 13.99380 learning_Rate = 0.01000 rmse=1.09894 mae=0.86450\n","\u003cclass '__main__.SocialReg'\u003e iteration 90: loss = 1040.2838, delta_loss = 13.65489 learning_Rate = 0.01000 rmse=1.09895 mae=0.86441\n","\u003cclass '__main__.SocialReg'\u003e iteration 91: loss = 1026.9573, delta_loss = 13.32646 learning_Rate = 0.01000 rmse=1.09898 mae=0.86433\n","\u003cclass '__main__.SocialReg'\u003e iteration 92: loss = 1013.9492, delta_loss = 13.00812 learning_Rate = 0.01000 rmse=1.09902 mae=0.86428\n","\u003cclass '__main__.SocialReg'\u003e iteration 93: loss = 1001.2497, delta_loss = 12.69952 learning_Rate = 0.01000 rmse=1.09906 mae=0.86423\n","\u003cclass '__main__.SocialReg'\u003e iteration 94: loss = 988.8494, delta_loss = 12.40030 learning_Rate = 0.01000 rmse=1.09912 mae=0.86419\n","\u003cclass '__main__.SocialReg'\u003e iteration 95: loss = 976.7392, delta_loss = 12.11013 learning_Rate = 0.01000 rmse=1.09918 mae=0.86415\n","\u003cclass '__main__.SocialReg'\u003e iteration 96: loss = 964.9105, delta_loss = 11.82869 learning_Rate = 0.01000 rmse=1.09927 mae=0.86413\n","\u003cclass '__main__.SocialReg'\u003e iteration 97: loss = 953.3549, delta_loss = 11.55567 learning_Rate = 0.01000 rmse=1.09935 mae=0.86411\n","\u003cclass '__main__.SocialReg'\u003e iteration 98: loss = 942.0641, delta_loss = 11.29077 learning_Rate = 0.01000 rmse=1.09944 mae=0.86410\n","\u003cclass '__main__.SocialReg'\u003e iteration 99: loss = 931.0304, delta_loss = 11.03372 learning_Rate = 0.01000 rmse=1.09955 mae=0.86409\n","\u003cclass '__main__.SocialReg'\u003e iteration 100: loss = 920.2462, delta_loss = 10.78423 learning_Rate = 0.01000 rmse=1.09965 mae=0.86408\n","the 3th cross validation training\n","constructing user-user similarity matrix...\n","\u003cclass '__main__.SocialReg'\u003e iteration 1: loss = 18468.6942, delta_loss = -18468.69420 learning_Rate = 0.01000 rmse=2.25777 mae=1.94222\n","\u003cclass '__main__.SocialReg'\u003e iteration 2: loss = 14689.1551, delta_loss = 3779.53909 learning_Rate = 0.01000 rmse=1.99251 mae=1.67909\n","\u003cclass '__main__.SocialReg'\u003e iteration 3: loss = 12434.8803, delta_loss = 2254.27477 learning_Rate = 0.01000 rmse=1.81686 mae=1.50817\n","\u003cclass '__main__.SocialReg'\u003e iteration 4: loss = 10935.7315, delta_loss = 1499.14880 learning_Rate = 0.01000 rmse=1.69304 mae=1.38902\n","\u003cclass '__main__.SocialReg'\u003e iteration 5: loss = 9847.4645, delta_loss = 1088.26708 learning_Rate = 0.01000 rmse=1.60170 mae=1.30360\n","\u003cclass '__main__.SocialReg'\u003e iteration 6: loss = 9004.4400, delta_loss = 843.02442 learning_Rate = 0.01000 rmse=1.53167 mae=1.24002\n","\u003cclass '__main__.SocialReg'\u003e iteration 7: loss = 8321.7070, delta_loss = 682.73304 learning_Rate = 0.01000 rmse=1.47637 mae=1.19044\n","\u003cclass '__main__.SocialReg'\u003e iteration 8: loss = 7751.4578, delta_loss = 570.24915 learning_Rate = 0.01000 rmse=1.43205 mae=1.15151\n","\u003cclass '__main__.SocialReg'\u003e iteration 9: loss = 7264.4841, delta_loss = 486.97370 learning_Rate = 0.01000 rmse=1.39580 mae=1.11963\n","\u003cclass '__main__.SocialReg'\u003e iteration 10: loss = 6841.6571, delta_loss = 422.82707 learning_Rate = 0.01000 rmse=1.36573 mae=1.09317\n","\u003cclass '__main__.SocialReg'\u003e iteration 11: loss = 6469.7233, delta_loss = 371.93378 learning_Rate = 0.01000 rmse=1.34054 mae=1.07103\n","\u003cclass '__main__.SocialReg'\u003e iteration 12: loss = 6139.0938, delta_loss = 330.62954 learning_Rate = 0.01000 rmse=1.31924 mae=1.05225\n","\u003cclass '__main__.SocialReg'\u003e iteration 13: loss = 5842.5979, delta_loss = 296.49587 learning_Rate = 0.01000 rmse=1.30107 mae=1.03603\n","\u003cclass '__main__.SocialReg'\u003e iteration 14: loss = 5574.7329, delta_loss = 267.86497 learning_Rate = 0.01000 rmse=1.28539 mae=1.02199\n","\u003cclass '__main__.SocialReg'\u003e iteration 15: loss = 5331.1855, delta_loss = 243.54738 learning_Rate = 0.01000 rmse=1.27184 mae=1.00990\n","\u003cclass '__main__.SocialReg'\u003e iteration 16: loss = 5108.5139, delta_loss = 222.67166 learning_Rate = 0.01000 rmse=1.25997 mae=0.99932\n","\u003cclass '__main__.SocialReg'\u003e iteration 17: loss = 4903.9292, delta_loss = 204.58470 learning_Rate = 0.01000 rmse=1.24942 mae=0.98984\n","\u003cclass '__main__.SocialReg'\u003e iteration 18: loss = 4715.1418, delta_loss = 188.78737 learning_Rate = 0.01000 rmse=1.24003 mae=0.98135\n","\u003cclass '__main__.SocialReg'\u003e iteration 19: loss = 4540.2502, delta_loss = 174.89163 learning_Rate = 0.01000 rmse=1.23161 mae=0.97374\n","\u003cclass '__main__.SocialReg'\u003e iteration 20: loss = 4377.6589, delta_loss = 162.59123 learning_Rate = 0.01000 rmse=1.22403 mae=0.96690\n","\u003cclass '__main__.SocialReg'\u003e iteration 21: loss = 4226.0177, delta_loss = 151.64126 learning_Rate = 0.01000 rmse=1.21715 mae=0.96066\n","\u003cclass '__main__.SocialReg'\u003e iteration 22: loss = 4084.1741, delta_loss = 141.84363 learning_Rate = 0.01000 rmse=1.21092 mae=0.95496\n","\u003cclass '__main__.SocialReg'\u003e iteration 23: loss = 3951.1377, delta_loss = 133.03640 learning_Rate = 0.01000 rmse=1.20522 mae=0.94971\n","\u003cclass '__main__.SocialReg'\u003e iteration 24: loss = 3826.0517, delta_loss = 125.08599 learning_Rate = 0.01000 rmse=1.19998 mae=0.94486\n","\u003cclass '__main__.SocialReg'\u003e iteration 25: loss = 3708.1704, delta_loss = 117.88124 learning_Rate = 0.01000 rmse=1.19519 mae=0.94040\n","\u003cclass '__main__.SocialReg'\u003e iteration 26: loss = 3596.8415, delta_loss = 111.32892 learning_Rate = 0.01000 rmse=1.19081 mae=0.93634\n","\u003cclass '__main__.SocialReg'\u003e iteration 27: loss = 3491.4912, delta_loss = 105.35029 learning_Rate = 0.01000 rmse=1.18676 mae=0.93257\n","\u003cclass '__main__.SocialReg'\u003e iteration 28: loss = 3391.6129, delta_loss = 99.87836 learning_Rate = 0.01000 rmse=1.18302 mae=0.92911\n","\u003cclass '__main__.SocialReg'\u003e iteration 29: loss = 3296.7571, delta_loss = 94.85576 learning_Rate = 0.01000 rmse=1.17956 mae=0.92590\n","\u003cclass '__main__.SocialReg'\u003e iteration 30: loss = 3206.5240, delta_loss = 90.23312 learning_Rate = 0.01000 rmse=1.17633 mae=0.92287\n","\u003cclass '__main__.SocialReg'\u003e iteration 31: loss = 3120.5563, delta_loss = 85.96765 learning_Rate = 0.01000 rmse=1.17329 mae=0.92002\n","\u003cclass '__main__.SocialReg'\u003e iteration 32: loss = 3038.5342, delta_loss = 82.02212 learning_Rate = 0.01000 rmse=1.17042 mae=0.91732\n","\u003cclass '__main__.SocialReg'\u003e iteration 33: loss = 2960.1703, delta_loss = 78.36395 learning_Rate = 0.01000 rmse=1.16773 mae=0.91479\n","\u003cclass '__main__.SocialReg'\u003e iteration 34: loss = 2885.2057, delta_loss = 74.96453 learning_Rate = 0.01000 rmse=1.16521 mae=0.91241\n","\u003cclass '__main__.SocialReg'\u003e iteration 35: loss = 2813.4071, delta_loss = 71.79864 learning_Rate = 0.01000 rmse=1.16284 mae=0.91016\n","\u003cclass '__main__.SocialReg'\u003e iteration 36: loss = 2744.5631, delta_loss = 68.84396 learning_Rate = 0.01000 rmse=1.16062 mae=0.90805\n","\u003cclass '__main__.SocialReg'\u003e iteration 37: loss = 2678.4825, delta_loss = 66.08065 learning_Rate = 0.01000 rmse=1.15853 mae=0.90606\n","\u003cclass '__main__.SocialReg'\u003e iteration 38: loss = 2614.9914, delta_loss = 63.49109 learning_Rate = 0.01000 rmse=1.15655 mae=0.90418\n","\u003cclass '__main__.SocialReg'\u003e iteration 39: loss = 2553.9318, delta_loss = 61.05954 learning_Rate = 0.01000 rmse=1.15469 mae=0.90240\n","\u003cclass '__main__.SocialReg'\u003e iteration 40: loss = 2495.1599, delta_loss = 58.77193 learning_Rate = 0.01000 rmse=1.15293 mae=0.90071\n","\u003cclass '__main__.SocialReg'\u003e iteration 41: loss = 2438.5442, delta_loss = 56.61566 learning_Rate = 0.01000 rmse=1.15127 mae=0.89913\n","\u003cclass '__main__.SocialReg'\u003e iteration 42: loss = 2383.9648, delta_loss = 54.57943 learning_Rate = 0.01000 rmse=1.14969 mae=0.89761\n","\u003cclass '__main__.SocialReg'\u003e iteration 43: loss = 2331.3117, delta_loss = 52.65311 learning_Rate = 0.01000 rmse=1.14818 mae=0.89617\n","\u003cclass '__main__.SocialReg'\u003e iteration 44: loss = 2280.4841, delta_loss = 50.82759 learning_Rate = 0.01000 rmse=1.14675 mae=0.89480\n","\u003cclass '__main__.SocialReg'\u003e iteration 45: loss = 2231.3894, delta_loss = 49.09468 learning_Rate = 0.01000 rmse=1.14538 mae=0.89350\n","\u003cclass '__main__.SocialReg'\u003e iteration 46: loss = 2183.9424, delta_loss = 47.44703 learning_Rate = 0.01000 rmse=1.14410 mae=0.89227\n","\u003cclass '__main__.SocialReg'\u003e iteration 47: loss = 2138.0644, delta_loss = 45.87802 learning_Rate = 0.01000 rmse=1.14288 mae=0.89111\n","\u003cclass '__main__.SocialReg'\u003e iteration 48: loss = 2093.6827, delta_loss = 44.38172 learning_Rate = 0.01000 rmse=1.14172 mae=0.88999\n","\u003cclass '__main__.SocialReg'\u003e iteration 49: loss = 2050.7299, delta_loss = 42.95278 learning_Rate = 0.01000 rmse=1.14062 mae=0.88893\n","\u003cclass '__main__.SocialReg'\u003e iteration 50: loss = 2009.1435, delta_loss = 41.58640 learning_Rate = 0.01000 rmse=1.13958 mae=0.88793\n","\u003cclass '__main__.SocialReg'\u003e iteration 51: loss = 1968.8652, delta_loss = 40.27829 learning_Rate = 0.01000 rmse=1.13860 mae=0.88699\n","\u003cclass '__main__.SocialReg'\u003e iteration 52: loss = 1929.8406, delta_loss = 39.02458 learning_Rate = 0.01000 rmse=1.13767 mae=0.88609\n","\u003cclass '__main__.SocialReg'\u003e iteration 53: loss = 1892.0188, delta_loss = 37.82180 learning_Rate = 0.01000 rmse=1.13679 mae=0.88524\n","\u003cclass '__main__.SocialReg'\u003e iteration 54: loss = 1855.3520, delta_loss = 36.66683 learning_Rate = 0.01000 rmse=1.13596 mae=0.88444\n","\u003cclass '__main__.SocialReg'\u003e iteration 55: loss = 1819.7951, delta_loss = 35.55687 learning_Rate = 0.01000 rmse=1.13516 mae=0.88366\n","\u003cclass '__main__.SocialReg'\u003e iteration 56: loss = 1785.3057, delta_loss = 34.48940 learning_Rate = 0.01000 rmse=1.13439 mae=0.88291\n","\u003cclass '__main__.SocialReg'\u003e iteration 57: loss = 1751.8436, delta_loss = 33.46214 learning_Rate = 0.01000 rmse=1.13366 mae=0.88219\n","\u003cclass '__main__.SocialReg'\u003e iteration 58: loss = 1719.3705, delta_loss = 32.47303 learning_Rate = 0.01000 rmse=1.13296 mae=0.88148\n","\u003cclass '__main__.SocialReg'\u003e iteration 59: loss = 1687.8503, delta_loss = 31.52020 learning_Rate = 0.01000 rmse=1.13230 mae=0.88080\n","\u003cclass '__main__.SocialReg'\u003e iteration 60: loss = 1657.2484, delta_loss = 30.60195 learning_Rate = 0.01000 rmse=1.13168 mae=0.88017\n","\u003cclass '__main__.SocialReg'\u003e iteration 61: loss = 1627.5317, delta_loss = 29.71670 learning_Rate = 0.01000 rmse=1.13109 mae=0.87955\n","\u003cclass '__main__.SocialReg'\u003e iteration 62: loss = 1598.6687, delta_loss = 28.86301 learning_Rate = 0.01000 rmse=1.13053 mae=0.87897\n","\u003cclass '__main__.SocialReg'\u003e iteration 63: loss = 1570.6291, delta_loss = 28.03954 learning_Rate = 0.01000 rmse=1.12999 mae=0.87841\n","\u003cclass '__main__.SocialReg'\u003e iteration 64: loss = 1543.3841, delta_loss = 27.24504 learning_Rate = 0.01000 rmse=1.12949 mae=0.87787\n","\u003cclass '__main__.SocialReg'\u003e iteration 65: loss = 1516.9058, delta_loss = 26.47834 learning_Rate = 0.01000 rmse=1.12902 mae=0.87737\n","\u003cclass '__main__.SocialReg'\u003e iteration 66: loss = 1491.1674, delta_loss = 25.73833 learning_Rate = 0.01000 rmse=1.12857 mae=0.87689\n","\u003cclass '__main__.SocialReg'\u003e iteration 67: loss = 1466.1435, delta_loss = 25.02395 learning_Rate = 0.01000 rmse=1.12815 mae=0.87642\n","\u003cclass '__main__.SocialReg'\u003e iteration 68: loss = 1441.8093, delta_loss = 24.33421 learning_Rate = 0.01000 rmse=1.12777 mae=0.87600\n","\u003cclass '__main__.SocialReg'\u003e iteration 69: loss = 1418.1411, delta_loss = 23.66813 learning_Rate = 0.01000 rmse=1.12742 mae=0.87560\n","\u003cclass '__main__.SocialReg'\u003e iteration 70: loss = 1395.1163, delta_loss = 23.02480 learning_Rate = 0.01000 rmse=1.12708 mae=0.87521\n","\u003cclass '__main__.SocialReg'\u003e iteration 71: loss = 1372.7130, delta_loss = 22.40333 learning_Rate = 0.01000 rmse=1.12677 mae=0.87485\n","\u003cclass '__main__.SocialReg'\u003e iteration 72: loss = 1350.9101, delta_loss = 21.80287 learning_Rate = 0.01000 rmse=1.12649 mae=0.87450\n","\u003cclass '__main__.SocialReg'\u003e iteration 73: loss = 1329.6875, delta_loss = 21.22260 learning_Rate = 0.01000 rmse=1.12623 mae=0.87417\n","\u003cclass '__main__.SocialReg'\u003e iteration 74: loss = 1309.0258, delta_loss = 20.66173 learning_Rate = 0.01000 rmse=1.12599 mae=0.87386\n","\u003cclass '__main__.SocialReg'\u003e iteration 75: loss = 1288.9063, delta_loss = 20.11949 learning_Rate = 0.01000 rmse=1.12577 mae=0.87356\n","\u003cclass '__main__.SocialReg'\u003e iteration 76: loss = 1269.3112, delta_loss = 19.59515 learning_Rate = 0.01000 rmse=1.12557 mae=0.87327\n","\u003cclass '__main__.SocialReg'\u003e iteration 77: loss = 1250.2232, delta_loss = 19.08800 learning_Rate = 0.01000 rmse=1.12538 mae=0.87300\n","\u003cclass '__main__.SocialReg'\u003e iteration 78: loss = 1231.6258, delta_loss = 18.59737 learning_Rate = 0.01000 rmse=1.12521 mae=0.87274\n","\u003cclass '__main__.SocialReg'\u003e iteration 79: loss = 1213.5032, delta_loss = 18.12262 learning_Rate = 0.01000 rmse=1.12507 mae=0.87251\n","\u003cclass '__main__.SocialReg'\u003e iteration 80: loss = 1195.8401, delta_loss = 17.66311 learning_Rate = 0.01000 rmse=1.12494 mae=0.87228\n","\u003cclass '__main__.SocialReg'\u003e iteration 81: loss = 1178.6218, delta_loss = 17.21825 learning_Rate = 0.01000 rmse=1.12483 mae=0.87209\n","\u003cclass '__main__.SocialReg'\u003e iteration 82: loss = 1161.8343, delta_loss = 16.78747 learning_Rate = 0.01000 rmse=1.12474 mae=0.87192\n","\u003cclass '__main__.SocialReg'\u003e iteration 83: loss = 1145.4641, delta_loss = 16.37023 learning_Rate = 0.01000 rmse=1.12465 mae=0.87174\n","\u003cclass '__main__.SocialReg'\u003e iteration 84: loss = 1129.4981, delta_loss = 15.96600 learning_Rate = 0.01000 rmse=1.12461 mae=0.87160\n","\u003cclass '__main__.SocialReg'\u003e iteration 85: loss = 1113.9238, delta_loss = 15.57430 learning_Rate = 0.01000 rmse=1.12457 mae=0.87145\n","\u003cclass '__main__.SocialReg'\u003e iteration 86: loss = 1098.7292, delta_loss = 15.19465 learning_Rate = 0.01000 rmse=1.12453 mae=0.87132\n","\u003cclass '__main__.SocialReg'\u003e iteration 87: loss = 1083.9026, delta_loss = 14.82660 learning_Rate = 0.01000 rmse=1.12451 mae=0.87120\n","\u003cclass '__main__.SocialReg'\u003e iteration 88: loss = 1069.4328, delta_loss = 14.46972 learning_Rate = 0.01000 rmse=1.12450 mae=0.87108\n","\u003cclass '__main__.SocialReg'\u003e iteration 89: loss = 1055.3092, delta_loss = 14.12360 learning_Rate = 0.01000 rmse=1.12451 mae=0.87097\n","\u003cclass '__main__.SocialReg'\u003e iteration 90: loss = 1041.5214, delta_loss = 13.78785 learning_Rate = 0.01000 rmse=1.12453 mae=0.87088\n","\u003cclass '__main__.SocialReg'\u003e iteration 91: loss = 1028.0593, delta_loss = 13.46210 learning_Rate = 0.01000 rmse=1.12455 mae=0.87079\n","\u003cclass '__main__.SocialReg'\u003e iteration 92: loss = 1014.9133, delta_loss = 13.14600 learning_Rate = 0.01000 rmse=1.12459 mae=0.87072\n","\u003cclass '__main__.SocialReg'\u003e iteration 93: loss = 1002.0741, delta_loss = 12.83920 learning_Rate = 0.01000 rmse=1.12463 mae=0.87066\n","\u003cclass '__main__.SocialReg'\u003e iteration 94: loss = 989.5327, delta_loss = 12.54138 learning_Rate = 0.01000 rmse=1.12468 mae=0.87060\n","\u003cclass '__main__.SocialReg'\u003e iteration 95: loss = 977.2805, delta_loss = 12.25223 learning_Rate = 0.01000 rmse=1.12475 mae=0.87055\n","\u003cclass '__main__.SocialReg'\u003e iteration 96: loss = 965.3090, delta_loss = 11.97146 learning_Rate = 0.01000 rmse=1.12482 mae=0.87051\n","\u003cclass '__main__.SocialReg'\u003e iteration 97: loss = 953.6102, delta_loss = 11.69878 learning_Rate = 0.01000 rmse=1.12490 mae=0.87047\n","\u003cclass '__main__.SocialReg'\u003e iteration 98: loss = 942.1763, delta_loss = 11.43393 learning_Rate = 0.01000 rmse=1.12498 mae=0.87043\n","\u003cclass '__main__.SocialReg'\u003e iteration 99: loss = 930.9997, delta_loss = 11.17664 learning_Rate = 0.01000 rmse=1.12508 mae=0.87041\n","\u003cclass '__main__.SocialReg'\u003e iteration 100: loss = 920.0730, delta_loss = 10.92666 learning_Rate = 0.01000 rmse=1.12518 mae=0.87039\n","the 4th cross validation training\n","constructing user-user similarity matrix...\n","\u003cclass '__main__.SocialReg'\u003e iteration 1: loss = 18282.4041, delta_loss = -18282.40410 learning_Rate = 0.01000 rmse=2.22500 mae=1.90596\n","\u003cclass '__main__.SocialReg'\u003e iteration 2: loss = 14556.9168, delta_loss = 3725.48732 learning_Rate = 0.01000 rmse=1.96042 mae=1.63877\n","\u003cclass '__main__.SocialReg'\u003e iteration 3: loss = 12351.0855, delta_loss = 2205.83127 learning_Rate = 0.01000 rmse=1.78637 mae=1.46740\n","\u003cclass '__main__.SocialReg'\u003e iteration 4: loss = 10874.6145, delta_loss = 1476.47105 learning_Rate = 0.01000 rmse=1.66467 mae=1.35276\n","\u003cclass '__main__.SocialReg'\u003e iteration 5: loss = 9797.6501, delta_loss = 1076.96435 learning_Rate = 0.01000 rmse=1.57489 mae=1.27024\n","\u003cclass '__main__.SocialReg'\u003e iteration 6: loss = 8962.0023, delta_loss = 835.64779 learning_Rate = 0.01000 rmse=1.50610 mae=1.20849\n","\u003cclass '__main__.SocialReg'\u003e iteration 7: loss = 8285.1194, delta_loss = 676.88295 learning_Rate = 0.01000 rmse=1.45226 mae=1.16128\n","\u003cclass '__main__.SocialReg'\u003e iteration 8: loss = 7719.9039, delta_loss = 565.21549 learning_Rate = 0.01000 rmse=1.40906 mae=1.12388\n","\u003cclass '__main__.SocialReg'\u003e iteration 9: loss = 7237.3646, delta_loss = 482.53932 learning_Rate = 0.01000 rmse=1.37375 mae=1.09341\n","\u003cclass '__main__.SocialReg'\u003e iteration 10: loss = 6818.4643, delta_loss = 418.90026 learning_Rate = 0.01000 rmse=1.34439 mae=1.06790\n","\u003cclass '__main__.SocialReg'\u003e iteration 11: loss = 6450.0142, delta_loss = 368.45015 learning_Rate = 0.01000 rmse=1.31979 mae=1.04658\n","\u003cclass '__main__.SocialReg'\u003e iteration 12: loss = 6122.4785, delta_loss = 327.53563 learning_Rate = 0.01000 rmse=1.29907 mae=1.02857\n","\u003cclass '__main__.SocialReg'\u003e iteration 13: loss = 5828.7300, delta_loss = 293.74850 learning_Rate = 0.01000 rmse=1.28131 mae=1.01305\n","\u003cclass '__main__.SocialReg'\u003e iteration 14: loss = 5563.3000, delta_loss = 265.42999 learning_Rate = 0.01000 rmse=1.26597 mae=0.99954\n","\u003cclass '__main__.SocialReg'\u003e iteration 15: loss = 5321.9030, delta_loss = 241.39703 learning_Rate = 0.01000 rmse=1.25257 mae=0.98756\n","\u003cclass '__main__.SocialReg'\u003e iteration 16: loss = 5101.1209, delta_loss = 220.78213 learning_Rate = 0.01000 rmse=1.24083 mae=0.97710\n","\u003cclass '__main__.SocialReg'\u003e iteration 17: loss = 4898.1864, delta_loss = 202.93445 learning_Rate = 0.01000 rmse=1.23051 mae=0.96796\n","\u003cclass '__main__.SocialReg'\u003e iteration 18: loss = 4710.8302, delta_loss = 187.35623 learning_Rate = 0.01000 rmse=1.22135 mae=0.95986\n","\u003cclass '__main__.SocialReg'\u003e iteration 19: loss = 4537.1698, delta_loss = 173.66042 learning_Rate = 0.01000 rmse=1.21323 mae=0.95266\n","\u003cclass '__main__.SocialReg'\u003e iteration 20: loss = 4375.6281, delta_loss = 161.54170 learning_Rate = 0.01000 rmse=1.20593 mae=0.94611\n","\u003cclass '__main__.SocialReg'\u003e iteration 21: loss = 4224.8719, delta_loss = 150.75613 learning_Rate = 0.01000 rmse=1.19937 mae=0.94017\n","\u003cclass '__main__.SocialReg'\u003e iteration 22: loss = 4083.7653, delta_loss = 141.10667 learning_Rate = 0.01000 rmse=1.19343 mae=0.93480\n","\u003cclass '__main__.SocialReg'\u003e iteration 23: loss = 3951.3327, delta_loss = 132.43255 learning_Rate = 0.01000 rmse=1.18797 mae=0.92983\n","\u003cclass '__main__.SocialReg'\u003e iteration 24: loss = 3826.7313, delta_loss = 124.60137 learning_Rate = 0.01000 rmse=1.18298 mae=0.92531\n","\u003cclass '__main__.SocialReg'\u003e iteration 25: loss = 3709.2281, delta_loss = 117.50323 learning_Rate = 0.01000 rmse=1.17842 mae=0.92117\n","\u003cclass '__main__.SocialReg'\u003e iteration 26: loss = 3598.1820, delta_loss = 111.04613 learning_Rate = 0.01000 rmse=1.17424 mae=0.91737\n","\u003cclass '__main__.SocialReg'\u003e iteration 27: loss = 3493.0295, delta_loss = 105.15252 learning_Rate = 0.01000 rmse=1.17040 mae=0.91388\n","\u003cclass '__main__.SocialReg'\u003e iteration 28: loss = 3393.2729, delta_loss = 99.75656 learning_Rate = 0.01000 rmse=1.16682 mae=0.91063\n","\u003cclass '__main__.SocialReg'\u003e iteration 29: loss = 3298.4709, delta_loss = 94.80196 learning_Rate = 0.01000 rmse=1.16350 mae=0.90761\n","\u003cclass '__main__.SocialReg'\u003e iteration 30: loss = 3208.2306, delta_loss = 90.24031 learning_Rate = 0.01000 rmse=1.16042 mae=0.90481\n","\u003cclass '__main__.SocialReg'\u003e iteration 31: loss = 3122.2009, delta_loss = 86.02969 learning_Rate = 0.01000 rmse=1.15756 mae=0.90222\n","\u003cclass '__main__.SocialReg'\u003e iteration 32: loss = 3040.0673, delta_loss = 82.13360 learning_Rate = 0.01000 rmse=1.15487 mae=0.89979\n","\u003cclass '__main__.SocialReg'\u003e iteration 33: loss = 2961.5472, delta_loss = 78.52013 learning_Rate = 0.01000 rmse=1.15236 mae=0.89751\n","\u003cclass '__main__.SocialReg'\u003e iteration 34: loss = 2886.3860, delta_loss = 75.16117 learning_Rate = 0.01000 rmse=1.14999 mae=0.89536\n","\u003cclass '__main__.SocialReg'\u003e iteration 35: loss = 2814.3541, delta_loss = 72.03190 learning_Rate = 0.01000 rmse=1.14775 mae=0.89332\n","\u003cclass '__main__.SocialReg'\u003e iteration 36: loss = 2745.2438, delta_loss = 69.11031 learning_Rate = 0.01000 rmse=1.14563 mae=0.89138\n","\u003cclass '__main__.SocialReg'\u003e iteration 37: loss = 2678.8670, delta_loss = 66.37680 learning_Rate = 0.01000 rmse=1.14364 mae=0.88954\n","\u003cclass '__main__.SocialReg'\u003e iteration 38: loss = 2615.0532, delta_loss = 63.81387 learning_Rate = 0.01000 rmse=1.14174 mae=0.88780\n","\u003cclass '__main__.SocialReg'\u003e iteration 39: loss = 2553.6473, delta_loss = 61.40588 learning_Rate = 0.01000 rmse=1.13995 mae=0.88615\n","\u003cclass '__main__.SocialReg'\u003e iteration 40: loss = 2494.5085, delta_loss = 59.13879 learning_Rate = 0.01000 rmse=1.13825 mae=0.88459\n","\u003cclass '__main__.SocialReg'\u003e iteration 41: loss = 2437.5085, delta_loss = 57.00003 learning_Rate = 0.01000 rmse=1.13664 mae=0.88310\n","\u003cclass '__main__.SocialReg'\u003e iteration 42: loss = 2382.5301, delta_loss = 54.97833 learning_Rate = 0.01000 rmse=1.13512 mae=0.88168\n","\u003cclass '__main__.SocialReg'\u003e iteration 43: loss = 2329.4666, delta_loss = 53.06357 learning_Rate = 0.01000 rmse=1.13367 mae=0.88032\n","\u003cclass '__main__.SocialReg'\u003e iteration 44: loss = 2278.2199, delta_loss = 51.24668 learning_Rate = 0.01000 rmse=1.13230 mae=0.87903\n","\u003cclass '__main__.SocialReg'\u003e iteration 45: loss = 2228.7003, delta_loss = 49.51956 learning_Rate = 0.01000 rmse=1.13100 mae=0.87780\n","\u003cclass '__main__.SocialReg'\u003e iteration 46: loss = 2180.8254, delta_loss = 47.87495 learning_Rate = 0.01000 rmse=1.12978 mae=0.87665\n","\u003cclass '__main__.SocialReg'\u003e iteration 47: loss = 2134.5190, delta_loss = 46.30639 learning_Rate = 0.01000 rmse=1.12861 mae=0.87555\n","\u003cclass '__main__.SocialReg'\u003e iteration 48: loss = 2089.7108, delta_loss = 44.80814 learning_Rate = 0.01000 rmse=1.12751 mae=0.87451\n","\u003cclass '__main__.SocialReg'\u003e iteration 49: loss = 2046.3358, delta_loss = 43.37507 learning_Rate = 0.01000 rmse=1.12646 mae=0.87352\n","\u003cclass '__main__.SocialReg'\u003e iteration 50: loss = 2004.3331, delta_loss = 42.00264 learning_Rate = 0.01000 rmse=1.12547 mae=0.87258\n","\u003cclass '__main__.SocialReg'\u003e iteration 51: loss = 1963.6463, delta_loss = 40.68681 learning_Rate = 0.01000 rmse=1.12454 mae=0.87170\n","\u003cclass '__main__.SocialReg'\u003e iteration 52: loss = 1924.2223, delta_loss = 39.42401 learning_Rate = 0.01000 rmse=1.12366 mae=0.87086\n","\u003cclass '__main__.SocialReg'\u003e iteration 53: loss = 1886.0113, delta_loss = 38.21104 learning_Rate = 0.01000 rmse=1.12284 mae=0.87005\n","\u003cclass '__main__.SocialReg'\u003e iteration 54: loss = 1848.9662, delta_loss = 37.04506 learning_Rate = 0.01000 rmse=1.12205 mae=0.86928\n","\u003cclass '__main__.SocialReg'\u003e iteration 55: loss = 1813.0427, delta_loss = 35.92350 learning_Rate = 0.01000 rmse=1.12130 mae=0.86856\n","\u003cclass '__main__.SocialReg'\u003e iteration 56: loss = 1778.1986, delta_loss = 34.84408 learning_Rate = 0.01000 rmse=1.12061 mae=0.86787\n","\u003cclass '__main__.SocialReg'\u003e iteration 57: loss = 1744.3939, delta_loss = 33.80471 learning_Rate = 0.01000 rmse=1.11996 mae=0.86722\n","\u003cclass '__main__.SocialReg'\u003e iteration 58: loss = 1711.5904, delta_loss = 32.80347 learning_Rate = 0.01000 rmse=1.11934 mae=0.86659\n","\u003cclass '__main__.SocialReg'\u003e iteration 59: loss = 1679.7518, delta_loss = 31.83863 learning_Rate = 0.01000 rmse=1.11876 mae=0.86600\n","\u003cclass '__main__.SocialReg'\u003e iteration 60: loss = 1648.8433, delta_loss = 30.90856 learning_Rate = 0.01000 rmse=1.11823 mae=0.86546\n","\u003cclass '__main__.SocialReg'\u003e iteration 61: loss = 1618.8315, delta_loss = 30.01175 learning_Rate = 0.01000 rmse=1.11774 mae=0.86494\n","\u003cclass '__main__.SocialReg'\u003e iteration 62: loss = 1589.6847, delta_loss = 29.14679 learning_Rate = 0.01000 rmse=1.11729 mae=0.86445\n","\u003cclass '__main__.SocialReg'\u003e iteration 63: loss = 1561.3724, delta_loss = 28.31235 learning_Rate = 0.01000 rmse=1.11686 mae=0.86399\n","\u003cclass '__main__.SocialReg'\u003e iteration 64: loss = 1533.8652, delta_loss = 27.50717 learning_Rate = 0.01000 rmse=1.11647 mae=0.86356\n","\u003cclass '__main__.SocialReg'\u003e iteration 65: loss = 1507.1352, delta_loss = 26.73006 learning_Rate = 0.01000 rmse=1.11611 mae=0.86316\n","\u003cclass '__main__.SocialReg'\u003e iteration 66: loss = 1481.1552, delta_loss = 25.97990 learning_Rate = 0.01000 rmse=1.11577 mae=0.86277\n","\u003cclass '__main__.SocialReg'\u003e iteration 67: loss = 1455.8996, delta_loss = 25.25561 learning_Rate = 0.01000 rmse=1.11547 mae=0.86242\n","\u003cclass '__main__.SocialReg'\u003e iteration 68: loss = 1431.3435, delta_loss = 24.55616 learning_Rate = 0.01000 rmse=1.11519 mae=0.86207\n","\u003cclass '__main__.SocialReg'\u003e iteration 69: loss = 1407.4629, delta_loss = 23.88057 learning_Rate = 0.01000 rmse=1.11494 mae=0.86175\n","\u003cclass '__main__.SocialReg'\u003e iteration 70: loss = 1384.2350, delta_loss = 23.22792 learning_Rate = 0.01000 rmse=1.11470 mae=0.86145\n","\u003cclass '__main__.SocialReg'\u003e iteration 71: loss = 1361.6377, delta_loss = 22.59731 learning_Rate = 0.01000 rmse=1.11448 mae=0.86116\n","\u003cclass '__main__.SocialReg'\u003e iteration 72: loss = 1339.6498, delta_loss = 21.98788 learning_Rate = 0.01000 rmse=1.11427 mae=0.86089\n","\u003cclass '__main__.SocialReg'\u003e iteration 73: loss = 1318.2510, delta_loss = 21.39883 learning_Rate = 0.01000 rmse=1.11410 mae=0.86063\n","\u003cclass '__main__.SocialReg'\u003e iteration 74: loss = 1297.4216, delta_loss = 20.82937 learning_Rate = 0.01000 rmse=1.11394 mae=0.86039\n","\u003cclass '__main__.SocialReg'\u003e iteration 75: loss = 1277.1429, delta_loss = 20.27874 learning_Rate = 0.01000 rmse=1.11381 mae=0.86018\n","\u003cclass '__main__.SocialReg'\u003e iteration 76: loss = 1257.3966, delta_loss = 19.74625 learning_Rate = 0.01000 rmse=1.11369 mae=0.85998\n","\u003cclass '__main__.SocialReg'\u003e iteration 77: loss = 1238.1654, delta_loss = 19.23118 learning_Rate = 0.01000 rmse=1.11358 mae=0.85980\n","\u003cclass '__main__.SocialReg'\u003e iteration 78: loss = 1219.4325, delta_loss = 18.73290 learning_Rate = 0.01000 rmse=1.11350 mae=0.85964\n","\u003cclass '__main__.SocialReg'\u003e iteration 79: loss = 1201.1818, delta_loss = 18.25075 learning_Rate = 0.01000 rmse=1.11343 mae=0.85950\n","\u003cclass '__main__.SocialReg'\u003e iteration 80: loss = 1183.3977, delta_loss = 17.78413 learning_Rate = 0.01000 rmse=1.11338 mae=0.85936\n","\u003cclass '__main__.SocialReg'\u003e iteration 81: loss = 1166.0652, delta_loss = 17.33245 learning_Rate = 0.01000 rmse=1.11334 mae=0.85924\n","\u003cclass '__main__.SocialReg'\u003e iteration 82: loss = 1149.1700, delta_loss = 16.89517 learning_Rate = 0.01000 rmse=1.11332 mae=0.85914\n","\u003cclass '__main__.SocialReg'\u003e iteration 83: loss = 1132.6983, delta_loss = 16.47173 learning_Rate = 0.01000 rmse=1.11331 mae=0.85904\n","\u003cclass '__main__.SocialReg'\u003e iteration 84: loss = 1116.6367, delta_loss = 16.06162 learning_Rate = 0.01000 rmse=1.11332 mae=0.85895\n","\u003cclass '__main__.SocialReg'\u003e iteration 85: loss = 1100.9723, delta_loss = 15.66435 learning_Rate = 0.01000 rmse=1.11333 mae=0.85888\n","\u003cclass '__main__.SocialReg'\u003e iteration 86: loss = 1085.6929, delta_loss = 15.27945 learning_Rate = 0.01000 rmse=1.11336 mae=0.85882\n","\u003cclass '__main__.SocialReg'\u003e iteration 87: loss = 1070.7865, delta_loss = 14.90644 learning_Rate = 0.01000 rmse=1.11339 mae=0.85878\n","\u003cclass '__main__.SocialReg'\u003e iteration 88: loss = 1056.2415, delta_loss = 14.54492 learning_Rate = 0.01000 rmse=1.11344 mae=0.85874\n","\u003cclass '__main__.SocialReg'\u003e iteration 89: loss = 1042.0471, delta_loss = 14.19444 learning_Rate = 0.01000 rmse=1.11350 mae=0.85872\n","\u003cclass '__main__.SocialReg'\u003e iteration 90: loss = 1028.1925, delta_loss = 13.85462 learning_Rate = 0.01000 rmse=1.11356 mae=0.85870\n","\u003cclass '__main__.SocialReg'\u003e iteration 91: loss = 1014.6674, delta_loss = 13.52507 learning_Rate = 0.01000 rmse=1.11364 mae=0.85869\n","\u003cclass '__main__.SocialReg'\u003e iteration 92: loss = 1001.4620, delta_loss = 13.20543 learning_Rate = 0.01000 rmse=1.11373 mae=0.85869\n","\u003cclass '__main__.SocialReg'\u003e iteration 93: loss = 988.5666, delta_loss = 12.89534 learning_Rate = 0.01000 rmse=1.11383 mae=0.85870\n","\u003cclass '__main__.SocialReg'\u003e iteration 94: loss = 975.9722, delta_loss = 12.59446 learning_Rate = 0.01000 rmse=1.11393 mae=0.85871\n","\u003cclass '__main__.SocialReg'\u003e iteration 95: loss = 963.6697, delta_loss = 12.30248 learning_Rate = 0.01000 rmse=1.11405 mae=0.85873\n","\u003cclass '__main__.SocialReg'\u003e iteration 96: loss = 951.6506, delta_loss = 12.01909 learning_Rate = 0.01000 rmse=1.11417 mae=0.85876\n","\u003cclass '__main__.SocialReg'\u003e iteration 97: loss = 939.9066, delta_loss = 11.74398 learning_Rate = 0.01000 rmse=1.11431 mae=0.85880\n","\u003cclass '__main__.SocialReg'\u003e iteration 98: loss = 928.4297, delta_loss = 11.47688 learning_Rate = 0.01000 rmse=1.11446 mae=0.85885\n","\u003cclass '__main__.SocialReg'\u003e iteration 99: loss = 917.2122, delta_loss = 11.21751 learning_Rate = 0.01000 rmse=1.11461 mae=0.85889\n","\u003cclass '__main__.SocialReg'\u003e iteration 100: loss = 906.2466, delta_loss = 10.96562 learning_Rate = 0.01000 rmse=1.11476 mae=0.85895\n","the rmses are [1.13203852925596, 1.1360973350208805, 1.0996505078056493, 1.1251841466053196, 1.1147604353763716]\n","the maes are [0.8768745523853527, 0.872791819852939, 0.8640838584030253, 0.8703893541355978, 0.8589486328795334]\n","the average of rmses is 1.1215461908128364 \n","the average of maes is 0.8686176435312897 \n"]}],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")\n","import numpy as np\n","#from mf import MF\n","#from reader.trust import TrustGetter\n","#from utility.matrix import SimMatrix\n","#from utility.similarity import pearson_sp, cosine_sp\n","#from utility import util\n","\n","\n","class SocialReg(MF):\n","    \"\"\"\n","    docstring for SocialReg\n","\n","    Ma H, Zhou D, Liu C, et al. Recommender systems with social regularization[C]//Proceedings of the fourth ACM international conference on Web search and data mining. ACM, 2011: 287-296.\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(SocialReg, self).__init__()\n","        # self.config.lambdaP = 0.001\n","        # self.config.lambdaQ = 0.001\n","        self.config.alpha = 0.1\n","        self.tg = TrustGetter()\n","        # self.init_model()\n","\n","    def init_model(self, k):\n","        super(SocialReg, self).init_model(k)\n","        from collections import defaultdict\n","        self.user_sim = SimMatrix()\n","        print('constructing user-user similarity matrix...')\n","\n","        # self.user_sim = util.load_data('../data/sim/ft_cf_soreg08_cv1.pkl')\n","\n","        for u in self.rg.user:\n","            for f in self.tg.get_followees(u):\n","                if self.user_sim.contains(u, f):\n","                    continue\n","                sim = self.get_sim(u, f)\n","                self.user_sim.set(u, f, sim)\n","\n","        # util.save_data(self.user_sim,'../data/sim/ft_cf_soreg08.pkl')\n","\n","    def get_sim(self, u, k):\n","        sim = (pearson_sp(self.rg.get_row(u), self.rg.get_row(k)) + 1.0) / 2.0  # fit the value into range [0.0,1.0]\n","        return sim\n","\n","    def train_model(self, k):\n","        super(SocialReg, self).train_model(k)\n","        iteration = 0\n","        while iteration \u003c self.config.maxIter:\n","            self.loss = 0\n","            for index, line in enumerate(self.rg.trainSet()):\n","                user, item, rating = line\n","                u = self.rg.user[user]\n","                i = self.rg.item[item]\n","                error = rating - self.predict(user, item)\n","                self.loss += 0.5 * error ** 2\n","                p, q = self.P[u], self.Q[i]\n","\n","                social_term_p, social_term_loss = np.zeros((self.config.factor)), 0.0\n","                followees = self.tg.get_followees(user)\n","                for followee in followees:\n","                    if self.rg.containsUser(followee):\n","                        s = self.user_sim[user][followee]\n","                        uf = self.P[self.rg.user[followee]]\n","                        social_term_p += s * (p - uf)\n","                        social_term_loss += s * ((p - uf).dot(p - uf))\n","\n","                social_term_m = np.zeros((self.config.factor))\n","                followers = self.tg.get_followers(user)\n","                for follower in followers:\n","                    if self.rg.containsUser(follower):\n","                        s = self.user_sim[user][follower]\n","                        ug = self.P[self.rg.user[follower]]\n","                        social_term_m += s * (p - ug)\n","\n","                # update latent vectors\n","                self.P[u] += self.config.lr * (\n","                        error * q - self.config.alpha * (social_term_p + social_term_m) - self.config.lambdaP * p)\n","                self.Q[i] += self.config.lr * (error * p - self.config.lambdaQ * q)\n","\n","                self.loss += 0.5 * self.config.alpha * social_term_loss\n","\n","            self.loss += 0.5 * self.config.lambdaP * (self.P * self.P).sum() + 0.5 * self.config.lambdaQ * (\n","                    self.Q * self.Q).sum()\n","\n","            iteration += 1\n","            if self.isConverged(iteration):\n","                break\n","\n","\n","if __name__ == '__main__':\n","    # srg = SocialReg()\n","    # srg.train_model(0)\n","    # coldrmse = srg.predict_model_cold_users()\n","    # print('cold start user rmse is :' + str(coldrmse))\n","    # srg.show_rmse()\n","\n","    rmses = []\n","    maes = []\n","    tcsr = SocialReg()\n","    # print(bmf.rg.trainSet_u[1])\n","    for i in range(tcsr.config.k_fold_num):\n","        print('the %dth cross validation training' % i)\n","        tcsr.train_model(i)\n","        rmse, mae = tcsr.predict_model()\n","        rmses.append(rmse)\n","        maes.append(mae)\n","    rmse_avg = sum(rmses) / 5\n","    mae_avg = sum(maes) / 5\n","    print(\"the rmses are %s\" % rmses)\n","    print(\"the maes are %s\" % maes)\n","    print(\"the average of rmses is %s \" % rmse_avg)\n","    print(\"the average of maes is %s \" % mae_avg)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"-n9uLYH9jHL-"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'dataset_name': 'CiaoDVD', 'k_fold_num': 5, 'rating_path': '/content/drive/MyDrive/data/ft_ratings.txt', 'rating_cv_path': '../data/cv/', 'trust_path': '/content/drive/MyDrive/data/ft_trust_SimRank.txt', 'sep': ' ', 'random_state': 0, 'size': 0.6, 'min_val': 0.5, 'max_val': 4.0, 'coldUserRating': 5, 'factor': 10, 'threshold': 0.0001, 'lr': 0.01, 'maxIter': 100, 'lambdaP': 0.001, 'lambdaQ': 0.001, 'gamma': 0, 'isEarlyStopping': False, 'result_path': '../results/', 'model_path': 'model/', 'result_log_path': 'log/'}\n","\u003cclass '__main__.TrustSVD'\u003e iteration 1: loss = 123442.7239, delta_loss = -123442.72386 learning_Rate = 0.01000 rmse=1.40761 mae=1.02681\n","\u003cclass '__main__.TrustSVD'\u003e iteration 2: loss = 54971.1486, delta_loss = 68471.57524 learning_Rate = 0.01000 rmse=1.29047 mae=0.96677\n","\u003cclass '__main__.TrustSVD'\u003e iteration 3: loss = 39814.9113, delta_loss = 15156.23734 learning_Rate = 0.01000 rmse=1.22023 mae=0.92636\n","\u003cclass '__main__.TrustSVD'\u003e iteration 4: loss = 35906.4335, delta_loss = 3908.47773 learning_Rate = 0.01000 rmse=1.18471 mae=0.90534\n","\u003cclass '__main__.TrustSVD'\u003e iteration 5: loss = 33587.5560, delta_loss = 2318.87754 learning_Rate = 0.01000 rmse=1.16391 mae=0.89273\n","\u003cclass '__main__.TrustSVD'\u003e iteration 6: loss = 31935.6081, delta_loss = 1651.94787 learning_Rate = 0.01000 rmse=1.14928 mae=0.88369\n","\u003cclass '__main__.TrustSVD'\u003e iteration 7: loss = 30664.2278, delta_loss = 1271.38036 learning_Rate = 0.01000 rmse=1.13861 mae=0.87675\n","\u003cclass '__main__.TrustSVD'\u003e iteration 8: loss = 29640.2850, delta_loss = 1023.94275 learning_Rate = 0.01000 rmse=1.13049 mae=0.87145\n","\u003cclass '__main__.TrustSVD'\u003e iteration 9: loss = 28789.2254, delta_loss = 851.05966 learning_Rate = 0.01000 rmse=1.12410 mae=0.86719\n","\u003cclass '__main__.TrustSVD'\u003e iteration 10: loss = 28064.9346, delta_loss = 724.29079 learning_Rate = 0.01000 rmse=1.11896 mae=0.86359\n","\u003cclass '__main__.TrustSVD'\u003e iteration 11: loss = 27437.0304, delta_loss = 627.90413 learning_Rate = 0.01000 rmse=1.11463 mae=0.86060\n","\u003cclass '__main__.TrustSVD'\u003e iteration 12: loss = 26884.5568, delta_loss = 552.47364 learning_Rate = 0.01000 rmse=1.11091 mae=0.85792\n","\u003cclass '__main__.TrustSVD'\u003e iteration 13: loss = 26392.5560, delta_loss = 492.00075 learning_Rate = 0.01000 rmse=1.10763 mae=0.85550\n","\u003cclass '__main__.TrustSVD'\u003e iteration 14: loss = 25950.0687, delta_loss = 442.48738 learning_Rate = 0.01000 rmse=1.10481 mae=0.85333\n","\u003cclass '__main__.TrustSVD'\u003e iteration 15: loss = 25548.8898, delta_loss = 401.17890 learning_Rate = 0.01000 rmse=1.10234 mae=0.85139\n","\u003cclass '__main__.TrustSVD'\u003e iteration 16: loss = 25182.7548, delta_loss = 366.13493 learning_Rate = 0.01000 rmse=1.10006 mae=0.84963\n","\u003cclass '__main__.TrustSVD'\u003e iteration 17: loss = 24846.7855, delta_loss = 335.96935 learning_Rate = 0.01000 rmse=1.09802 mae=0.84804\n","\u003cclass '__main__.TrustSVD'\u003e iteration 18: loss = 24537.1035, delta_loss = 309.68199 learning_Rate = 0.01000 rmse=1.09620 mae=0.84662\n","\u003cclass '__main__.TrustSVD'\u003e iteration 19: loss = 24250.5605, delta_loss = 286.54300 learning_Rate = 0.01000 rmse=1.09456 mae=0.84531\n","\u003cclass '__main__.TrustSVD'\u003e iteration 20: loss = 23984.5503, delta_loss = 266.01019 learning_Rate = 0.01000 rmse=1.09307 mae=0.84407\n","\u003cclass '__main__.TrustSVD'\u003e iteration 21: loss = 23736.8799, delta_loss = 247.67045 learning_Rate = 0.01000 rmse=1.09169 mae=0.84294\n","\u003cclass '__main__.TrustSVD'\u003e iteration 22: loss = 23505.6803, delta_loss = 231.19955 learning_Rate = 0.01000 rmse=1.09043 mae=0.84192\n","\u003cclass '__main__.TrustSVD'\u003e iteration 23: loss = 23289.3443, delta_loss = 216.33600 learning_Rate = 0.01000 rmse=1.08924 mae=0.84094\n","\u003cclass '__main__.TrustSVD'\u003e iteration 24: loss = 23086.4799, delta_loss = 202.86437 learning_Rate = 0.01000 rmse=1.08812 mae=0.83999\n","\u003cclass '__main__.TrustSVD'\u003e iteration 25: loss = 22895.8750, delta_loss = 190.60489 learning_Rate = 0.01000 rmse=1.08710 mae=0.83914\n","\u003cclass '__main__.TrustSVD'\u003e iteration 26: loss = 22716.4688, delta_loss = 179.40629 learning_Rate = 0.01000 rmse=1.08614 mae=0.83836\n","\u003cclass '__main__.TrustSVD'\u003e iteration 27: loss = 22547.3279, delta_loss = 169.14083 learning_Rate = 0.01000 rmse=1.08525 mae=0.83764\n","\u003cclass '__main__.TrustSVD'\u003e iteration 28: loss = 22387.6276, delta_loss = 159.70030 learning_Rate = 0.01000 rmse=1.08441 mae=0.83695\n","\u003cclass '__main__.TrustSVD'\u003e iteration 29: loss = 22236.6348, delta_loss = 150.99278 learning_Rate = 0.01000 rmse=1.08363 mae=0.83632\n","\u003cclass '__main__.TrustSVD'\u003e iteration 30: loss = 22093.6949, delta_loss = 142.93989 learning_Rate = 0.01000 rmse=1.08292 mae=0.83575\n","\u003cclass '__main__.TrustSVD'\u003e iteration 31: loss = 21958.2204, delta_loss = 135.47457 learning_Rate = 0.01000 rmse=1.08226 mae=0.83521\n","\u003cclass '__main__.TrustSVD'\u003e iteration 32: loss = 21829.6813, delta_loss = 128.53907 learning_Rate = 0.01000 rmse=1.08164 mae=0.83470\n","\u003cclass '__main__.TrustSVD'\u003e iteration 33: loss = 21707.5979, delta_loss = 122.08339 learning_Rate = 0.01000 rmse=1.08108 mae=0.83423\n","\u003cclass '__main__.TrustSVD'\u003e iteration 34: loss = 21591.5340, delta_loss = 116.06394 learning_Rate = 0.01000 rmse=1.08054 mae=0.83377\n","\u003cclass '__main__.TrustSVD'\u003e iteration 35: loss = 21481.0915, delta_loss = 110.44248 learning_Rate = 0.01000 rmse=1.08005 mae=0.83335\n","\u003cclass '__main__.TrustSVD'\u003e iteration 36: loss = 21375.9063, delta_loss = 105.18519 learning_Rate = 0.01000 rmse=1.07958 mae=0.83294\n","\u003cclass '__main__.TrustSVD'\u003e iteration 37: loss = 21275.6443, delta_loss = 100.26202 learning_Rate = 0.01000 rmse=1.07914 mae=0.83254\n","\u003cclass '__main__.TrustSVD'\u003e iteration 38: loss = 21179.9982, delta_loss = 95.64609 learning_Rate = 0.01000 rmse=1.07873 mae=0.83217\n","\u003cclass '__main__.TrustSVD'\u003e iteration 39: loss = 21088.6850, delta_loss = 91.31323 learning_Rate = 0.01000 rmse=1.07835 mae=0.83182\n","\u003cclass '__main__.TrustSVD'\u003e iteration 40: loss = 21001.4433, delta_loss = 87.24163 learning_Rate = 0.01000 rmse=1.07799 mae=0.83148\n","\u003cclass '__main__.TrustSVD'\u003e iteration 41: loss = 20918.0318, delta_loss = 83.41152 learning_Rate = 0.01000 rmse=1.07765 mae=0.83117\n","\u003cclass '__main__.TrustSVD'\u003e iteration 42: loss = 20838.2269, delta_loss = 79.80494 learning_Rate = 0.01000 rmse=1.07733 mae=0.83087\n","\u003cclass '__main__.TrustSVD'\u003e iteration 43: loss = 20761.8213, delta_loss = 76.40553 learning_Rate = 0.01000 rmse=1.07703 mae=0.83058\n","\u003cclass '__main__.TrustSVD'\u003e iteration 44: loss = 20688.6230, delta_loss = 73.19838 learning_Rate = 0.01000 rmse=1.07676 mae=0.83031\n","\u003cclass '__main__.TrustSVD'\u003e iteration 45: loss = 20618.4531, delta_loss = 70.16983 learning_Rate = 0.01000 rmse=1.07650 mae=0.83004\n","\u003cclass '__main__.TrustSVD'\u003e iteration 46: loss = 20551.1457, delta_loss = 67.30740 learning_Rate = 0.01000 rmse=1.07626 mae=0.82980\n","\u003cclass '__main__.TrustSVD'\u003e iteration 47: loss = 20486.5461, delta_loss = 64.59963 learning_Rate = 0.01000 rmse=1.07604 mae=0.82956\n","\u003cclass '__main__.TrustSVD'\u003e iteration 48: loss = 20424.5101, delta_loss = 62.03604 learning_Rate = 0.01000 rmse=1.07582 mae=0.82932\n","\u003cclass '__main__.TrustSVD'\u003e iteration 49: loss = 20364.9031, delta_loss = 59.60697 learning_Rate = 0.01000 rmse=1.07561 mae=0.82909\n","\u003cclass '__main__.TrustSVD'\u003e iteration 50: loss = 20307.5995, delta_loss = 57.30357 learning_Rate = 0.01000 rmse=1.07543 mae=0.82889\n","\u003cclass '__main__.TrustSVD'\u003e iteration 51: loss = 20252.4819, delta_loss = 55.11766 learning_Rate = 0.01000 rmse=1.07526 mae=0.82869\n","\u003cclass '__main__.TrustSVD'\u003e iteration 52: loss = 20199.4401, delta_loss = 53.04175 learning_Rate = 0.01000 rmse=1.07509 mae=0.82850\n","\u003cclass '__main__.TrustSVD'\u003e iteration 53: loss = 20148.3712, delta_loss = 51.06889 learning_Rate = 0.01000 rmse=1.07493 mae=0.82832\n","\u003cclass '__main__.TrustSVD'\u003e iteration 54: loss = 20099.1785, delta_loss = 49.19269 learning_Rate = 0.01000 rmse=1.07478 mae=0.82814\n","\u003cclass '__main__.TrustSVD'\u003e iteration 55: loss = 20051.7713, delta_loss = 47.40724 learning_Rate = 0.01000 rmse=1.07464 mae=0.82799\n","\u003cclass '__main__.TrustSVD'\u003e iteration 56: loss = 20006.0642, delta_loss = 45.70706 learning_Rate = 0.01000 rmse=1.07451 mae=0.82782\n","\u003cclass '__main__.TrustSVD'\u003e iteration 57: loss = 19961.9771, delta_loss = 44.08710 learning_Rate = 0.01000 rmse=1.07439 mae=0.82767\n","\u003cclass '__main__.TrustSVD'\u003e iteration 58: loss = 19919.4345, delta_loss = 42.54265 learning_Rate = 0.01000 rmse=1.07428 mae=0.82753\n","\u003cclass '__main__.TrustSVD'\u003e iteration 59: loss = 19878.3651, delta_loss = 41.06935 learning_Rate = 0.01000 rmse=1.07417 mae=0.82739\n","\u003cclass '__main__.TrustSVD'\u003e iteration 60: loss = 19838.7020, delta_loss = 39.66314 learning_Rate = 0.01000 rmse=1.07407 mae=0.82725\n","\u003cclass '__main__.TrustSVD'\u003e iteration 61: loss = 19800.3817, delta_loss = 38.32027 learning_Rate = 0.01000 rmse=1.07398 mae=0.82713\n","\u003cclass '__main__.TrustSVD'\u003e iteration 62: loss = 19763.3445, delta_loss = 37.03720 learning_Rate = 0.01000 rmse=1.07388 mae=0.82700\n","\u003cclass '__main__.TrustSVD'\u003e iteration 63: loss = 19727.5338, delta_loss = 35.81067 learning_Rate = 0.01000 rmse=1.07380 mae=0.82689\n","\u003cclass '__main__.TrustSVD'\u003e iteration 64: loss = 19692.8962, delta_loss = 34.63761 learning_Rate = 0.01000 rmse=1.07372 mae=0.82677\n","\u003cclass '__main__.TrustSVD'\u003e iteration 65: loss = 19659.3811, delta_loss = 33.51517 learning_Rate = 0.01000 rmse=1.07363 mae=0.82666\n","\u003cclass '__main__.TrustSVD'\u003e iteration 66: loss = 19626.9404, delta_loss = 32.44068 learning_Rate = 0.01000 rmse=1.07355 mae=0.82655\n","\u003cclass '__main__.TrustSVD'\u003e iteration 67: loss = 19595.5288, delta_loss = 31.41161 learning_Rate = 0.01000 rmse=1.07348 mae=0.82645\n","\u003cclass '__main__.TrustSVD'\u003e iteration 68: loss = 19565.1031, delta_loss = 30.42564 learning_Rate = 0.01000 rmse=1.07340 mae=0.82635\n","\u003cclass '__main__.TrustSVD'\u003e iteration 69: loss = 19535.6226, delta_loss = 29.48055 learning_Rate = 0.01000 rmse=1.07333 mae=0.82625\n","\u003cclass '__main__.TrustSVD'\u003e iteration 70: loss = 19507.0483, delta_loss = 28.57427 learning_Rate = 0.01000 rmse=1.07327 mae=0.82616\n","\u003cclass '__main__.TrustSVD'\u003e iteration 71: loss = 19479.3434, delta_loss = 27.70487 learning_Rate = 0.01000 rmse=1.07321 mae=0.82607\n","\u003cclass '__main__.TrustSVD'\u003e iteration 72: loss = 19452.4729, delta_loss = 26.87052 learning_Rate = 0.01000 rmse=1.07315 mae=0.82599\n","\u003cclass '__main__.TrustSVD'\u003e iteration 73: loss = 19426.4034, delta_loss = 26.06949 learning_Rate = 0.01000 rmse=1.07309 mae=0.82591\n","\u003cclass '__main__.TrustSVD'\u003e iteration 74: loss = 19401.1033, delta_loss = 25.30017 learning_Rate = 0.01000 rmse=1.07305 mae=0.82585\n","\u003cclass '__main__.TrustSVD'\u003e iteration 75: loss = 19376.5422, delta_loss = 24.56103 learning_Rate = 0.01000 rmse=1.07299 mae=0.82577\n","\u003cclass '__main__.TrustSVD'\u003e iteration 76: loss = 19352.6916, delta_loss = 23.85063 learning_Rate = 0.01000 rmse=1.07295 mae=0.82570\n","\u003cclass '__main__.TrustSVD'\u003e iteration 77: loss = 19329.5240, delta_loss = 23.16763 learning_Rate = 0.01000 rmse=1.07291 mae=0.82564\n","\u003cclass '__main__.TrustSVD'\u003e iteration 78: loss = 19307.0133, delta_loss = 22.51073 learning_Rate = 0.01000 rmse=1.07286 mae=0.82558\n","\u003cclass '__main__.TrustSVD'\u003e iteration 79: loss = 19285.1345, delta_loss = 21.87874 learning_Rate = 0.01000 rmse=1.07283 mae=0.82552\n","\u003cclass '__main__.TrustSVD'\u003e iteration 80: loss = 19263.8640, delta_loss = 21.27051 learning_Rate = 0.01000 rmse=1.07280 mae=0.82547\n","\u003cclass '__main__.TrustSVD'\u003e iteration 81: loss = 19243.1790, delta_loss = 20.68497 learning_Rate = 0.01000 rmse=1.07276 mae=0.82542\n","\u003cclass '__main__.TrustSVD'\u003e iteration 82: loss = 19223.0580, delta_loss = 20.12108 learning_Rate = 0.01000 rmse=1.07273 mae=0.82537\n","\u003cclass '__main__.TrustSVD'\u003e iteration 83: loss = 19203.4800, delta_loss = 19.57790 learning_Rate = 0.01000 rmse=1.07270 mae=0.82532\n","\u003cclass '__main__.TrustSVD'\u003e iteration 84: loss = 19184.4255, delta_loss = 19.05451 learning_Rate = 0.01000 rmse=1.07268 mae=0.82527\n","\u003cclass '__main__.TrustSVD'\u003e iteration 85: loss = 19165.8755, delta_loss = 18.55005 learning_Rate = 0.01000 rmse=1.07266 mae=0.82523\n","\u003cclass '__main__.TrustSVD'\u003e iteration 86: loss = 19147.8118, delta_loss = 18.06369 learning_Rate = 0.01000 rmse=1.07262 mae=0.82518\n","\u003cclass '__main__.TrustSVD'\u003e iteration 87: loss = 19130.2171, delta_loss = 17.59466 learning_Rate = 0.01000 rmse=1.07260 mae=0.82514\n","\u003cclass '__main__.TrustSVD'\u003e iteration 88: loss = 19113.0749, delta_loss = 17.14223 learning_Rate = 0.01000 rmse=1.07258 mae=0.82510\n","\u003cclass '__main__.TrustSVD'\u003e iteration 89: loss = 19096.3692, delta_loss = 16.70569 learning_Rate = 0.01000 rmse=1.07255 mae=0.82507\n","\u003cclass '__main__.TrustSVD'\u003e iteration 90: loss = 19080.0848, delta_loss = 16.28440 learning_Rate = 0.01000 rmse=1.07253 mae=0.82503\n","\u003cclass '__main__.TrustSVD'\u003e iteration 91: loss = 19064.2071, delta_loss = 15.87771 learning_Rate = 0.01000 rmse=1.07251 mae=0.82500\n","\u003cclass '__main__.TrustSVD'\u003e iteration 92: loss = 19048.7221, delta_loss = 15.48502 learning_Rate = 0.01000 rmse=1.07250 mae=0.82497\n","\u003cclass '__main__.TrustSVD'\u003e iteration 93: loss = 19033.6163, delta_loss = 15.10578 learning_Rate = 0.01000 rmse=1.07248 mae=0.82495\n","\u003cclass '__main__.TrustSVD'\u003e iteration 94: loss = 19018.8769, delta_loss = 14.73943 learning_Rate = 0.01000 rmse=1.07246 mae=0.82492\n","\u003cclass '__main__.TrustSVD'\u003e iteration 95: loss = 19004.4914, delta_loss = 14.38546 learning_Rate = 0.01000 rmse=1.07245 mae=0.82489\n","\u003cclass '__main__.TrustSVD'\u003e iteration 96: loss = 18990.4481, delta_loss = 14.04338 learning_Rate = 0.01000 rmse=1.07244 mae=0.82487\n","\u003cclass '__main__.TrustSVD'\u003e iteration 97: loss = 18976.7353, delta_loss = 13.71272 learning_Rate = 0.01000 rmse=1.07242 mae=0.82485\n","\u003cclass '__main__.TrustSVD'\u003e iteration 98: loss = 18963.3423, delta_loss = 13.39303 learning_Rate = 0.01000 rmse=1.07241 mae=0.82482\n","\u003cclass '__main__.TrustSVD'\u003e iteration 99: loss = 18950.2584, delta_loss = 13.08389 learning_Rate = 0.01000 rmse=1.07239 mae=0.82480\n","\u003cclass '__main__.TrustSVD'\u003e iteration 100: loss = 18937.4736, delta_loss = 12.78488 learning_Rate = 0.01000 rmse=1.07238 mae=0.82477\n","current best rmse is 1.07238, mae is 0.82477\n","\u003cclass '__main__.TrustSVD'\u003e iteration 1: loss = 124952.5373, delta_loss = -124952.53734 learning_Rate = 0.01000 rmse=1.40986 mae=1.01980\n","\u003cclass '__main__.TrustSVD'\u003e iteration 2: loss = 57240.2942, delta_loss = 67712.24310 learning_Rate = 0.01000 rmse=1.30435 mae=0.96715\n","\u003cclass '__main__.TrustSVD'\u003e iteration 3: loss = 40205.8457, delta_loss = 17034.44851 learning_Rate = 0.01000 rmse=1.23721 mae=0.92876\n","\u003cclass '__main__.TrustSVD'\u003e iteration 4: loss = 36076.2364, delta_loss = 4129.60929 learning_Rate = 0.01000 rmse=1.20561 mae=0.90848\n","\u003cclass '__main__.TrustSVD'\u003e iteration 5: loss = 33730.9853, delta_loss = 2345.25113 learning_Rate = 0.01000 rmse=1.18603 mae=0.89617\n","\u003cclass '__main__.TrustSVD'\u003e iteration 6: loss = 32073.1728, delta_loss = 1657.81252 learning_Rate = 0.01000 rmse=1.17232 mae=0.88768\n","\u003cclass '__main__.TrustSVD'\u003e iteration 7: loss = 30800.2248, delta_loss = 1272.94804 learning_Rate = 0.01000 rmse=1.16242 mae=0.88154\n","\u003cclass '__main__.TrustSVD'\u003e iteration 8: loss = 29773.7054, delta_loss = 1026.51933 learning_Rate = 0.01000 rmse=1.15462 mae=0.87662\n","\u003cclass '__main__.TrustSVD'\u003e iteration 9: loss = 28917.6955, delta_loss = 856.00989 learning_Rate = 0.01000 rmse=1.14826 mae=0.87249\n","\u003cclass '__main__.TrustSVD'\u003e iteration 10: loss = 28186.5477, delta_loss = 731.14787 learning_Rate = 0.01000 rmse=1.14289 mae=0.86877\n","\u003cclass '__main__.TrustSVD'\u003e iteration 11: loss = 27550.8757, delta_loss = 635.67192 learning_Rate = 0.01000 rmse=1.13813 mae=0.86535\n","\u003cclass '__main__.TrustSVD'\u003e iteration 12: loss = 26990.5975, delta_loss = 560.27825 learning_Rate = 0.01000 rmse=1.13402 mae=0.86231\n","\u003cclass '__main__.TrustSVD'\u003e iteration 13: loss = 26491.3059, delta_loss = 499.29161 learning_Rate = 0.01000 rmse=1.13047 mae=0.85972\n","\u003cclass '__main__.TrustSVD'\u003e iteration 14: loss = 26042.2849, delta_loss = 449.02099 learning_Rate = 0.01000 rmse=1.12727 mae=0.85739\n","\u003cclass '__main__.TrustSVD'\u003e iteration 15: loss = 25635.3531, delta_loss = 406.93177 learning_Rate = 0.01000 rmse=1.12437 mae=0.85525\n","\u003cclass '__main__.TrustSVD'\u003e iteration 16: loss = 25264.1437, delta_loss = 371.20943 learning_Rate = 0.01000 rmse=1.12180 mae=0.85334\n","\u003cclass '__main__.TrustSVD'\u003e iteration 17: loss = 24923.6294, delta_loss = 340.51429 learning_Rate = 0.01000 rmse=1.11949 mae=0.85158\n","\u003cclass '__main__.TrustSVD'\u003e iteration 18: loss = 24609.7941, delta_loss = 313.83526 learning_Rate = 0.01000 rmse=1.11740 mae=0.85001\n","\u003cclass '__main__.TrustSVD'\u003e iteration 19: loss = 24319.3951, delta_loss = 290.39902 learning_Rate = 0.01000 rmse=1.11553 mae=0.84864\n","\u003cclass '__main__.TrustSVD'\u003e iteration 20: loss = 24049.7837, delta_loss = 269.61144 learning_Rate = 0.01000 rmse=1.11388 mae=0.84739\n","\u003cclass '__main__.TrustSVD'\u003e iteration 21: loss = 23798.7665, delta_loss = 251.01722 learning_Rate = 0.01000 rmse=1.11239 mae=0.84622\n","\u003cclass '__main__.TrustSVD'\u003e iteration 22: loss = 23564.4974, delta_loss = 234.26904 learning_Rate = 0.01000 rmse=1.11101 mae=0.84515\n","\u003cclass '__main__.TrustSVD'\u003e iteration 23: loss = 23345.3958, delta_loss = 219.10161 learning_Rate = 0.01000 rmse=1.10975 mae=0.84414\n","\u003cclass '__main__.TrustSVD'\u003e iteration 24: loss = 23140.0864, delta_loss = 205.30944 learning_Rate = 0.01000 rmse=1.10861 mae=0.84322\n","\u003cclass '__main__.TrustSVD'\u003e iteration 25: loss = 22947.3575, delta_loss = 192.72885 learning_Rate = 0.01000 rmse=1.10756 mae=0.84240\n","\u003cclass '__main__.TrustSVD'\u003e iteration 26: loss = 22766.1328, delta_loss = 181.22468 learning_Rate = 0.01000 rmse=1.10660 mae=0.84162\n","\u003cclass '__main__.TrustSVD'\u003e iteration 27: loss = 22595.4513, delta_loss = 170.68154 learning_Rate = 0.01000 rmse=1.10571 mae=0.84091\n","\u003cclass '__main__.TrustSVD'\u003e iteration 28: loss = 22434.4527, delta_loss = 160.99860 learning_Rate = 0.01000 rmse=1.10489 mae=0.84025\n","\u003cclass '__main__.TrustSVD'\u003e iteration 29: loss = 22282.3660, delta_loss = 152.08669 learning_Rate = 0.01000 rmse=1.10413 mae=0.83963\n","\u003cclass '__main__.TrustSVD'\u003e iteration 30: loss = 22138.4994, delta_loss = 143.86662 learning_Rate = 0.01000 rmse=1.10342 mae=0.83904\n","\u003cclass '__main__.TrustSVD'\u003e iteration 31: loss = 22002.2313, delta_loss = 136.26809 learning_Rate = 0.01000 rmse=1.10277 mae=0.83847\n","\u003cclass '__main__.TrustSVD'\u003e iteration 32: loss = 21873.0025, delta_loss = 129.22881 learning_Rate = 0.01000 rmse=1.10217 mae=0.83796\n","\u003cclass '__main__.TrustSVD'\u003e iteration 33: loss = 21750.3088, delta_loss = 122.69373 learning_Rate = 0.01000 rmse=1.10162 mae=0.83749\n","\u003cclass '__main__.TrustSVD'\u003e iteration 34: loss = 21633.6946, delta_loss = 116.61420 learning_Rate = 0.01000 rmse=1.10110 mae=0.83706\n","\u003cclass '__main__.TrustSVD'\u003e iteration 35: loss = 21522.7472, delta_loss = 110.94732 learning_Rate = 0.01000 rmse=1.10062 mae=0.83665\n","\u003cclass '__main__.TrustSVD'\u003e iteration 36: loss = 21417.0921, delta_loss = 105.65515 learning_Rate = 0.01000 rmse=1.10015 mae=0.83624\n","\u003cclass '__main__.TrustSVD'\u003e iteration 37: loss = 21316.3879, delta_loss = 100.70417 learning_Rate = 0.01000 rmse=1.09972 mae=0.83585\n","\u003cclass '__main__.TrustSVD'\u003e iteration 38: loss = 21220.3232, delta_loss = 96.06467 learning_Rate = 0.01000 rmse=1.09931 mae=0.83549\n","\u003cclass '__main__.TrustSVD'\u003e iteration 39: loss = 21128.6130, delta_loss = 91.71026 learning_Rate = 0.01000 rmse=1.09894 mae=0.83516\n","\u003cclass '__main__.TrustSVD'\u003e iteration 40: loss = 21040.9956, delta_loss = 87.61744 learning_Rate = 0.01000 rmse=1.09858 mae=0.83485\n","\u003cclass '__main__.TrustSVD'\u003e iteration 41: loss = 20957.2303, delta_loss = 83.76525 learning_Rate = 0.01000 rmse=1.09824 mae=0.83455\n","\u003cclass '__main__.TrustSVD'\u003e iteration 42: loss = 20877.0954, delta_loss = 80.13491 learning_Rate = 0.01000 rmse=1.09793 mae=0.83428\n","\u003cclass '__main__.TrustSVD'\u003e iteration 43: loss = 20800.3858, delta_loss = 76.70958 learning_Rate = 0.01000 rmse=1.09763 mae=0.83400\n","\u003cclass '__main__.TrustSVD'\u003e iteration 44: loss = 20726.9117, delta_loss = 73.47408 learning_Rate = 0.01000 rmse=1.09734 mae=0.83372\n","\u003cclass '__main__.TrustSVD'\u003e iteration 45: loss = 20656.4970, delta_loss = 70.41472 learning_Rate = 0.01000 rmse=1.09707 mae=0.83348\n","\u003cclass '__main__.TrustSVD'\u003e iteration 46: loss = 20588.9779, delta_loss = 67.51910 learning_Rate = 0.01000 rmse=1.09682 mae=0.83324\n","\u003cclass '__main__.TrustSVD'\u003e iteration 47: loss = 20524.2019, delta_loss = 64.77596 learning_Rate = 0.01000 rmse=1.09658 mae=0.83301\n","\u003cclass '__main__.TrustSVD'\u003e iteration 48: loss = 20462.0269, delta_loss = 62.17506 learning_Rate = 0.01000 rmse=1.09635 mae=0.83280\n","\u003cclass '__main__.TrustSVD'\u003e iteration 49: loss = 20402.3198, delta_loss = 59.70706 learning_Rate = 0.01000 rmse=1.09614 mae=0.83258\n","\u003cclass '__main__.TrustSVD'\u003e iteration 50: loss = 20344.9564, delta_loss = 57.36340 learning_Rate = 0.01000 rmse=1.09592 mae=0.83238\n","\u003cclass '__main__.TrustSVD'\u003e iteration 51: loss = 20289.8202, delta_loss = 55.13624 learning_Rate = 0.01000 rmse=1.09572 mae=0.83218\n","\u003cclass '__main__.TrustSVD'\u003e iteration 52: loss = 20236.8018, delta_loss = 53.01839 learning_Rate = 0.01000 rmse=1.09553 mae=0.83199\n","\u003cclass '__main__.TrustSVD'\u003e iteration 53: loss = 20185.7986, delta_loss = 51.00321 learning_Rate = 0.01000 rmse=1.09535 mae=0.83182\n","\u003cclass '__main__.TrustSVD'\u003e iteration 54: loss = 20136.7140, delta_loss = 49.08458 learning_Rate = 0.01000 rmse=1.09518 mae=0.83164\n","\u003cclass '__main__.TrustSVD'\u003e iteration 55: loss = 20089.4572, delta_loss = 47.25684 learning_Rate = 0.01000 rmse=1.09503 mae=0.83148\n","\u003cclass '__main__.TrustSVD'\u003e iteration 56: loss = 20043.9424, delta_loss = 45.51476 learning_Rate = 0.01000 rmse=1.09487 mae=0.83132\n","\u003cclass '__main__.TrustSVD'\u003e iteration 57: loss = 20000.0889, delta_loss = 43.85348 learning_Rate = 0.01000 rmse=1.09473 mae=0.83117\n","\u003cclass '__main__.TrustSVD'\u003e iteration 58: loss = 19957.8204, delta_loss = 42.26847 learning_Rate = 0.01000 rmse=1.09459 mae=0.83103\n","\u003cclass '__main__.TrustSVD'\u003e iteration 59: loss = 19917.0649, delta_loss = 40.75555 learning_Rate = 0.01000 rmse=1.09446 mae=0.83090\n","\u003cclass '__main__.TrustSVD'\u003e iteration 60: loss = 19877.7541, delta_loss = 39.31078 learning_Rate = 0.01000 rmse=1.09433 mae=0.83078\n","\u003cclass '__main__.TrustSVD'\u003e iteration 61: loss = 19839.8236, delta_loss = 37.93053 learning_Rate = 0.01000 rmse=1.09420 mae=0.83066\n","\u003cclass '__main__.TrustSVD'\u003e iteration 62: loss = 19803.2122, delta_loss = 36.61138 learning_Rate = 0.01000 rmse=1.09408 mae=0.83054\n","\u003cclass '__main__.TrustSVD'\u003e iteration 63: loss = 19767.8621, delta_loss = 35.35013 learning_Rate = 0.01000 rmse=1.09397 mae=0.83044\n","\u003cclass '__main__.TrustSVD'\u003e iteration 64: loss = 19733.7183, delta_loss = 34.14380 learning_Rate = 0.01000 rmse=1.09386 mae=0.83034\n","\u003cclass '__main__.TrustSVD'\u003e iteration 65: loss = 19700.7287, delta_loss = 32.98958 learning_Rate = 0.01000 rmse=1.09375 mae=0.83025\n","\u003cclass '__main__.TrustSVD'\u003e iteration 66: loss = 19668.8438, delta_loss = 31.88485 learning_Rate = 0.01000 rmse=1.09365 mae=0.83015\n","\u003cclass '__main__.TrustSVD'\u003e iteration 67: loss = 19638.0167, delta_loss = 30.82713 learning_Rate = 0.01000 rmse=1.09356 mae=0.83007\n","\u003cclass '__main__.TrustSVD'\u003e iteration 68: loss = 19608.2026, delta_loss = 29.81410 learning_Rate = 0.01000 rmse=1.09346 mae=0.82997\n","\u003cclass '__main__.TrustSVD'\u003e iteration 69: loss = 19579.3590, delta_loss = 28.84358 learning_Rate = 0.01000 rmse=1.09336 mae=0.82987\n","\u003cclass '__main__.TrustSVD'\u003e iteration 70: loss = 19551.4455, delta_loss = 27.91350 learning_Rate = 0.01000 rmse=1.09327 mae=0.82979\n","\u003cclass '__main__.TrustSVD'\u003e iteration 71: loss = 19524.4236, delta_loss = 27.02192 learning_Rate = 0.01000 rmse=1.09319 mae=0.82970\n","\u003cclass '__main__.TrustSVD'\u003e iteration 72: loss = 19498.2566, delta_loss = 26.16701 learning_Rate = 0.01000 rmse=1.09310 mae=0.82962\n","\u003cclass '__main__.TrustSVD'\u003e iteration 73: loss = 19472.9096, delta_loss = 25.34704 learning_Rate = 0.01000 rmse=1.09302 mae=0.82953\n","\u003cclass '__main__.TrustSVD'\u003e iteration 74: loss = 19448.3492, delta_loss = 24.56038 learning_Rate = 0.01000 rmse=1.09295 mae=0.82945\n","\u003cclass '__main__.TrustSVD'\u003e iteration 75: loss = 19424.5437, delta_loss = 23.80547 learning_Rate = 0.01000 rmse=1.09287 mae=0.82936\n","\u003cclass '__main__.TrustSVD'\u003e iteration 76: loss = 19401.4629, delta_loss = 23.08085 learning_Rate = 0.01000 rmse=1.09280 mae=0.82928\n","\u003cclass '__main__.TrustSVD'\u003e iteration 77: loss = 19379.0777, delta_loss = 22.38514 learning_Rate = 0.01000 rmse=1.09272 mae=0.82920\n","\u003cclass '__main__.TrustSVD'\u003e iteration 78: loss = 19357.3607, delta_loss = 21.71702 learning_Rate = 0.01000 rmse=1.09266 mae=0.82913\n","\u003cclass '__main__.TrustSVD'\u003e iteration 79: loss = 19336.2855, delta_loss = 21.07525 learning_Rate = 0.01000 rmse=1.09259 mae=0.82905\n","\u003cclass '__main__.TrustSVD'\u003e iteration 80: loss = 19315.8268, delta_loss = 20.45864 learning_Rate = 0.01000 rmse=1.09252 mae=0.82897\n","\u003cclass '__main__.TrustSVD'\u003e iteration 81: loss = 19295.9607, delta_loss = 19.86607 learning_Rate = 0.01000 rmse=1.09245 mae=0.82890\n","\u003cclass '__main__.TrustSVD'\u003e iteration 82: loss = 19276.6643, delta_loss = 19.29648 learning_Rate = 0.01000 rmse=1.09238 mae=0.82883\n","\u003cclass '__main__.TrustSVD'\u003e iteration 83: loss = 19257.9154, delta_loss = 18.74884 learning_Rate = 0.01000 rmse=1.09232 mae=0.82876\n","\u003cclass '__main__.TrustSVD'\u003e iteration 84: loss = 19239.6932, delta_loss = 18.22220 learning_Rate = 0.01000 rmse=1.09225 mae=0.82869\n","\u003cclass '__main__.TrustSVD'\u003e iteration 85: loss = 19221.9776, delta_loss = 17.71564 learning_Rate = 0.01000 rmse=1.09219 mae=0.82862\n","\u003cclass '__main__.TrustSVD'\u003e iteration 86: loss = 19204.7493, delta_loss = 17.22829 learning_Rate = 0.01000 rmse=1.09213 mae=0.82855\n","\u003cclass '__main__.TrustSVD'\u003e iteration 87: loss = 19187.9900, delta_loss = 16.75932 learning_Rate = 0.01000 rmse=1.09207 mae=0.82849\n","\u003cclass '__main__.TrustSVD'\u003e iteration 88: loss = 19171.6820, delta_loss = 16.30793 learning_Rate = 0.01000 rmse=1.09201 mae=0.82842\n","\u003cclass '__main__.TrustSVD'\u003e iteration 89: loss = 19155.8087, delta_loss = 15.87337 learning_Rate = 0.01000 rmse=1.09195 mae=0.82836\n","\u003cclass '__main__.TrustSVD'\u003e iteration 90: loss = 19140.3537, delta_loss = 15.45492 learning_Rate = 0.01000 rmse=1.09189 mae=0.82830\n","\u003cclass '__main__.TrustSVD'\u003e iteration 91: loss = 19125.3018, delta_loss = 15.05190 learning_Rate = 0.01000 rmse=1.09184 mae=0.82824\n","\u003cclass '__main__.TrustSVD'\u003e iteration 92: loss = 19110.6382, delta_loss = 14.66366 learning_Rate = 0.01000 rmse=1.09178 mae=0.82818\n","\u003cclass '__main__.TrustSVD'\u003e iteration 93: loss = 19096.3486, delta_loss = 14.28957 learning_Rate = 0.01000 rmse=1.09172 mae=0.82811\n","\u003cclass '__main__.TrustSVD'\u003e iteration 94: loss = 19082.4196, delta_loss = 13.92904 learning_Rate = 0.01000 rmse=1.09167 mae=0.82805\n","\u003cclass '__main__.TrustSVD'\u003e iteration 95: loss = 19068.8381, delta_loss = 13.58150 learning_Rate = 0.01000 rmse=1.09162 mae=0.82800\n","\u003cclass '__main__.TrustSVD'\u003e iteration 96: loss = 19055.5917, delta_loss = 13.24640 learning_Rate = 0.01000 rmse=1.09157 mae=0.82794\n","\u003cclass '__main__.TrustSVD'\u003e iteration 97: loss = 19042.6684, delta_loss = 12.92324 learning_Rate = 0.01000 rmse=1.09152 mae=0.82789\n","\u003cclass '__main__.TrustSVD'\u003e iteration 98: loss = 19030.0569, delta_loss = 12.61151 learning_Rate = 0.01000 rmse=1.09147 mae=0.82784\n","\u003cclass '__main__.TrustSVD'\u003e iteration 99: loss = 19017.7462, delta_loss = 12.31075 learning_Rate = 0.01000 rmse=1.09142 mae=0.82778\n","\u003cclass '__main__.TrustSVD'\u003e iteration 100: loss = 19005.7257, delta_loss = 12.02050 learning_Rate = 0.01000 rmse=1.09137 mae=0.82773\n","current best rmse is 1.09137, mae is 0.82773\n","\u003cclass '__main__.TrustSVD'\u003e iteration 1: loss = 126481.8226, delta_loss = -126481.82258 learning_Rate = 0.01000 rmse=1.38820 mae=1.01972\n","\u003cclass '__main__.TrustSVD'\u003e iteration 2: loss = 57955.1460, delta_loss = 68526.67659 learning_Rate = 0.01000 rmse=1.27214 mae=0.96166\n","\u003cclass '__main__.TrustSVD'\u003e iteration 3: loss = 40410.5571, delta_loss = 17544.58886 learning_Rate = 0.01000 rmse=1.19724 mae=0.91805\n","\u003cclass '__main__.TrustSVD'\u003e iteration 4: loss = 36135.9373, delta_loss = 4274.61984 learning_Rate = 0.01000 rmse=1.16058 mae=0.89474\n","\u003cclass '__main__.TrustSVD'\u003e iteration 5: loss = 33768.5846, delta_loss = 2367.35270 learning_Rate = 0.01000 rmse=1.14028 mae=0.88200\n","\u003cclass '__main__.TrustSVD'\u003e iteration 6: loss = 32101.8165, delta_loss = 1666.76812 learning_Rate = 0.01000 rmse=1.12730 mae=0.87425\n","\u003cclass '__main__.TrustSVD'\u003e iteration 7: loss = 30822.6674, delta_loss = 1279.14912 learning_Rate = 0.01000 rmse=1.11772 mae=0.86857\n","\u003cclass '__main__.TrustSVD'\u003e iteration 8: loss = 29791.1432, delta_loss = 1031.52413 learning_Rate = 0.01000 rmse=1.10993 mae=0.86389\n","\u003cclass '__main__.TrustSVD'\u003e iteration 9: loss = 28931.4107, delta_loss = 859.73254 learning_Rate = 0.01000 rmse=1.10338 mae=0.86012\n","\u003cclass '__main__.TrustSVD'\u003e iteration 10: loss = 28197.6918, delta_loss = 733.71890 learning_Rate = 0.01000 rmse=1.09782 mae=0.85687\n","\u003cclass '__main__.TrustSVD'\u003e iteration 11: loss = 27560.2660, delta_loss = 637.42577 learning_Rate = 0.01000 rmse=1.09306 mae=0.85394\n","\u003cclass '__main__.TrustSVD'\u003e iteration 12: loss = 26998.7526, delta_loss = 561.51343 learning_Rate = 0.01000 rmse=1.08894 mae=0.85121\n","\u003cclass '__main__.TrustSVD'\u003e iteration 13: loss = 26498.5688, delta_loss = 500.18378 learning_Rate = 0.01000 rmse=1.08533 mae=0.84872\n","\u003cclass '__main__.TrustSVD'\u003e iteration 14: loss = 26048.9325, delta_loss = 449.63625 learning_Rate = 0.01000 rmse=1.08221 mae=0.84650\n","\u003cclass '__main__.TrustSVD'\u003e iteration 15: loss = 25641.6657, delta_loss = 407.26685 learning_Rate = 0.01000 rmse=1.07947 mae=0.84457\n","\u003cclass '__main__.TrustSVD'\u003e iteration 16: loss = 25270.4349, delta_loss = 371.23084 learning_Rate = 0.01000 rmse=1.07692 mae=0.84279\n","\u003cclass '__main__.TrustSVD'\u003e iteration 17: loss = 24930.2449, delta_loss = 340.19000 learning_Rate = 0.01000 rmse=1.07460 mae=0.84116\n","\u003cclass '__main__.TrustSVD'\u003e iteration 18: loss = 24617.0877, delta_loss = 313.15721 learning_Rate = 0.01000 rmse=1.07253 mae=0.83970\n","\u003cclass '__main__.TrustSVD'\u003e iteration 19: loss = 24327.6933, delta_loss = 289.39433 learning_Rate = 0.01000 rmse=1.07066 mae=0.83835\n","\u003cclass '__main__.TrustSVD'\u003e iteration 20: loss = 24059.3517, delta_loss = 268.34166 learning_Rate = 0.01000 rmse=1.06898 mae=0.83706\n","\u003cclass '__main__.TrustSVD'\u003e iteration 21: loss = 23809.7839, delta_loss = 249.56772 learning_Rate = 0.01000 rmse=1.06746 mae=0.83587\n","\u003cclass '__main__.TrustSVD'\u003e iteration 22: loss = 23577.0505, delta_loss = 232.73344 learning_Rate = 0.01000 rmse=1.06607 mae=0.83475\n","\u003cclass '__main__.TrustSVD'\u003e iteration 23: loss = 23359.4837, delta_loss = 217.56684 learning_Rate = 0.01000 rmse=1.06481 mae=0.83368\n","\u003cclass '__main__.TrustSVD'\u003e iteration 24: loss = 23155.6381, delta_loss = 203.84558 learning_Rate = 0.01000 rmse=1.06357 mae=0.83264\n","\u003cclass '__main__.TrustSVD'\u003e iteration 25: loss = 22964.2532, delta_loss = 191.38490 learning_Rate = 0.01000 rmse=1.06242 mae=0.83169\n","\u003cclass '__main__.TrustSVD'\u003e iteration 26: loss = 22784.2238, delta_loss = 180.02936 learning_Rate = 0.01000 rmse=1.06139 mae=0.83083\n","\u003cclass '__main__.TrustSVD'\u003e iteration 27: loss = 22614.5768, delta_loss = 169.64698 learning_Rate = 0.01000 rmse=1.06042 mae=0.83003\n","\u003cclass '__main__.TrustSVD'\u003e iteration 28: loss = 22454.4519, delta_loss = 160.12499 learning_Rate = 0.01000 rmse=1.05952 mae=0.82927\n","\u003cclass '__main__.TrustSVD'\u003e iteration 29: loss = 22303.0853, delta_loss = 151.36656 learning_Rate = 0.01000 rmse=1.05868 mae=0.82855\n","\u003cclass '__main__.TrustSVD'\u003e iteration 30: loss = 22159.7971, delta_loss = 143.28823 learning_Rate = 0.01000 rmse=1.05791 mae=0.82788\n","\u003cclass '__main__.TrustSVD'\u003e iteration 31: loss = 22023.9793, delta_loss = 135.81782 learning_Rate = 0.01000 rmse=1.05720 mae=0.82725\n","\u003cclass '__main__.TrustSVD'\u003e iteration 32: loss = 21895.0865, delta_loss = 128.89273 learning_Rate = 0.01000 rmse=1.05654 mae=0.82664\n","\u003cclass '__main__.TrustSVD'\u003e iteration 33: loss = 21772.6281, delta_loss = 122.45842 learning_Rate = 0.01000 rmse=1.05593 mae=0.82607\n","\u003cclass '__main__.TrustSVD'\u003e iteration 34: loss = 21656.1608, delta_loss = 116.46731 learning_Rate = 0.01000 rmse=1.05536 mae=0.82552\n","\u003cclass '__main__.TrustSVD'\u003e iteration 35: loss = 21545.2831, delta_loss = 110.87766 learning_Rate = 0.01000 rmse=1.05481 mae=0.82498\n","\u003cclass '__main__.TrustSVD'\u003e iteration 36: loss = 21439.6303, delta_loss = 105.65280 learning_Rate = 0.01000 rmse=1.05429 mae=0.82447\n","\u003cclass '__main__.TrustSVD'\u003e iteration 37: loss = 21338.8700, delta_loss = 100.76037 learning_Rate = 0.01000 rmse=1.05381 mae=0.82400\n","\u003cclass '__main__.TrustSVD'\u003e iteration 38: loss = 21242.6983, delta_loss = 96.17171 learning_Rate = 0.01000 rmse=1.05336 mae=0.82354\n","\u003cclass '__main__.TrustSVD'\u003e iteration 39: loss = 21150.8369, delta_loss = 91.86140 learning_Rate = 0.01000 rmse=1.05294 mae=0.82311\n","\u003cclass '__main__.TrustSVD'\u003e iteration 40: loss = 21063.0301, delta_loss = 87.80674 learning_Rate = 0.01000 rmse=1.05254 mae=0.82269\n","\u003cclass '__main__.TrustSVD'\u003e iteration 41: loss = 20979.0426, delta_loss = 83.98750 learning_Rate = 0.01000 rmse=1.05216 mae=0.82230\n","\u003cclass '__main__.TrustSVD'\u003e iteration 42: loss = 20898.6571, delta_loss = 80.38549 learning_Rate = 0.01000 rmse=1.05179 mae=0.82193\n","\u003cclass '__main__.TrustSVD'\u003e iteration 43: loss = 20821.6727, delta_loss = 76.98439 learning_Rate = 0.01000 rmse=1.05146 mae=0.82158\n","\u003cclass '__main__.TrustSVD'\u003e iteration 44: loss = 20747.9033, delta_loss = 73.76948 learning_Rate = 0.01000 rmse=1.05114 mae=0.82125\n","\u003cclass '__main__.TrustSVD'\u003e iteration 45: loss = 20677.1758, delta_loss = 70.72745 learning_Rate = 0.01000 rmse=1.05083 mae=0.82092\n","\u003cclass '__main__.TrustSVD'\u003e iteration 46: loss = 20609.3296, delta_loss = 67.84623 learning_Rate = 0.01000 rmse=1.05053 mae=0.82061\n","\u003cclass '__main__.TrustSVD'\u003e iteration 47: loss = 20544.2147, delta_loss = 65.11486 learning_Rate = 0.01000 rmse=1.05026 mae=0.82030\n","\u003cclass '__main__.TrustSVD'\u003e iteration 48: loss = 20481.6914, delta_loss = 62.52336 learning_Rate = 0.01000 rmse=1.05000 mae=0.82001\n","\u003cclass '__main__.TrustSVD'\u003e iteration 49: loss = 20421.6288, delta_loss = 60.06260 learning_Rate = 0.01000 rmse=1.04975 mae=0.81972\n","\u003cclass '__main__.TrustSVD'\u003e iteration 50: loss = 20363.9045, delta_loss = 57.72425 learning_Rate = 0.01000 rmse=1.04952 mae=0.81946\n","\u003cclass '__main__.TrustSVD'\u003e iteration 51: loss = 20308.4039, delta_loss = 55.50065 learning_Rate = 0.01000 rmse=1.04930 mae=0.81921\n","\u003cclass '__main__.TrustSVD'\u003e iteration 52: loss = 20255.0191, delta_loss = 53.38477 learning_Rate = 0.01000 rmse=1.04909 mae=0.81897\n","\u003cclass '__main__.TrustSVD'\u003e iteration 53: loss = 20203.6489, delta_loss = 51.37015 learning_Rate = 0.01000 rmse=1.04889 mae=0.81873\n","\u003cclass '__main__.TrustSVD'\u003e iteration 54: loss = 20154.1981, delta_loss = 49.45081 learning_Rate = 0.01000 rmse=1.04869 mae=0.81852\n","\u003cclass '__main__.TrustSVD'\u003e iteration 55: loss = 20106.5769, delta_loss = 47.62123 learning_Rate = 0.01000 rmse=1.04851 mae=0.81831\n","\u003cclass '__main__.TrustSVD'\u003e iteration 56: loss = 20060.7006, delta_loss = 45.87629 learning_Rate = 0.01000 rmse=1.04832 mae=0.81811\n","\u003cclass '__main__.TrustSVD'\u003e iteration 57: loss = 20016.4893, delta_loss = 44.21127 learning_Rate = 0.01000 rmse=1.04815 mae=0.81793\n","\u003cclass '__main__.TrustSVD'\u003e iteration 58: loss = 19973.8676, delta_loss = 42.62175 learning_Rate = 0.01000 rmse=1.04799 mae=0.81775\n","\u003cclass '__main__.TrustSVD'\u003e iteration 59: loss = 19932.7639, delta_loss = 41.10364 learning_Rate = 0.01000 rmse=1.04783 mae=0.81759\n","\u003cclass '__main__.TrustSVD'\u003e iteration 60: loss = 19893.1108, delta_loss = 39.65311 learning_Rate = 0.01000 rmse=1.04769 mae=0.81744\n","\u003cclass '__main__.TrustSVD'\u003e iteration 61: loss = 19854.8442, delta_loss = 38.26660 learning_Rate = 0.01000 rmse=1.04754 mae=0.81729\n","\u003cclass '__main__.TrustSVD'\u003e iteration 62: loss = 19817.9035, delta_loss = 36.94078 learning_Rate = 0.01000 rmse=1.04741 mae=0.81716\n","\u003cclass '__main__.TrustSVD'\u003e iteration 63: loss = 19782.2309, delta_loss = 35.67253 learning_Rate = 0.01000 rmse=1.04728 mae=0.81703\n","\u003cclass '__main__.TrustSVD'\u003e iteration 64: loss = 19747.7720, delta_loss = 34.45892 learning_Rate = 0.01000 rmse=1.04716 mae=0.81691\n","\u003cclass '__main__.TrustSVD'\u003e iteration 65: loss = 19714.4748, delta_loss = 33.29722 learning_Rate = 0.01000 rmse=1.04705 mae=0.81679\n","\u003cclass '__main__.TrustSVD'\u003e iteration 66: loss = 19682.2899, delta_loss = 32.18485 learning_Rate = 0.01000 rmse=1.04694 mae=0.81668\n","\u003cclass '__main__.TrustSVD'\u003e iteration 67: loss = 19651.1706, delta_loss = 31.11938 learning_Rate = 0.01000 rmse=1.04684 mae=0.81657\n","\u003cclass '__main__.TrustSVD'\u003e iteration 68: loss = 19621.0720, delta_loss = 30.09854 learning_Rate = 0.01000 rmse=1.04675 mae=0.81647\n","\u003cclass '__main__.TrustSVD'\u003e iteration 69: loss = 19591.9518, delta_loss = 29.12018 learning_Rate = 0.01000 rmse=1.04666 mae=0.81637\n","\u003cclass '__main__.TrustSVD'\u003e iteration 70: loss = 19563.7696, delta_loss = 28.18226 learning_Rate = 0.01000 rmse=1.04657 mae=0.81628\n","\u003cclass '__main__.TrustSVD'\u003e iteration 71: loss = 19536.4867, delta_loss = 27.28288 learning_Rate = 0.01000 rmse=1.04648 mae=0.81618\n","\u003cclass '__main__.TrustSVD'\u003e iteration 72: loss = 19510.0665, delta_loss = 26.42023 learning_Rate = 0.01000 rmse=1.04640 mae=0.81609\n","\u003cclass '__main__.TrustSVD'\u003e iteration 73: loss = 19484.4739, delta_loss = 25.59259 learning_Rate = 0.01000 rmse=1.04632 mae=0.81600\n","\u003cclass '__main__.TrustSVD'\u003e iteration 74: loss = 19459.6755, delta_loss = 24.79835 learning_Rate = 0.01000 rmse=1.04625 mae=0.81592\n","\u003cclass '__main__.TrustSVD'\u003e iteration 75: loss = 19435.6396, delta_loss = 24.03598 learning_Rate = 0.01000 rmse=1.04617 mae=0.81583\n","\u003cclass '__main__.TrustSVD'\u003e iteration 76: loss = 19412.3355, delta_loss = 23.30403 learning_Rate = 0.01000 rmse=1.04610 mae=0.81575\n","\u003cclass '__main__.TrustSVD'\u003e iteration 77: loss = 19389.7344, delta_loss = 22.60111 learning_Rate = 0.01000 rmse=1.04603 mae=0.81566\n","\u003cclass '__main__.TrustSVD'\u003e iteration 78: loss = 19367.8085, delta_loss = 21.92593 learning_Rate = 0.01000 rmse=1.04597 mae=0.81559\n","\u003cclass '__main__.TrustSVD'\u003e iteration 79: loss = 19346.5313, delta_loss = 21.27723 learning_Rate = 0.01000 rmse=1.04591 mae=0.81552\n","\u003cclass '__main__.TrustSVD'\u003e iteration 80: loss = 19325.8774, delta_loss = 20.65386 learning_Rate = 0.01000 rmse=1.04584 mae=0.81545\n","\u003cclass '__main__.TrustSVD'\u003e iteration 81: loss = 19305.8227, delta_loss = 20.05467 learning_Rate = 0.01000 rmse=1.04578 mae=0.81538\n","\u003cclass '__main__.TrustSVD'\u003e iteration 82: loss = 19286.3441, delta_loss = 19.47862 learning_Rate = 0.01000 rmse=1.04572 mae=0.81531\n","\u003cclass '__main__.TrustSVD'\u003e iteration 83: loss = 19267.4194, delta_loss = 18.92469 learning_Rate = 0.01000 rmse=1.04567 mae=0.81526\n","\u003cclass '__main__.TrustSVD'\u003e iteration 84: loss = 19249.0275, delta_loss = 18.39191 learning_Rate = 0.01000 rmse=1.04563 mae=0.81520\n","\u003cclass '__main__.TrustSVD'\u003e iteration 85: loss = 19231.1481, delta_loss = 17.87938 learning_Rate = 0.01000 rmse=1.04558 mae=0.81515\n","\u003cclass '__main__.TrustSVD'\u003e iteration 86: loss = 19213.7619, delta_loss = 17.38621 learning_Rate = 0.01000 rmse=1.04553 mae=0.81510\n","\u003cclass '__main__.TrustSVD'\u003e iteration 87: loss = 19196.8503, delta_loss = 16.91158 learning_Rate = 0.01000 rmse=1.04549 mae=0.81505\n","\u003cclass '__main__.TrustSVD'\u003e iteration 88: loss = 19180.3956, delta_loss = 16.45469 learning_Rate = 0.01000 rmse=1.04546 mae=0.81500\n","\u003cclass '__main__.TrustSVD'\u003e iteration 89: loss = 19164.3809, delta_loss = 16.01479 learning_Rate = 0.01000 rmse=1.04542 mae=0.81496\n","\u003cclass '__main__.TrustSVD'\u003e iteration 90: loss = 19148.7897, delta_loss = 15.59117 learning_Rate = 0.01000 rmse=1.04538 mae=0.81492\n","\u003cclass '__main__.TrustSVD'\u003e iteration 91: loss = 19133.6066, delta_loss = 15.18312 learning_Rate = 0.01000 rmse=1.04535 mae=0.81488\n","\u003cclass '__main__.TrustSVD'\u003e iteration 92: loss = 19118.8166, delta_loss = 14.79000 learning_Rate = 0.01000 rmse=1.04531 mae=0.81484\n","\u003cclass '__main__.TrustSVD'\u003e iteration 93: loss = 19104.4054, delta_loss = 14.41119 learning_Rate = 0.01000 rmse=1.04528 mae=0.81481\n","\u003cclass '__main__.TrustSVD'\u003e iteration 94: loss = 19090.3593, delta_loss = 14.04608 learning_Rate = 0.01000 rmse=1.04526 mae=0.81478\n","\u003cclass '__main__.TrustSVD'\u003e iteration 95: loss = 19076.6652, delta_loss = 13.69411 learning_Rate = 0.01000 rmse=1.04523 mae=0.81475\n","\u003cclass '__main__.TrustSVD'\u003e iteration 96: loss = 19063.3105, delta_loss = 13.35473 learning_Rate = 0.01000 rmse=1.04521 mae=0.81472\n","\u003cclass '__main__.TrustSVD'\u003e iteration 97: loss = 19050.2830, delta_loss = 13.02743 learning_Rate = 0.01000 rmse=1.04518 mae=0.81469\n","\u003cclass '__main__.TrustSVD'\u003e iteration 98: loss = 19037.5713, delta_loss = 12.71170 learning_Rate = 0.01000 rmse=1.04516 mae=0.81466\n","\u003cclass '__main__.TrustSVD'\u003e iteration 99: loss = 19025.1643, delta_loss = 12.40708 learning_Rate = 0.01000 rmse=1.04515 mae=0.81464\n","\u003cclass '__main__.TrustSVD'\u003e iteration 100: loss = 19013.0511, delta_loss = 12.11311 learning_Rate = 0.01000 rmse=1.04513 mae=0.81462\n","current best rmse is 1.04513, mae is 0.81462\n","\u003cclass '__main__.TrustSVD'\u003e iteration 1: loss = 126479.9750, delta_loss = -126479.97503 learning_Rate = 0.01000 rmse=1.39350 mae=1.01088\n","\u003cclass '__main__.TrustSVD'\u003e iteration 2: loss = 58112.9916, delta_loss = 68366.98342 learning_Rate = 0.01000 rmse=1.29284 mae=0.96439\n","\u003cclass '__main__.TrustSVD'\u003e iteration 3: loss = 40221.4670, delta_loss = 17891.52459 learning_Rate = 0.01000 rmse=1.22964 mae=0.92965\n","\u003cclass '__main__.TrustSVD'\u003e iteration 4: loss = 35999.7688, delta_loss = 4221.69826 learning_Rate = 0.01000 rmse=1.19650 mae=0.90973\n","\u003cclass '__main__.TrustSVD'\u003e iteration 5: loss = 33634.8644, delta_loss = 2364.90434 learning_Rate = 0.01000 rmse=1.17676 mae=0.89706\n","\u003cclass '__main__.TrustSVD'\u003e iteration 6: loss = 31966.5486, delta_loss = 1668.31579 learning_Rate = 0.01000 rmse=1.16334 mae=0.88832\n","\u003cclass '__main__.TrustSVD'\u003e iteration 7: loss = 30684.0618, delta_loss = 1282.48687 learning_Rate = 0.01000 rmse=1.15333 mae=0.88213\n","\u003cclass '__main__.TrustSVD'\u003e iteration 8: loss = 29649.2762, delta_loss = 1034.78560 learning_Rate = 0.01000 rmse=1.14522 mae=0.87707\n","\u003cclass '__main__.TrustSVD'\u003e iteration 9: loss = 28787.1975, delta_loss = 862.07861 learning_Rate = 0.01000 rmse=1.13853 mae=0.87296\n","\u003cclass '__main__.TrustSVD'\u003e iteration 10: loss = 28052.1713, delta_loss = 735.02621 learning_Rate = 0.01000 rmse=1.13301 mae=0.86943\n","\u003cclass '__main__.TrustSVD'\u003e iteration 11: loss = 27414.3257, delta_loss = 637.84561 learning_Rate = 0.01000 rmse=1.12824 mae=0.86631\n","\u003cclass '__main__.TrustSVD'\u003e iteration 12: loss = 26853.0680, delta_loss = 561.25774 learning_Rate = 0.01000 rmse=1.12414 mae=0.86363\n","\u003cclass '__main__.TrustSVD'\u003e iteration 13: loss = 26353.6278, delta_loss = 499.44023 learning_Rate = 0.01000 rmse=1.12045 mae=0.86118\n","\u003cclass '__main__.TrustSVD'\u003e iteration 14: loss = 25905.0786, delta_loss = 448.54920 learning_Rate = 0.01000 rmse=1.11718 mae=0.85891\n","\u003cclass '__main__.TrustSVD'\u003e iteration 15: loss = 25499.1309, delta_loss = 405.94766 learning_Rate = 0.01000 rmse=1.11431 mae=0.85690\n","\u003cclass '__main__.TrustSVD'\u003e iteration 16: loss = 25129.3581, delta_loss = 369.77281 learning_Rate = 0.01000 rmse=1.11175 mae=0.85507\n","\u003cclass '__main__.TrustSVD'\u003e iteration 17: loss = 24790.6815, delta_loss = 338.67661 learning_Rate = 0.01000 rmse=1.10948 mae=0.85345\n","\u003cclass '__main__.TrustSVD'\u003e iteration 18: loss = 24479.0190, delta_loss = 311.66246 learning_Rate = 0.01000 rmse=1.10746 mae=0.85194\n","\u003cclass '__main__.TrustSVD'\u003e iteration 19: loss = 24191.0401, delta_loss = 287.97893 learning_Rate = 0.01000 rmse=1.10559 mae=0.85053\n","\u003cclass '__main__.TrustSVD'\u003e iteration 20: loss = 23923.9910, delta_loss = 267.04915 learning_Rate = 0.01000 rmse=1.10388 mae=0.84916\n","\u003cclass '__main__.TrustSVD'\u003e iteration 21: loss = 23675.5679, delta_loss = 248.42304 learning_Rate = 0.01000 rmse=1.10229 mae=0.84786\n","\u003cclass '__main__.TrustSVD'\u003e iteration 22: loss = 23443.8236, delta_loss = 231.74435 learning_Rate = 0.01000 rmse=1.10084 mae=0.84666\n","\u003cclass '__main__.TrustSVD'\u003e iteration 23: loss = 23227.0961, delta_loss = 216.72744 learning_Rate = 0.01000 rmse=1.09951 mae=0.84556\n","\u003cclass '__main__.TrustSVD'\u003e iteration 24: loss = 23023.9555, delta_loss = 203.14062 learning_Rate = 0.01000 rmse=1.09834 mae=0.84462\n","\u003cclass '__main__.TrustSVD'\u003e iteration 25: loss = 22833.1616, delta_loss = 190.79391 learning_Rate = 0.01000 rmse=1.09726 mae=0.84377\n","\u003cclass '__main__.TrustSVD'\u003e iteration 26: loss = 22653.6315, delta_loss = 179.53006 learning_Rate = 0.01000 rmse=1.09627 mae=0.84301\n","\u003cclass '__main__.TrustSVD'\u003e iteration 27: loss = 22484.4139, delta_loss = 169.21765 learning_Rate = 0.01000 rmse=1.09536 mae=0.84229\n","\u003cclass '__main__.TrustSVD'\u003e iteration 28: loss = 22324.6680, delta_loss = 159.74593 learning_Rate = 0.01000 rmse=1.09451 mae=0.84159\n","\u003cclass '__main__.TrustSVD'\u003e iteration 29: loss = 22173.6471, delta_loss = 151.02084 learning_Rate = 0.01000 rmse=1.09372 mae=0.84095\n","\u003cclass '__main__.TrustSVD'\u003e iteration 30: loss = 22030.6852, delta_loss = 142.96191 learning_Rate = 0.01000 rmse=1.09299 mae=0.84037\n","\u003cclass '__main__.TrustSVD'\u003e iteration 31: loss = 21895.1854, delta_loss = 135.49985 learning_Rate = 0.01000 rmse=1.09228 mae=0.83983\n","\u003cclass '__main__.TrustSVD'\u003e iteration 32: loss = 21766.6107, delta_loss = 128.57462 learning_Rate = 0.01000 rmse=1.09162 mae=0.83934\n","\u003cclass '__main__.TrustSVD'\u003e iteration 33: loss = 21644.4768, delta_loss = 122.13396 learning_Rate = 0.01000 rmse=1.09099 mae=0.83885\n","\u003cclass '__main__.TrustSVD'\u003e iteration 34: loss = 21528.3447, delta_loss = 116.13211 learning_Rate = 0.01000 rmse=1.09042 mae=0.83840\n","\u003cclass '__main__.TrustSVD'\u003e iteration 35: loss = 21417.8158, delta_loss = 110.52887 learning_Rate = 0.01000 rmse=1.08990 mae=0.83797\n","\u003cclass '__main__.TrustSVD'\u003e iteration 36: loss = 21312.5271, delta_loss = 105.28876 learning_Rate = 0.01000 rmse=1.08940 mae=0.83756\n","\u003cclass '__main__.TrustSVD'\u003e iteration 37: loss = 21212.1467, delta_loss = 100.38035 learning_Rate = 0.01000 rmse=1.08895 mae=0.83717\n","\u003cclass '__main__.TrustSVD'\u003e iteration 38: loss = 21116.3710, delta_loss = 95.77571 learning_Rate = 0.01000 rmse=1.08853 mae=0.83680\n","\u003cclass '__main__.TrustSVD'\u003e iteration 39: loss = 21024.9211, delta_loss = 91.44994 learning_Rate = 0.01000 rmse=1.08813 mae=0.83643\n","\u003cclass '__main__.TrustSVD'\u003e iteration 40: loss = 20937.5403, delta_loss = 87.38077 learning_Rate = 0.01000 rmse=1.08776 mae=0.83608\n","\u003cclass '__main__.TrustSVD'\u003e iteration 41: loss = 20853.9920, delta_loss = 83.54823 learning_Rate = 0.01000 rmse=1.08742 mae=0.83576\n","\u003cclass '__main__.TrustSVD'\u003e iteration 42: loss = 20774.0577, delta_loss = 79.93435 learning_Rate = 0.01000 rmse=1.08710 mae=0.83546\n","\u003cclass '__main__.TrustSVD'\u003e iteration 43: loss = 20697.5348, delta_loss = 76.52293 learning_Rate = 0.01000 rmse=1.08680 mae=0.83519\n","\u003cclass '__main__.TrustSVD'\u003e iteration 44: loss = 20624.2354, delta_loss = 73.29933 learning_Rate = 0.01000 rmse=1.08653 mae=0.83494\n","\u003cclass '__main__.TrustSVD'\u003e iteration 45: loss = 20553.9852, delta_loss = 70.25028 learning_Rate = 0.01000 rmse=1.08627 mae=0.83470\n","\u003cclass '__main__.TrustSVD'\u003e iteration 46: loss = 20486.6214, delta_loss = 67.36370 learning_Rate = 0.01000 rmse=1.08602 mae=0.83446\n","\u003cclass '__main__.TrustSVD'\u003e iteration 47: loss = 20421.9928, delta_loss = 64.62862 learning_Rate = 0.01000 rmse=1.08578 mae=0.83423\n","\u003cclass '__main__.TrustSVD'\u003e iteration 48: loss = 20359.9578, delta_loss = 62.03502 learning_Rate = 0.01000 rmse=1.08557 mae=0.83401\n","\u003cclass '__main__.TrustSVD'\u003e iteration 49: loss = 20300.3841, delta_loss = 59.57371 learning_Rate = 0.01000 rmse=1.08537 mae=0.83380\n","\u003cclass '__main__.TrustSVD'\u003e iteration 50: loss = 20243.1478, delta_loss = 57.23630 learning_Rate = 0.01000 rmse=1.08518 mae=0.83360\n","\u003cclass '__main__.TrustSVD'\u003e iteration 51: loss = 20188.1327, delta_loss = 55.01506 learning_Rate = 0.01000 rmse=1.08501 mae=0.83341\n","\u003cclass '__main__.TrustSVD'\u003e iteration 52: loss = 20135.2299, delta_loss = 52.90287 learning_Rate = 0.01000 rmse=1.08483 mae=0.83323\n","\u003cclass '__main__.TrustSVD'\u003e iteration 53: loss = 20084.3367, delta_loss = 50.89318 learning_Rate = 0.01000 rmse=1.08466 mae=0.83305\n","\u003cclass '__main__.TrustSVD'\u003e iteration 54: loss = 20035.3567, delta_loss = 48.97994 learning_Rate = 0.01000 rmse=1.08451 mae=0.83289\n","\u003cclass '__main__.TrustSVD'\u003e iteration 55: loss = 19988.1992, delta_loss = 47.15754 learning_Rate = 0.01000 rmse=1.08436 mae=0.83272\n","\u003cclass '__main__.TrustSVD'\u003e iteration 56: loss = 19942.7784, delta_loss = 45.42078 learning_Rate = 0.01000 rmse=1.08422 mae=0.83256\n","\u003cclass '__main__.TrustSVD'\u003e iteration 57: loss = 19899.0136, delta_loss = 43.76483 learning_Rate = 0.01000 rmse=1.08408 mae=0.83241\n","\u003cclass '__main__.TrustSVD'\u003e iteration 58: loss = 19856.8284, delta_loss = 42.18520 learning_Rate = 0.01000 rmse=1.08395 mae=0.83227\n","\u003cclass '__main__.TrustSVD'\u003e iteration 59: loss = 19816.1507, delta_loss = 40.67771 learning_Rate = 0.01000 rmse=1.08382 mae=0.83213\n","\u003cclass '__main__.TrustSVD'\u003e iteration 60: loss = 19776.9122, delta_loss = 39.23846 learning_Rate = 0.01000 rmse=1.08370 mae=0.83199\n","\u003cclass '__main__.TrustSVD'\u003e iteration 61: loss = 19739.0484, delta_loss = 37.86381 learning_Rate = 0.01000 rmse=1.08359 mae=0.83187\n","\u003cclass '__main__.TrustSVD'\u003e iteration 62: loss = 19702.4981, delta_loss = 36.55034 learning_Rate = 0.01000 rmse=1.08348 mae=0.83176\n","\u003cclass '__main__.TrustSVD'\u003e iteration 63: loss = 19667.2032, delta_loss = 35.29488 learning_Rate = 0.01000 rmse=1.08338 mae=0.83165\n","\u003cclass '__main__.TrustSVD'\u003e iteration 64: loss = 19633.1088, delta_loss = 34.09443 learning_Rate = 0.01000 rmse=1.08329 mae=0.83155\n","\u003cclass '__main__.TrustSVD'\u003e iteration 65: loss = 19600.1626, delta_loss = 32.94618 learning_Rate = 0.01000 rmse=1.08319 mae=0.83144\n","\u003cclass '__main__.TrustSVD'\u003e iteration 66: loss = 19568.3151, delta_loss = 31.84750 learning_Rate = 0.01000 rmse=1.08310 mae=0.83134\n","\u003cclass '__main__.TrustSVD'\u003e iteration 67: loss = 19537.5192, delta_loss = 30.79590 learning_Rate = 0.01000 rmse=1.08301 mae=0.83123\n","\u003cclass '__main__.TrustSVD'\u003e iteration 68: loss = 19507.7301, delta_loss = 29.78906 learning_Rate = 0.01000 rmse=1.08291 mae=0.83113\n","\u003cclass '__main__.TrustSVD'\u003e iteration 69: loss = 19478.9054, delta_loss = 28.82477 learning_Rate = 0.01000 rmse=1.08283 mae=0.83104\n","\u003cclass '__main__.TrustSVD'\u003e iteration 70: loss = 19451.0044, delta_loss = 27.90097 learning_Rate = 0.01000 rmse=1.08275 mae=0.83095\n","\u003cclass '__main__.TrustSVD'\u003e iteration 71: loss = 19423.9887, delta_loss = 27.01569 learning_Rate = 0.01000 rmse=1.08268 mae=0.83086\n","\u003cclass '__main__.TrustSVD'\u003e iteration 72: loss = 19397.8216, delta_loss = 26.16709 learning_Rate = 0.01000 rmse=1.08260 mae=0.83078\n","\u003cclass '__main__.TrustSVD'\u003e iteration 73: loss = 19372.4682, delta_loss = 25.35341 learning_Rate = 0.01000 rmse=1.08254 mae=0.83070\n","\u003cclass '__main__.TrustSVD'\u003e iteration 74: loss = 19347.8952, delta_loss = 24.57302 learning_Rate = 0.01000 rmse=1.08248 mae=0.83062\n","\u003cclass '__main__.TrustSVD'\u003e iteration 75: loss = 19324.0708, delta_loss = 23.82435 learning_Rate = 0.01000 rmse=1.08241 mae=0.83054\n","\u003cclass '__main__.TrustSVD'\u003e iteration 76: loss = 19300.9649, delta_loss = 23.10591 learning_Rate = 0.01000 rmse=1.08236 mae=0.83048\n","\u003cclass '__main__.TrustSVD'\u003e iteration 77: loss = 19278.5486, delta_loss = 22.41630 learning_Rate = 0.01000 rmse=1.08231 mae=0.83041\n","\u003cclass '__main__.TrustSVD'\u003e iteration 78: loss = 19256.7944, delta_loss = 21.75420 learning_Rate = 0.01000 rmse=1.08225 mae=0.83034\n","\u003cclass '__main__.TrustSVD'\u003e iteration 79: loss = 19235.6761, delta_loss = 21.11834 learning_Rate = 0.01000 rmse=1.08220 mae=0.83028\n","\u003cclass '__main__.TrustSVD'\u003e iteration 80: loss = 19215.1686, delta_loss = 20.50752 learning_Rate = 0.01000 rmse=1.08215 mae=0.83022\n","\u003cclass '__main__.TrustSVD'\u003e iteration 81: loss = 19195.2479, delta_loss = 19.92062 learning_Rate = 0.01000 rmse=1.08211 mae=0.83016\n","\u003cclass '__main__.TrustSVD'\u003e iteration 82: loss = 19175.8914, delta_loss = 19.35654 learning_Rate = 0.01000 rmse=1.08207 mae=0.83010\n","\u003cclass '__main__.TrustSVD'\u003e iteration 83: loss = 19157.0771, delta_loss = 18.81427 learning_Rate = 0.01000 rmse=1.08203 mae=0.83005\n","\u003cclass '__main__.TrustSVD'\u003e iteration 84: loss = 19138.7843, delta_loss = 18.29283 learning_Rate = 0.01000 rmse=1.08199 mae=0.83000\n","\u003cclass '__main__.TrustSVD'\u003e iteration 85: loss = 19120.9930, delta_loss = 17.79129 learning_Rate = 0.01000 rmse=1.08194 mae=0.82995\n","\u003cclass '__main__.TrustSVD'\u003e iteration 86: loss = 19103.6842, delta_loss = 17.30876 learning_Rate = 0.01000 rmse=1.08190 mae=0.82990\n","\u003cclass '__main__.TrustSVD'\u003e iteration 87: loss = 19086.8398, delta_loss = 16.84441 learning_Rate = 0.01000 rmse=1.08187 mae=0.82986\n","\u003cclass '__main__.TrustSVD'\u003e iteration 88: loss = 19070.4424, delta_loss = 16.39745 learning_Rate = 0.01000 rmse=1.08183 mae=0.82982\n","\u003cclass '__main__.TrustSVD'\u003e iteration 89: loss = 19054.4753, delta_loss = 15.96710 learning_Rate = 0.01000 rmse=1.08179 mae=0.82977\n","\u003cclass '__main__.TrustSVD'\u003e iteration 90: loss = 19038.9226, delta_loss = 15.55265 learning_Rate = 0.01000 rmse=1.08176 mae=0.82973\n","\u003cclass '__main__.TrustSVD'\u003e iteration 91: loss = 19023.7692, delta_loss = 15.15340 learning_Rate = 0.01000 rmse=1.08172 mae=0.82969\n","\u003cclass '__main__.TrustSVD'\u003e iteration 92: loss = 19009.0005, delta_loss = 14.76870 learning_Rate = 0.01000 rmse=1.08169 mae=0.82965\n","\u003cclass '__main__.TrustSVD'\u003e iteration 93: loss = 18994.6026, delta_loss = 14.39792 learning_Rate = 0.01000 rmse=1.08164 mae=0.82960\n","\u003cclass '__main__.TrustSVD'\u003e iteration 94: loss = 18980.5622, delta_loss = 14.04046 learning_Rate = 0.01000 rmse=1.08160 mae=0.82956\n","\u003cclass '__main__.TrustSVD'\u003e iteration 95: loss = 18966.8664, delta_loss = 13.69576 learning_Rate = 0.01000 rmse=1.08155 mae=0.82951\n","\u003cclass '__main__.TrustSVD'\u003e iteration 96: loss = 18953.5031, delta_loss = 13.36328 learning_Rate = 0.01000 rmse=1.08151 mae=0.82946\n","\u003cclass '__main__.TrustSVD'\u003e iteration 97: loss = 18940.4606, delta_loss = 13.04249 learning_Rate = 0.01000 rmse=1.08146 mae=0.82942\n","\u003cclass '__main__.TrustSVD'\u003e iteration 98: loss = 18927.7277, delta_loss = 12.73290 learning_Rate = 0.01000 rmse=1.08141 mae=0.82937\n","\u003cclass '__main__.TrustSVD'\u003e iteration 99: loss = 18915.2937, delta_loss = 12.43405 learning_Rate = 0.01000 rmse=1.08136 mae=0.82933\n","\u003cclass '__main__.TrustSVD'\u003e iteration 100: loss = 18903.1482, delta_loss = 12.14548 learning_Rate = 0.01000 rmse=1.08132 mae=0.82929\n","current best rmse is 1.08132, mae is 0.82929\n","\u003cclass '__main__.TrustSVD'\u003e iteration 1: loss = 123912.3484, delta_loss = -123912.34837 learning_Rate = 0.01000 rmse=1.40655 mae=1.01944\n","\u003cclass '__main__.TrustSVD'\u003e iteration 2: loss = 56506.0821, delta_loss = 67406.26625 learning_Rate = 0.01000 rmse=1.29288 mae=0.96407\n","\u003cclass '__main__.TrustSVD'\u003e iteration 3: loss = 39993.4199, delta_loss = 16512.66224 learning_Rate = 0.01000 rmse=1.22600 mae=0.92501\n","\u003cclass '__main__.TrustSVD'\u003e iteration 4: loss = 35875.9936, delta_loss = 4117.42627 learning_Rate = 0.01000 rmse=1.19286 mae=0.90418\n","\u003cclass '__main__.TrustSVD'\u003e iteration 5: loss = 33573.3193, delta_loss = 2302.67427 learning_Rate = 0.01000 rmse=1.17239 mae=0.89127\n","\u003cclass '__main__.TrustSVD'\u003e iteration 6: loss = 31947.1934, delta_loss = 1626.12599 learning_Rate = 0.01000 rmse=1.15766 mae=0.88140\n","\u003cclass '__main__.TrustSVD'\u003e iteration 7: loss = 30694.0549, delta_loss = 1253.13845 learning_Rate = 0.01000 rmse=1.14635 mae=0.87383\n","\u003cclass '__main__.TrustSVD'\u003e iteration 8: loss = 29679.1732, delta_loss = 1014.88169 learning_Rate = 0.01000 rmse=1.13753 mae=0.86790\n","\u003cclass '__main__.TrustSVD'\u003e iteration 9: loss = 28830.9903, delta_loss = 848.18286 learning_Rate = 0.01000 rmse=1.13038 mae=0.86307\n","\u003cclass '__main__.TrustSVD'\u003e iteration 10: loss = 28106.4196, delta_loss = 724.57079 learning_Rate = 0.01000 rmse=1.12444 mae=0.85907\n","\u003cclass '__main__.TrustSVD'\u003e iteration 11: loss = 27477.0476, delta_loss = 629.37194 learning_Rate = 0.01000 rmse=1.11948 mae=0.85574\n","\u003cclass '__main__.TrustSVD'\u003e iteration 12: loss = 26922.9753, delta_loss = 554.07228 learning_Rate = 0.01000 rmse=1.11523 mae=0.85286\n","\u003cclass '__main__.TrustSVD'\u003e iteration 13: loss = 26429.7398, delta_loss = 493.23553 learning_Rate = 0.01000 rmse=1.11148 mae=0.85018\n","\u003cclass '__main__.TrustSVD'\u003e iteration 14: loss = 25986.5664, delta_loss = 443.17338 learning_Rate = 0.01000 rmse=1.10810 mae=0.84773\n","\u003cclass '__main__.TrustSVD'\u003e iteration 15: loss = 25585.2682, delta_loss = 401.29827 learning_Rate = 0.01000 rmse=1.10499 mae=0.84546\n","\u003cclass '__main__.TrustSVD'\u003e iteration 16: loss = 25219.5116, delta_loss = 365.75657 learning_Rate = 0.01000 rmse=1.10223 mae=0.84339\n","\u003cclass '__main__.TrustSVD'\u003e iteration 17: loss = 24884.3131, delta_loss = 335.19846 learning_Rate = 0.01000 rmse=1.09977 mae=0.84150\n","\u003cclass '__main__.TrustSVD'\u003e iteration 18: loss = 24575.6863, delta_loss = 308.62680 learning_Rate = 0.01000 rmse=1.09750 mae=0.83974\n","\u003cclass '__main__.TrustSVD'\u003e iteration 19: loss = 24290.3910, delta_loss = 285.29536 learning_Rate = 0.01000 rmse=1.09545 mae=0.83814\n","\u003cclass '__main__.TrustSVD'\u003e iteration 20: loss = 24025.7525, delta_loss = 264.63851 learning_Rate = 0.01000 rmse=1.09358 mae=0.83664\n","\u003cclass '__main__.TrustSVD'\u003e iteration 21: loss = 23779.5310, delta_loss = 246.22142 learning_Rate = 0.01000 rmse=1.09188 mae=0.83523\n","\u003cclass '__main__.TrustSVD'\u003e iteration 22: loss = 23549.8268, delta_loss = 229.70426 learning_Rate = 0.01000 rmse=1.09033 mae=0.83392\n","\u003cclass '__main__.TrustSVD'\u003e iteration 23: loss = 23335.0103, delta_loss = 214.81645 learning_Rate = 0.01000 rmse=1.08892 mae=0.83269\n","\u003cclass '__main__.TrustSVD'\u003e iteration 24: loss = 23133.6719, delta_loss = 201.33847 learning_Rate = 0.01000 rmse=1.08761 mae=0.83155\n","\u003cclass '__main__.TrustSVD'\u003e iteration 25: loss = 22944.5827, delta_loss = 189.08914 learning_Rate = 0.01000 rmse=1.08641 mae=0.83047\n","\u003cclass '__main__.TrustSVD'\u003e iteration 26: loss = 22766.6659, delta_loss = 177.91679 learning_Rate = 0.01000 rmse=1.08531 mae=0.82946\n","\u003cclass '__main__.TrustSVD'\u003e iteration 27: loss = 22598.9728, delta_loss = 167.69310 learning_Rate = 0.01000 rmse=1.08429 mae=0.82850\n","\u003cclass '__main__.TrustSVD'\u003e iteration 28: loss = 22440.6641, delta_loss = 158.30873 learning_Rate = 0.01000 rmse=1.08335 mae=0.82761\n","\u003cclass '__main__.TrustSVD'\u003e iteration 29: loss = 22290.9942, delta_loss = 149.66990 learning_Rate = 0.01000 rmse=1.08247 mae=0.82677\n","\u003cclass '__main__.TrustSVD'\u003e iteration 30: loss = 22149.2983, delta_loss = 141.69590 learning_Rate = 0.01000 rmse=1.08167 mae=0.82596\n","\u003cclass '__main__.TrustSVD'\u003e iteration 31: loss = 22014.9813, delta_loss = 134.31695 learning_Rate = 0.01000 rmse=1.08093 mae=0.82521\n","\u003cclass '__main__.TrustSVD'\u003e iteration 32: loss = 21887.5088, delta_loss = 127.47250 learning_Rate = 0.01000 rmse=1.08025 mae=0.82452\n","\u003cclass '__main__.TrustSVD'\u003e iteration 33: loss = 21766.3990, delta_loss = 121.10982 learning_Rate = 0.01000 rmse=1.07962 mae=0.82390\n","\u003cclass '__main__.TrustSVD'\u003e iteration 34: loss = 21651.2162, delta_loss = 115.18280 learning_Rate = 0.01000 rmse=1.07903 mae=0.82332\n","\u003cclass '__main__.TrustSVD'\u003e iteration 35: loss = 21541.5652, delta_loss = 109.65099 learning_Rate = 0.01000 rmse=1.07849 mae=0.82279\n","\u003cclass '__main__.TrustSVD'\u003e iteration 36: loss = 21437.0865, delta_loss = 104.47872 learning_Rate = 0.01000 rmse=1.07798 mae=0.82230\n","\u003cclass '__main__.TrustSVD'\u003e iteration 37: loss = 21337.4520, delta_loss = 99.63448 learning_Rate = 0.01000 rmse=1.07750 mae=0.82186\n","\u003cclass '__main__.TrustSVD'\u003e iteration 38: loss = 21242.3617, delta_loss = 95.09030 learning_Rate = 0.01000 rmse=1.07704 mae=0.82143\n","\u003cclass '__main__.TrustSVD'\u003e iteration 39: loss = 21151.5405, delta_loss = 90.82128 learning_Rate = 0.01000 rmse=1.07660 mae=0.82102\n","\u003cclass '__main__.TrustSVD'\u003e iteration 40: loss = 21064.7353, delta_loss = 86.80520 learning_Rate = 0.01000 rmse=1.07618 mae=0.82061\n","\u003cclass '__main__.TrustSVD'\u003e iteration 41: loss = 20981.7131, delta_loss = 83.02213 learning_Rate = 0.01000 rmse=1.07580 mae=0.82023\n","\u003cclass '__main__.TrustSVD'\u003e iteration 42: loss = 20902.2589, delta_loss = 79.45421 learning_Rate = 0.01000 rmse=1.07542 mae=0.81987\n","\u003cclass '__main__.TrustSVD'\u003e iteration 43: loss = 20826.1736, delta_loss = 76.08532 learning_Rate = 0.01000 rmse=1.07507 mae=0.81951\n","\u003cclass '__main__.TrustSVD'\u003e iteration 44: loss = 20753.2727, delta_loss = 72.90094 learning_Rate = 0.01000 rmse=1.07474 mae=0.81917\n","\u003cclass '__main__.TrustSVD'\u003e iteration 45: loss = 20683.3847, delta_loss = 69.88792 learning_Rate = 0.01000 rmse=1.07442 mae=0.81884\n","\u003cclass '__main__.TrustSVD'\u003e iteration 46: loss = 20616.3504, delta_loss = 67.03431 learning_Rate = 0.01000 rmse=1.07412 mae=0.81852\n","\u003cclass '__main__.TrustSVD'\u003e iteration 47: loss = 20552.0211, delta_loss = 64.32928 learning_Rate = 0.01000 rmse=1.07383 mae=0.81821\n","\u003cclass '__main__.TrustSVD'\u003e iteration 48: loss = 20490.2582, delta_loss = 61.76294 learning_Rate = 0.01000 rmse=1.07354 mae=0.81791\n","\u003cclass '__main__.TrustSVD'\u003e iteration 49: loss = 20430.9319, delta_loss = 59.32626 learning_Rate = 0.01000 rmse=1.07328 mae=0.81763\n","\u003cclass '__main__.TrustSVD'\u003e iteration 50: loss = 20373.9210, delta_loss = 57.01096 learning_Rate = 0.01000 rmse=1.07304 mae=0.81737\n","\u003cclass '__main__.TrustSVD'\u003e iteration 51: loss = 20319.1115, delta_loss = 54.80947 learning_Rate = 0.01000 rmse=1.07281 mae=0.81712\n","\u003cclass '__main__.TrustSVD'\u003e iteration 52: loss = 20266.3967, delta_loss = 52.71482 learning_Rate = 0.01000 rmse=1.07258 mae=0.81687\n","\u003cclass '__main__.TrustSVD'\u003e iteration 53: loss = 20215.6761, delta_loss = 50.72057 learning_Rate = 0.01000 rmse=1.07235 mae=0.81663\n","\u003cclass '__main__.TrustSVD'\u003e iteration 54: loss = 20166.8553, delta_loss = 48.82081 learning_Rate = 0.01000 rmse=1.07214 mae=0.81641\n","\u003cclass '__main__.TrustSVD'\u003e iteration 55: loss = 20119.8453, delta_loss = 47.01005 learning_Rate = 0.01000 rmse=1.07194 mae=0.81620\n","\u003cclass '__main__.TrustSVD'\u003e iteration 56: loss = 20074.5621, delta_loss = 45.28321 learning_Rate = 0.01000 rmse=1.07175 mae=0.81600\n","\u003cclass '__main__.TrustSVD'\u003e iteration 57: loss = 20030.9265, delta_loss = 43.63559 learning_Rate = 0.01000 rmse=1.07157 mae=0.81581\n","\u003cclass '__main__.TrustSVD'\u003e iteration 58: loss = 19988.8637, delta_loss = 42.06280 learning_Rate = 0.01000 rmse=1.07140 mae=0.81563\n","\u003cclass '__main__.TrustSVD'\u003e iteration 59: loss = 19948.3029, delta_loss = 40.56075 learning_Rate = 0.01000 rmse=1.07124 mae=0.81546\n","\u003cclass '__main__.TrustSVD'\u003e iteration 60: loss = 19909.1773, delta_loss = 39.12566 learning_Rate = 0.01000 rmse=1.07108 mae=0.81531\n","\u003cclass '__main__.TrustSVD'\u003e iteration 61: loss = 19871.4233, delta_loss = 37.75397 learning_Rate = 0.01000 rmse=1.07094 mae=0.81516\n","\u003cclass '__main__.TrustSVD'\u003e iteration 62: loss = 19834.9809, delta_loss = 36.44235 learning_Rate = 0.01000 rmse=1.07080 mae=0.81502\n","\u003cclass '__main__.TrustSVD'\u003e iteration 63: loss = 19799.7932, delta_loss = 35.18771 learning_Rate = 0.01000 rmse=1.07065 mae=0.81488\n","\u003cclass '__main__.TrustSVD'\u003e iteration 64: loss = 19765.8061, delta_loss = 33.98712 learning_Rate = 0.01000 rmse=1.07052 mae=0.81474\n","\u003cclass '__main__.TrustSVD'\u003e iteration 65: loss = 19732.9682, delta_loss = 32.83786 learning_Rate = 0.01000 rmse=1.07040 mae=0.81461\n","\u003cclass '__main__.TrustSVD'\u003e iteration 66: loss = 19701.2309, delta_loss = 31.73736 learning_Rate = 0.01000 rmse=1.07028 mae=0.81449\n","\u003cclass '__main__.TrustSVD'\u003e iteration 67: loss = 19670.5477, delta_loss = 30.68320 learning_Rate = 0.01000 rmse=1.07017 mae=0.81438\n","\u003cclass '__main__.TrustSVD'\u003e iteration 68: loss = 19640.8746, delta_loss = 29.67312 learning_Rate = 0.01000 rmse=1.07006 mae=0.81427\n","\u003cclass '__main__.TrustSVD'\u003e iteration 69: loss = 19612.1696, delta_loss = 28.70496 learning_Rate = 0.01000 rmse=1.06996 mae=0.81417\n","\u003cclass '__main__.TrustSVD'\u003e iteration 70: loss = 19584.3929, delta_loss = 27.77672 learning_Rate = 0.01000 rmse=1.06988 mae=0.81408\n","\u003cclass '__main__.TrustSVD'\u003e iteration 71: loss = 19557.5064, delta_loss = 26.88650 learning_Rate = 0.01000 rmse=1.06978 mae=0.81399\n","\u003cclass '__main__.TrustSVD'\u003e iteration 72: loss = 19531.4739, delta_loss = 26.03248 learning_Rate = 0.01000 rmse=1.06969 mae=0.81390\n","\u003cclass '__main__.TrustSVD'\u003e iteration 73: loss = 19506.2609, delta_loss = 25.21298 learning_Rate = 0.01000 rmse=1.06961 mae=0.81383\n","\u003cclass '__main__.TrustSVD'\u003e iteration 74: loss = 19481.8345, delta_loss = 24.42639 learning_Rate = 0.01000 rmse=1.06954 mae=0.81375\n","\u003cclass '__main__.TrustSVD'\u003e iteration 75: loss = 19458.1633, delta_loss = 23.67119 learning_Rate = 0.01000 rmse=1.06946 mae=0.81367\n","\u003cclass '__main__.TrustSVD'\u003e iteration 76: loss = 19435.2174, delta_loss = 22.94594 learning_Rate = 0.01000 rmse=1.06938 mae=0.81360\n","\u003cclass '__main__.TrustSVD'\u003e iteration 77: loss = 19412.9681, delta_loss = 22.24928 learning_Rate = 0.01000 rmse=1.06932 mae=0.81354\n","\u003cclass '__main__.TrustSVD'\u003e iteration 78: loss = 19391.3882, delta_loss = 21.57992 learning_Rate = 0.01000 rmse=1.06924 mae=0.81347\n","\u003cclass '__main__.TrustSVD'\u003e iteration 79: loss = 19370.4515, delta_loss = 20.93663 learning_Rate = 0.01000 rmse=1.06918 mae=0.81341\n","\u003cclass '__main__.TrustSVD'\u003e iteration 80: loss = 19350.1333, delta_loss = 20.31825 learning_Rate = 0.01000 rmse=1.06912 mae=0.81335\n","\u003cclass '__main__.TrustSVD'\u003e iteration 81: loss = 19330.4096, delta_loss = 19.72368 learning_Rate = 0.01000 rmse=1.06907 mae=0.81330\n","\u003cclass '__main__.TrustSVD'\u003e iteration 82: loss = 19311.2578, delta_loss = 19.15186 learning_Rate = 0.01000 rmse=1.06901 mae=0.81324\n","\u003cclass '__main__.TrustSVD'\u003e iteration 83: loss = 19292.6559, delta_loss = 18.60182 learning_Rate = 0.01000 rmse=1.06896 mae=0.81318\n","\u003cclass '__main__.TrustSVD'\u003e iteration 84: loss = 19274.5834, delta_loss = 18.07258 learning_Rate = 0.01000 rmse=1.06891 mae=0.81313\n","\u003cclass '__main__.TrustSVD'\u003e iteration 85: loss = 19257.0201, delta_loss = 17.56327 learning_Rate = 0.01000 rmse=1.06885 mae=0.81307\n","\u003cclass '__main__.TrustSVD'\u003e iteration 86: loss = 19239.9471, delta_loss = 17.07302 learning_Rate = 0.01000 rmse=1.06879 mae=0.81303\n","\u003cclass '__main__.TrustSVD'\u003e iteration 87: loss = 19223.3460, delta_loss = 16.60102 learning_Rate = 0.01000 rmse=1.06874 mae=0.81298\n","\u003cclass '__main__.TrustSVD'\u003e iteration 88: loss = 19207.1996, delta_loss = 16.14649 learning_Rate = 0.01000 rmse=1.06868 mae=0.81293\n","\u003cclass '__main__.TrustSVD'\u003e iteration 89: loss = 19191.4909, delta_loss = 15.70869 learning_Rate = 0.01000 rmse=1.06863 mae=0.81288\n","\u003cclass '__main__.TrustSVD'\u003e iteration 90: loss = 19176.2039, delta_loss = 15.28692 learning_Rate = 0.01000 rmse=1.06857 mae=0.81284\n","\u003cclass '__main__.TrustSVD'\u003e iteration 91: loss = 19161.3234, delta_loss = 14.88051 learning_Rate = 0.01000 rmse=1.06852 mae=0.81279\n","\u003cclass '__main__.TrustSVD'\u003e iteration 92: loss = 19146.8346, delta_loss = 14.48882 learning_Rate = 0.01000 rmse=1.06847 mae=0.81275\n","\u003cclass '__main__.TrustSVD'\u003e iteration 93: loss = 19132.7234, delta_loss = 14.11123 learning_Rate = 0.01000 rmse=1.06842 mae=0.81270\n","\u003cclass '__main__.TrustSVD'\u003e iteration 94: loss = 19118.9762, delta_loss = 13.74718 learning_Rate = 0.01000 rmse=1.06837 mae=0.81266\n","\u003cclass '__main__.TrustSVD'\u003e iteration 95: loss = 19105.5801, delta_loss = 13.39609 learning_Rate = 0.01000 rmse=1.06831 mae=0.81262\n","\u003cclass '__main__.TrustSVD'\u003e iteration 96: loss = 19092.5227, delta_loss = 13.05744 learning_Rate = 0.01000 rmse=1.06827 mae=0.81258\n","\u003cclass '__main__.TrustSVD'\u003e iteration 97: loss = 19079.7919, delta_loss = 12.73073 learning_Rate = 0.01000 rmse=1.06822 mae=0.81255\n","\u003cclass '__main__.TrustSVD'\u003e iteration 98: loss = 19067.3765, delta_loss = 12.41547 learning_Rate = 0.01000 rmse=1.06818 mae=0.81251\n","\u003cclass '__main__.TrustSVD'\u003e iteration 99: loss = 19055.2653, delta_loss = 12.11120 learning_Rate = 0.01000 rmse=1.06814 mae=0.81248\n","\u003cclass '__main__.TrustSVD'\u003e iteration 100: loss = 19043.4478, delta_loss = 11.81747 learning_Rate = 0.01000 rmse=1.06809 mae=0.81244\n","current best rmse is 1.06809, mae is 0.81244\n","the rmses are [1.0723762058208286, 1.0913739801905433, 1.0451304998486222, 1.081323236466817, 1.0680909715622449]\n","the maes are [0.8247748642716876, 0.8277324218749993, 0.8146197731698944, 0.8292933348629117, 0.8124386225832294]\n","the average of rmses is 1.0716589787778112 \n","the average of maes is 0.8217718033525445 \n"]}],"source":["# encoding:utf-8\n","import sys\n","\n","sys.path.append(\"..\")\n","\n","import math\n","import numpy as np\n","#from mf import MF\n","#from reader.trust import TrustGetter\n","\n","\n","class TrustSVD(MF):\n","    \"\"\"\n","    docstring for TrustSVD\n","    implement the TrustSVD\n","\n","    Koren Y. Factor in the neighbors: Scalable and accurate collaborative filtering[J]. ACM Transactions on Knowledge Discovery from Data (TKDD), 2010, 4(1): 1.\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(TrustSVD, self).__init__()\n","\n","        self.config.lr = 0.01  # 0.005\n","        self.config.maxIter = 100\n","        self.config.lambdaP = 1.2\n","        self.config.lambdaQ = 1.2\n","\n","        self.config.lambdaB = 1.2\n","        self.config.lambdaY = 1.2\n","        self.config.lambdaW = 1.2\n","        self.config.lambdaT = 0.9\n","\n","        self.tg = TrustGetter()\n","        # self.init_model()\n","\n","    def init_model(self, k):\n","        super(TrustSVD, self).init_model(k)\n","        self.Bu = np.random.rand(self.rg.get_train_size()[0]) / (self.config.factor ** 0.5)  # bias value of user\n","        self.Bi = np.random.rand(self.rg.get_train_size()[1]) / (self.config.factor ** 0.5)  # bias value of item\n","        self.Y = np.random.rand(self.rg.get_train_size()[1], self.config.factor) / (\n","                self.config.factor ** 0.5)  # implicit preference\n","        self.W = np.random.rand(self.rg.get_train_size()[0], self.config.factor) / (\n","                self.config.factor ** 0.5)  # implicit preference\n","\n","    def train_model(self, k):\n","        super(TrustSVD, self).train_model(k)\n","        iteration = 0\n","        while iteration \u003c self.config.maxIter:\n","            self.loss = 0\n","            for index, line in enumerate(self.rg.trainSet()):\n","                user, item, rating = line\n","                u = self.rg.user[user]\n","                i = self.rg.item[item]\n","                error = rating - self.predict(user, item)\n","                self.loss += error ** 2\n","\n","                p, q = self.P[u], self.Q[i]\n","                nu, sum_y = self.get_sum_y(user)\n","                nv, sum_w = self.get_sum_w(user)\n","\n","                frac = lambda x: 1.0 / math.sqrt(x)\n","\n","                # update latent vectors\n","                self.Bu[u] += self.config.lr * (error - self.config.lambdaB * frac(nu) * self.Bu[u])\n","                self.Bi[i] += self.config.lr * (error - self.config.lambdaB * frac(nv) * self.Bi[i])\n","\n","                self.Q[i] += self.config.lr * (error * (p + sum_y + sum_w) - self.config.lambdaQ * frac(nu) * q)\n","\n","                followees = self.tg.get_followees(user)\n","                ws = np.zeros(self.config.factor)\n","                for followee in followees:\n","                    if self.rg.containsUser(user) and self.rg.containsUser(followee):\n","                        nw = len(self.tg.get_followers(followee))\n","                        vid = self.rg.user[followee]\n","                        w = self.W[vid]\n","                        weight = 1  # followees[followee]\n","                        err = w.dot(p) - weight\n","                        self.loss += err ** 2\n","                        ws += err * w\n","                        self.W[vid] += self.config.lr * (\n","                                err * frac(nv) * q - self.config.lambdaT * err * p - self.config.lambdaW * frac(\n","                            nw) * w)  # w\n","                self.P[u] += self.config.lr * (error * q - self.config.lambdaT * ws - (\n","                        self.config.lambdaP * frac(nu) + self.config.lambdaT * frac(nv)) * p)\n","\n","                u_items = self.rg.user_rated_items(u)\n","                for j in u_items:\n","                    idj = self.rg.item[j]\n","                    self.Y[idj] += self.config.lr * (\n","                            error * frac(nu) * q - self.config.lambdaY * frac(nv) * self.Y[idj])\n","\n","            self.loss += self.config.lambdaP * (self.P * self.P).sum() + self.config.lambdaQ * (self.Q * self.Q).sum() \\\n","                         + self.config.lambdaB * (\n","                                 (self.Bu * self.Bu).sum() + (self.Bi * self.Bi).sum()) + self.config.lambdaY * (\n","                                 self.Y * self.Y).sum() + self.config.lambdaW * (self.W * self.W).sum()\n","            iteration += 1\n","            if self.isConverged(iteration):\n","                break\n","\n","    def predict(self, u, i):\n","        if self.rg.containsUser(u) and self.rg.containsItem(i):\n","            _, sum_y = self.get_sum_y(u)\n","            _, sum_w = self.get_sum_w(u)\n","            u = self.rg.user[u]\n","            i = self.rg.item[i]\n","            return self.Q[i].dot(self.P[u] + sum_y + sum_w) + self.rg.globalMean + self.Bi[i] + self.Bu[u]\n","        elif self.rg.containsUser(u) and not self.rg.containsItem(i):\n","            return self.rg.userMeans[u]\n","        elif not self.rg.containsUser(u) and self.rg.containsItem(i):\n","            return self.rg.itemMeans[i]\n","        else:\n","            return self.rg.globalMean\n","\n","    def get_sum_y(self, u):\n","        u_items = self.rg.user_rated_items(u)\n","        nu = len(u_items)\n","        sum_y = np.zeros(self.config.factor)\n","        for j in u_items:\n","            sum_y += self.Y[self.rg.item[j]]\n","        sum_y /= (np.sqrt(nu))\n","        return nu, sum_y\n","\n","    def get_sum_w(self, u):\n","        followees = self.tg.get_followees(u)\n","        nu = 1\n","        sum_w = np.zeros(self.config.factor)\n","        for v in followees.keys():\n","            if self.rg.containsUser(v):\n","                nu += 1\n","                sum_w += self.W[self.rg.user[v]]\n","        sum_w /= np.sqrt(nu)\n","        return nu, sum_w\n","\n","\n","if __name__ == '__main__':\n","    # bmf = TrustSVD()\n","    # bmf.train_model(0)\n","    # coldrmse = bmf.predict_model_cold_users()\n","    # print('cold start user rmse is :' + str(coldrmse))\n","    # bmf.show_rmse()\n","\n","    rmses = []\n","    maes = []\n","    bmf = TrustSVD()\n","    #bmf.config.k_fold_num = 1\n","    # print(bmf.rg.trainSet_u[1])\n","    for i in range(bmf.config.k_fold_num):\n","        bmf.train_model(i)\n","        rmse, mae = bmf.predict_model()\n","        print(\"current best rmse is %0.5f, mae is %0.5f\" % (rmse, mae))\n","        rmses.append(rmse)\n","        maes.append(mae)\n","    rmse_avg = sum(rmses) / bmf.config.k_fold_num\n","    mae_avg = sum(maes) / bmf.config.k_fold_num\n","    print(\"the rmses are %s\" % rmses)\n","    print(\"the maes are %s\" % maes)\n","    print(\"the average of rmses is %s \" % rmse_avg)\n","    print(\"the average of maes is %s \" % mae_avg)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN2BMZpF/C93ZmCucsr7qi2","collapsed_sections":[],"mount_file_id":"1bttmN3kU9g2ezCRyU_aqQ_tw6ixfnXzA","name":"RSAlgorithms.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}